---
title: "Drosophila Metabarcoding"
subtitle: "Determining a detection threshold"
author: "Alexander Piper"
date: "`r Sys.Date()`"
output:
  html_document:
    highlighter: null
    theme: "flatly"
    code_download: true
    toc: true
    toc_float: 
      collapsed: false
      smooth_scroll: true
    df_print: paged    
  pdf_document: default
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
# Knitr global setup - change eval to true to run code
library(knitr)
knitr::opts_chunk$set(echo = TRUE, eval=FALSE, message=FALSE,error=FALSE, fig.show = "hold", fig.keep = "all")
opts_chunk$set(dev = 'png')
```

# Load packages
```{r load packages}
#Set required packages
.cran_packages <- c("tidyverse",
                    "tidymodels",
                    "patchwork", 
                    "RColorBrewer",
                    "probably",
                    "devtools")
.bioc_packages <- c("dada2",
                    "phyloseq", 
                    "DECIPHER",
                    "Biostrings",
                    "ShortRead", 
                    "philr",
                    "ALDEx2")

.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install(.bioc_packages[!.inst], ask = F)
}

sapply(c(.cran_packages,.bioc_packages), require, character.only = TRUE)

# Github packages
devtools::install_github("alexpiper/seqateurs")
devtools::install_github("mikemc/speedyseq")

library(speedyseq)
library(seqateurs)

#Source internal functions
source('R/themes.R')

```


# Introduction

We will evaluate 5 different methods to estimate the cross contamination rate:

* The ‘unassigned indices’ method used the abundance ratio of valid (applied during library preparation) to invalid (pairs that could only arise due to switching) index combinations as per Wilcox et al. (2018).

* The ‘positive control’ method used the abundance ratio of synthetic COI sequences that were correctly assigned to the positive control libraries to those that were found in other samples. 

* The ‘mock community’ method used the abundance ratio of expected to unexpected taxon observations across all mock communities. 

* The ‘logistic regression’ method fit a logistic model of the per-sample RRA of each detection, trained on the expected and unexpected taxon observations within the mock communities, with the sequencing run included as an additional covariate to account for run-specific variation in contamination rates. With this method the predictive equation from the logistic model describes the probability of each observation being a true positive, and all observations with probability ≥50% were considered detections.

* The final method used the same logistic regression model but included both the number of DNA extraction and PCR replicates that each observation was detected in as additional covariates. 


To evaluate the predictive performance of each approach, all taxon observations within the mock communities will be randomly split into 80% training and 20% test sets and the logistic regression classifiers and all detection thresholds compared for their ability to remove cross contamination within the test dataset. 

To ensure the comparisons were robust to whichever observations were assigned to the training and test sets, the random splitting, training, and evaluation will be repeated 1,000 times and the results averaged.

# Unassigned indices

```{R switching missasigned}
files <- "data/"
runs <- dir(files)
## Calculate index switching
i=1

# Make output list 
outlist <- vector("list", length=length(runs))
for (i in 1:length(runs)){
  path <- paste0(files,"/", runs[i])

  indices <- sort(list.files(path, pattern="_R1_", full.names = TRUE)) %>%
    purrr::set_names() %>%
    purrr::map(seqateurs::summarise_index) %>%
    bind_rows(.id="sample_name")%>%
    arrange(desc(Freq)) %>% 
    dplyr::mutate(sample_name = sample_name %>% 
                    str_remove(pattern = "^(.*)\\/") %>%
                    str_remove(pattern = "(?:.(?!_S))+$"))

  
  if(!any(str_detect(indices$sample_name, "Undetermined"))){
    stop("Error, an Undetermined reads fastq must be present to calculate index switching")
    }
  
  outlist[[i]] <- indices %>%
    mutate(fcid = runs[i])
}

indices <- outlist %>%
  bind_rows()

#write_rds(indices, "output/indices.rds")

indices <- readRDS("output/indices.rds")
# Get all possible combinations
combos <- indices %>% 
  dplyr::filter(!str_detect(sample_name, "Undetermined")) %>%
  dplyr::select(index, index2, fcid) %>%
  group_by(fcid) %>%
  tidyr::expand(index, index2) %>%
  mutate(other=FALSE)

#get unused combinations resulting from index switching
switched <- indices %>%
  left_join(combos, by=c("index", "index2", "fcid")) %>%
  as_tibble() %>%
  mutate(other = replace_na(other, TRUE),
         type = case_when(
    str_detect(sample_name,"Undetermined") & other == FALSE ~ "switched",
    !str_detect(sample_name,"Undetermined") & other == FALSE ~ "correct",
    other==TRUE ~ "other"
  )) %>%
  dplyr::select(-other)

switch_summary <- switched %>%
  group_by(fcid, type) %>%
  summarise(reads = sum(Freq))%>% 
  pivot_wider(names_from = type,
              values_from = reads) %>%
  mutate(switchrate = switched/correct)

#Plot switching
gg.switch <- switched %>%
  filter(!type=="other") %>%
  mutate(index = factor(index, levels = unique(index)),
         index2 = factor(index2, levels= unique(index2))) %>%
  mutate(fcid = case_when(
    fcid == "HLVKYDMXX" ~ paste0("NovaSeq - ", fcid),
    TRUE ~ paste0("MiSeq - ", fcid)
  )) %>%
  ggplot(aes(x = index, y = index2), stat="identity") +
  geom_tile(aes(fill = Freq),alpha=0.8)  + 
  scale_fill_viridis_c(name="log10 Reads", begin=0.1, trans="log10", na.value="gray")+
  base_theme + 
  facet_wrap(~fcid, scales="free", drop=TRUE) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank()) + 
  labs(x = "i7 Index",
       y = "i5 Index")

gg.switch

```

# Positive control

```{r switch syns}
ps <- readRDS("output/rds/ps_merged.rds")

# plot synthetic positive controls
Syn_taxa <- c("Synthetic Acrididae", "Synthetic Aphididae", "Synthetic Apidae", "Synthetic Cerambycidae", "Synthetic Crambidae", "Synthetic Culicidae","Synthetic Drosophilidae","Synthetic Nitidulidae","Synthetic Siricidae","Synthetic Tephritidae", "Synthetic Thripidae", "Synthetic Tortricidae", "Synthetic Triozidae")


#Check for presence of all synthetic taxa
library(RColorBrewer)
colourCount = length(Syn_taxa)
getPalette = colorRampPalette(brewer.pal(12, "Spectral"))
colour.pal <- getPalette(colourCount)

gg.syn <- ps %>%
  subset_samples(type=="POS") %>%
  subset_taxa(Species %in% str_replace(Syn_taxa, " ", "_")) %>%
  filter_taxa(function(x) mean(x) > 0, TRUE) %>%
  speedyseq::psmelt()%>%
  dplyr::filter(fcid=="HLVKYDMXX") %>%
  group_by(sample_id) %>%
  mutate_at(vars(Abundance), ~ . / sum(.) ) %>% #Convert to proportions
    ggplot(aes(x=sample_name, y=Abundance, fill=Species)) +
  geom_col(position="stack") + 
  facet_grid(pcr_primers~type, scales="free") +
  scale_y_continuous(labels = scales::percent) +
  coord_flip()+
  base_theme+
  scale_fill_manual(values=colour.pal)  +
  theme(legend.position = "bottom") +
  labs(x = "Sample Name",
       y= "Relative abundance",
       fill="Species")

gg.syn

# Calculate index switching from syns that are outside positive controls, and non-syns within the positive controls
pos_switchrate <- ps %>%
  speedyseq::psmelt() %>%
  mutate(Species = Species %>% str_replace("_", " ")) %>%
  mutate(switched = case_when(
    type=="POS" & Species %in% Syn_taxa  ~ "TP",
    type=="POS" & !Species %in% Syn_taxa  ~ "FP",
    !type=="POS" & Species %in% Syn_taxa  ~ "FP",
    !type=="POS" & !Species %in% Syn_taxa  ~ "TP"
  )) %>%
  group_by(switched, fcid) %>%
  summarise(Abundance = sum(Abundance)) %>%
  ungroup() %>%
  mutate(total = sum(Abundance)) %>%
  dplyr::filter(switched == "FP") %>%
  mutate(switchrate = Abundance / total)
  
pos_switchrate

```

# Mock community

From the use of the mock community we can see that the majority cross contamination must have come from DNA extraction and prior processes. Therefore we will also get an estimate 

```{r switch mocks}
ps1 <- readRDS("output/rds/ps1.rds")

# Subset to mocks
ps_model <- ps1

tax_table(ps_model)[,8] <- tax_table(ps_model)[,8]%>%
  str_replace("Drosophila albomicans", "Drosophila immigrans") %>%
  str_replace("Drosophila nasuta", "Drosophila immigrans") %>%
  str_replace("Drosophila hypocausta", "Drosophila immigrans") %>%
  str_replace("Drosophila pulaua", "Drosophila immigrans") %>%
  str_replace("Drosophila kohkoa", "Drosophila immigrans") %>%
  str_replace("Drosophila rubida", "Drosophila immigrans") %>%
  str_replace("Drosophila sulfurigaster", "Drosophila immigrans") %>%
  str_replace(" ", "_")

ps_model <- ps_model %>%
  speedyseq::tax_glom(taxrank = "Species") %>%
  filter_taxa( function(x) mean(x) > 0, TRUE) 

exp <- read_csv("sample_data/expected_quant_merged.csv") %>%
  dplyr::rename(sample_name = Sample) %>%
  pivot_longer(-sample_name,
               names_to= "taxon",
               values_to= "expected") %>%
  mutate(taxon = str_replace(taxon, pattern=" ",replacement="_"),
         sample_name = str_remove(sample_name, "-exp*.$")) %>%
  dplyr::filter(!is.na(sample_name),
  !str_detect(sample_name, "CM[0-9]|CT[0-9]|CML[0-9]|Syn"),
  expected > 0) %>%
  distinct()

# Merge replicates and get observed
sam1 <- speedyseq::psmelt(ps_model) %>%
  janitor::clean_names() %>%
  mutate(taxon = species) %>%
  filter(abundance > 0 ) %>%
  filter(!str_detect(taxon, "__")) %>%
  filter(fcid %in% c("CB3DR", "HLVKYDMXX"))  %>%
  dplyr::select(otu, sample_name, extract_id, sample_id, taxon, pcr_primers,fcid, material_type = type, abundance) %>%
  distinct()  %>%
  mutate(taxon = taxon %>% str_replace(" ", "_")) %>%
  mutate(sample_name = sample_name %>%
           str_remove_all("BF1-BR1-|SauronS878-HexCOIR4-|fwhF2-HexCOIR4-|fwhF2-fwhR2n-") %>%
           str_remove_all("HLVKYDMXX_|CK3HD_|CB3DR_|CJKFJ_"),
         sample_id = paste0(fcid, "_", sample_name),
         sample_name = sample_name %>%
           str_remove("-ex[0-9]"))  %>%
group_by(otu, sample_name,sample_id, taxon, pcr_primers, fcid, material_type, n_rep, n_extract) %>%
  summarise(abundance = sum(abundance)) %>% 
  ungroup()

repcounts <- sam1 %>%
 # filter(abundance > 0) %>% 
  group_by(sample_name, otu, fcid) %>%
  mutate(
    n_extract = case_when( # Need this to only count reps they were detected in!
    abundance > 0 ~ extract_id,
    TRUE ~ as.character(NA)
  ),
    n_rep = case_when(
    abundance > 0 ~ sample_id,
    TRUE ~ as.character(NA)
  )) %>%
  summarise(n_extract = n_distinct(n_extract, na.rm = TRUE), n_rep = n_distinct(n_rep, na.rm = TRUE)) 

sam <- sam1%>%
  left_join(repcounts)


#Join tables 
mocks <- sam %>%
  filter(sample_name %in% exp$sample_name,
         material_type =="DrosMock") %>%
  left_join(exp, by = c("sample_name","taxon")) %>%
  mutate(outcome = case_when(
    abundance > 0 & is.na(expected) ~ "FP",
    abundance > 0 & !is.na(expected) ~ "TP",
    abundance == 0 & expected > 0 ~ "FN"
  )) %>%
  filter(!is.na(outcome))%>%
  mutate(outcome = case_when(
    outcome == "FP" & abundance > 10000 ~ as.character(NA), #Deal with obvious misannotated expecteds
    TRUE ~ outcome
  )) 

#Make a heatmap
#Run CB3DR
group.colors <- c(TP = "#abdda4", FP = "#d7191c", FN ="#2b83ba")
mocks %>%
  filter(fcid=="CB3DR") %>%
  group_by(sample_id, pcr_primers) %>%
  mutate_at(vars(abundance), ~ . / sum(.) ) %>% #Convert to proportions
  mutate(label = percent(abundance %>% round(2)) %>%
          str_replace("^0.00%|^0.0%", "< 0.0%")) %>%
  ungroup()  %>%
  ggplot(aes(x=sample_id, y=taxon)) + 
  geom_tile(aes(fill = outcome), alpha=0.8) +
  geom_text(aes(label = label)) +
  base_theme +
  scale_fill_manual(values=group.colors)+ 
  facet_grid(fcid~pcr_primers, scales="free", drop=TRUE) +
  labs(x = "Sample",
       y = "Taxon",
       title = "CB3DR") +
  theme(legend.position = "bottom")

#Run HLVKYDMXX
gg.assignments <- mocks %>%
  filter(fcid=="HLVKYDMXX") %>%
  group_by(sample_id, pcr_primers) %>%
  mutate_at(vars(abundance), ~ . / sum(.) ) %>% #Convert to proportions
  mutate(label = percent(abundance %>% round(2)) %>%
           str_replace("^0.00%|^0.0%", "< 0.0%")) %>%
  ungroup()  %>%
  ggplot(aes(x=sample_id, y=taxon)) + 
  geom_tile(aes(fill = outcome), alpha=0.8) +
  geom_text(aes(label = label)) +
  base_theme +
  scale_fill_manual(values=group.colors)+
  labs(x = "Sample",
       y = "Taxon",
       title = "HLVKYDMXX") +
  theme(legend.position = "bottom")

#Calculate switchrate
mock_switchrate <- mocks %>%
  group_by(fcid, outcome) %>%
  summarise(reads = sum(abundance))%>% 
  pivot_wider(names_from = outcome,
              values_from = reads) %>%
  mutate(switchrate = FP/TP) %>%
  dplyr::select(fcid, FP, TP, switchrate)

mock_switchrate 
```

# Logistic regression

```{r logistic regression}
# Merge replicates and get observed
sam1 <- speedyseq::psmelt(ps_model) %>%
  janitor::clean_names() %>%
  mutate(taxon = species) %>%
  filter(fcid %in% c("CB3DR", "HLVKYDMXX"))  %>%
  group_by(sample_id,fcid, pcr_primers)  %>%
  dplyr::mutate(abundance_RA = abundance, total_seq = sum(abundance)) %>%
  #mutate(abundance_RA = abundance_RA + 0.5) %>% # Add pseudocount
  mutate_at(vars(abundance_RA), ~ . / sum(.) ) %>%
  group_by(sample_id, fcid, pcr_primers)  %>%
  mutate(abundance_clr = abundance_RA) %>%
  mutate_at(vars(abundance_clr ), ~metacal::clr(.) ) %>%
  ungroup() %>%
  dplyr::select(otu, sample_name, extract_id, sample_id, taxon, pcr_primers,fcid, material_type = type, abundance, abundance_RA, abundance_clr,total_seq) %>%
  distinct() 

repcounts <- sam1 %>%
 # filter(abundance > 0) %>% 
  group_by(sample_name, otu, fcid) %>%
  mutate(
    n_extract = case_when( # Need this to only count reps they were detected in!
    abundance > 0 ~ extract_id,
    TRUE ~ as.character(NA)
  ),
    n_rep = case_when(
    abundance > 0 ~ sample_id,
    TRUE ~ as.character(NA)
  )) %>%
  summarise(n_extract = n_distinct(n_extract, na.rm = TRUE), n_rep = n_distinct(n_rep, na.rm = TRUE)) 

sam <- sam1%>%
  left_join(repcounts)%>%
  mutate(taxon = taxon %>% str_replace(" ", "_")) %>%
  mutate(sample_id = sample_name,
         sample_name = sample_name %>%      
         str_remove_all("BF1-BR1-|SauronS878-HexCOIR4-|fwhF2-HexCOIR4-|fwhF2-fwhR2n-") %>%
         str_remove_all("HLVKYDMXX_|CK3HD_|CB3DR_|CJKFJ_")) %>%
  group_by(otu, sample_name, sample_id, taxon, pcr_primers, fcid, material_type, n_rep, n_extract) %>%
  summarise(abundance = sum(abundance), abundance_RA = mean(abundance_RA), abundance_clr = mean(abundance_clr), total_seq = sum(total_seq)) %>%   
  ungroup() %>%
 filter(abundance > 0)

# Create model dataset
mock_dat <- sam %>%
  filter(sample_name %in% exp$sample_name,
         material_type =="DrosMock") %>%
  left_join(exp, by = c("sample_name","taxon")) %>%
  mutate(outcome = case_when(
    abundance > 0 & is.na(expected) ~ 0, #False positive
    abundance > 0 & !is.na(expected) ~ 1, # True positive
    abundance == 0 & expected > 0 ~ 1, # False negative
    abundance ==0 & is.na(expected) ~ 0 # True negative
  )) %>%
  filter(!is.na(outcome))%>%
  group_by(sample_id, pcr_primers, fcid) %>%
  dplyr::mutate(abundance_RA = abundance) %>%
  #mutate(abundance_RA = abundance_RA + 0.5) %>% # Add pseudocount
  mutate_at(vars(abundance_RA), ~ . / sum(.) ) %>%
  mutate(abundance_clr = abundance_RA) %>%
  mutate_at(vars(abundance_clr ), ~seqateurs::clr(.) ) %>%
  ungroup() %>%
  dplyr::select(fcid, sample_id, sample_name, taxon, abundance, abundance_RA, abundance_clr, outcome, n_rep, n_extract) %>%
  mutate(outcome = case_when(
    outcome == 0 & abundance_RA > 0.01 ~ as.numeric(NA), #Deal with any obvious misannotated expected
    outcome == 1 & abundance == 0 ~ as.numeric(NA), #Deal with complete dropouts
    TRUE ~ outcome
  )) %>%
  filter(!is.na(outcome)) %>%
  mutate(outcome = as.factor(outcome)) 
  

# Check for difference in distribution
gg.bias_sep <- mock_dat %>%
  ggplot(aes(x = abundance_RA, fill = as.factor(outcome))) +
  geom_histogram(position = "identity", alpha = 0.7) +
  #facet_grid(fcid, scales="free") + 
  base_theme+
  scale_x_log10()+
  theme(legend.position = "right") + 
  labs(
    x = "log(Abundance)",
    y = "Number of occurances",
    fill = "Outcome"
  )

gg.bias_sep
#Looks like there is enough separation to predict it

# Look at overall numbers of events
mock_dat %>%
  group_by(fcid, outcome) %>%
  summarise(count = n()) %>%
  ggplot(aes(x = outcome, y=count, fill=outcome)) +
  geom_col() + 
  facet_grid(~fcid) +
  base_theme  

# Create dataset split
set.seed(seed = 66) #245

mock_split <- initial_split(mock_dat, strata = outcome, prop=0.8)
mock_train <- training(mock_split)
mock_test <- testing(mock_split)

# Cross validations
#mock_cv <-  group_vfold_cv(data = mock_train, group = sample_id, strata = fcid, v = 10)
mock_cv <- vfold_cv(mock_train, v = 10)

# Create modelling recipe
switch_recipe <- recipe(outcome ~ abundance_RA + fcid, data = mock_train) %>%
  #update_role(sample_id, sample_name,fcid, taxon, new_role = "ID") %>%
  step_novel(all_nominal(), -all_outcomes()) %>% 
  step_dummy(fcid, one_hot = FALSE) %>% 
  #themis::step_upsample(outcome) %>%
  step_zv(all_predictors()) %>%
  step_log(abundance_RA, base=10, offset = 0.00001) %>%
  step_normalize(abundance_RA) 

# Define model
glm_spec <- logistic_reg() %>% 
  set_mode("classification") %>% 
  set_engine("glm") 

# Create workflow
glm_wf <- workflow() %>%
  add_recipe(switch_recipe) %>%
  add_model(glm_spec)

# Fit workflow
logistic_glm <- glm_wf  %>%
  fit(mock_train)

logistic_glm_resamp <- fit_resamples(glm_wf, resamples = mock_cv)%>% 
  unnest(.metrics)%>%
  filter(.metric == "roc_auc")

# See how it went on the trainigng dataset
predictions_glm <- logistic_glm %>%
  predict(new_data = mock_train) %>%
  bind_cols(bake(prep(switch_recipe), new_data =  mock_train))

# Get importance of predictors
logistic_glm  %>%
  pull_workflow_fit()%>%
  vip::vi() %>%
  group_by(Sign) %>%
  top_n(20, wt = abs(Importance)) %>%
  ungroup() %>%
  mutate(
    Importance = abs(Importance),
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  ggplot(aes(x = Importance, y = Variable, fill = Sign)) +
  geom_col(show.legend = FALSE) +
  labs(y = NULL)

#Predict test dataset
predictions_glm <- logistic_glm %>%
  predict(new_data = mock_test) %>%
  bind_cols(mock_test) %>%
  mutate(outcome = as.factor(outcome))

# Confusion matrix
gg.conf_matrix <- predictions_glm %>%
  conf_mat(outcome, .pred_class) %>%
  pluck(1) %>%
  as_tibble() %>%
  ggplot(aes(Prediction, Truth, alpha = n)) +
  geom_tile(show.legend = FALSE) +
  geom_text(aes(label = n), colour = "white", alpha = 1, size = 8)

gg.conf_matrix

# Calculate metrics
multimetric <- metric_set(accuracy, bal_accuracy, sens, yardstick::spec, precision, recall, ppv, npv)
multimetric(predictions_glm, truth = outcome, estimate = .pred_class)  

# Check for disagreements within mock
test <- predictions_glm %>%
  dplyr::select(.pred_class, abundance_clr,abundance, abundance_RA, sample_id,  taxon, outcome)  %>%
  mutate(diff = !.pred_class == outcome)

# Make an ROC curve
## get probabilities on test set
predictions_prob <- logistic_glm %>%
  predict(new_data = mock_test, type="prob") %>%
  bind_cols(bake(prep(switch_recipe), new_data =  mock_test))

# plot curve
gg.roc_curve <- roc_curve(predictions_prob, truth = outcome, .pred_0) %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity)) +
  geom_path() +
  geom_abline(lty = 3) + 
  coord_equal()

gg.roc_curve
```


# Logistic Regression + Replicates

```{r logistic regression with replicates}
# Create modelling recipe
switch_recipe_reps <- recipe(outcome ~ abundance_RA + fcid + n_extract + n_rep, data = mock_train) %>%
  #update_role(sample_id, sample_name,fcid, taxon, new_role = "ID") %>%
  step_novel(all_nominal(), -all_outcomes()) %>% 
  step_dummy(fcid, one_hot = FALSE) %>% 
  #themis::step_upsample(outcome) %>%
  step_zv(all_predictors()) %>%
  step_log(abundance_RA, base=10, offset = 0.0001) %>%
  step_normalize(n_rep, n_extract, abundance_RA) 


juice(prep(switch_recipe_reps))

# Define model
glm_spec <- logistic_reg() %>%  #penalty = tune(), mixture = tune()
  set_mode("classification") %>% 
  set_engine("glm") 

# Create workflow
glm_reps_wf <- workflow() %>%
  add_recipe(switch_recipe_reps) %>%
  add_model(glm_spec)

# Tune workflow
#Tune grid using a latin hypercube design
#cv <- vfold_cv(mock_train, v = 5) # Should i do group to ensure samples are kept together?
#
#glm_tune <- tune_grid(glm_reps_wf, resamples = cv, grid = 20)
#tune_res <- collect_metrics(glm_tune)
#
#autoplot(glm_tune)
#
#glm_reps_wf_tuned <- finalize_workflow(glm_reps_wf, glm_tune %>% select_best("roc_auc"))

glm_reps_wf_tuned <- glm_reps_wf 

# Fit workflow
logistic_glm_reps <- glm_reps_wf_tuned  %>%
  fit(mock_train)

logistic_glm_reps_resamp <- fit_resamples(logistic_glm_reps, resamples = mock_cv) %>% 
  unnest(.metrics)%>%
  filter(.metric == "roc_auc")

# See how it went on the training dataset
predictions_glm <- logistic_glm_reps %>%
  predict(new_data = mock_train) %>%
  bind_cols(bake(prep(switch_recipe), new_data =  mock_train))

# Get importance of predictors
logistic_glm_reps  %>%
  pull_workflow_fit()%>%
  vip::vi() %>%
  group_by(Sign) %>%
  top_n(20, wt = abs(Importance)) %>%
  ungroup() %>%
  mutate(
    Importance = abs(Importance),
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  ggplot(aes(x = Importance, y = Variable, fill = Sign)) +
  geom_col(show.legend = FALSE) +
  labs(y = NULL)

#Predict test dataset
predictions_glm <- logistic_glm_reps %>%
  predict(new_data = mock_test) %>%
  bind_cols(mock_test) %>%
  mutate(outcome = as.factor(outcome))

# Confusion matrix
gg.conf_matrix <- predictions_glm %>%
  conf_mat(outcome, .pred_class) %>%
  pluck(1) %>%
  as_tibble() %>%
  ggplot(aes(Prediction, Truth, alpha = n)) +
  geom_tile(show.legend = FALSE) +
  geom_text(aes(label = n), colour = "white", alpha = 1, size = 8)

gg.conf_matrix

# Calculate metrics
multimetric <- metric_set(accuracy, bal_accuracy, sens, yardstick::spec, precision, recall, ppv, npv)
multimetric(predictions_glm, truth = outcome, estimate = .pred_class)  

# Check for disagreements within mock
test <- predictions_glm %>%
  dplyr::select(.pred_class, abundance_clr, abundance_RA, abundance, sample_id, n_rep, n_extract, taxon, outcome)  %>%
  mutate(diff = !.pred_class == outcome)

# Make an ROC curve
## get probabilities on test set
predictions_prob <- logistic_glm_reps %>%
  predict(new_data = mock_test, type="prob") %>%
  bind_cols(bake(prep(switch_recipe), new_data =  mock_test))

# plot curve
gg.roc_curve <- roc_curve(predictions_prob, truth = outcome, .pred_0) %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity)) +
  geom_path() +
  geom_abline(lty = 3) + 
  coord_equal()

gg.roc_curve
```


# Random forest + Replicates

```{r logistic regression with replicates}
# Create modelling recipe
rf_recipe <- recipe(outcome ~ abundance_RA + abundance + fcid + n_extract + n_rep, data = mock_train) %>%
  #update_role(sample_id, sample_name,fcid, taxon, new_role = "ID") %>%
  step_novel(all_nominal(), -all_outcomes()) %>% 
  step_dummy(fcid, one_hot = FALSE) %>% 
  #themis::step_upsample(outcome) %>%
  step_zv(all_predictors()) %>%
  step_log(abundance_RA, base=10, offset = 0.0001) %>%
  step_normalize(all_numeric()) 

juice(prep(rf_recipe))

# Define model
rf_spec <- rand_forest(
  mtry = tune(),
  trees = 1000,
  min_n = tune()
) %>%
  set_mode("classification") %>%
  set_engine("ranger", importance = "impurity")

# Create workflow
rf_wf <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(rf_spec)

# Tune workflow
#Tune grid using a latin hypercube design

rf_tune <- tune_grid(rf_wf, resamples = mock_cv, grid = 20)
tune_res <- collect_metrics(rf_tune)

autoplot(rf_tune)
#
rf_wf_tuned <- finalize_workflow(rf_wf, rf_tune %>% select_best("roc_auc"))

rf_resamp <- fit_resamples(rf_wf_tuned, resamples = mock_cv) %>% 
  unnest(.metrics) %>%
  filter(.metric == "roc_auc")

# Fit workflow
rf_reps <- rf_wf_tuned  %>%
  fit(mock_train)

# See how it went on the training dataset
predictions_rf <- rf_reps %>%
  predict(new_data = mock_train) %>%
  bind_cols(bake(prep(switch_recipe), new_data =  mock_train))

# Get importance of predictors
rf_reps  %>%
  pull_workflow_fit()%>%
  vip::vi() %>%
  #group_by(Sign) %>%
  top_n(20, wt = abs(Importance)) %>%
  ungroup() %>%
  mutate(
    Importance = abs(Importance),
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  ggplot(aes(x = Importance, y = Variable)) +
  geom_col(show.legend = FALSE) +
  labs(y = NULL)

#Predict test dataset
predictions_rf <- rf_reps %>%
  predict(new_data = mock_test) %>%
  bind_cols(mock_test) %>%
  mutate(outcome = as.factor(outcome))

# Confusion matrix
gg.conf_matrix <- predictions_rf %>%
  conf_mat(outcome, .pred_class) %>%
  pluck(1) %>%
  as_tibble() %>%
  ggplot(aes(Prediction, Truth, alpha = n)) +
  geom_tile(show.legend = FALSE) +
  geom_text(aes(label = n), colour = "white", alpha = 1, size = 8)

gg.conf_matrix

# Calculate metrics
multimetric <- metric_set(accuracy, bal_accuracy, sens, yardstick::spec, precision, recall, ppv, npv)
multimetric(predictions_rf, truth = outcome, estimate = .pred_class)  

# Check for disagreements within mock
test <- predictions_rf %>%
  dplyr::select(.pred_class, abundance_clr, abundance_RA, abundance, sample_id,  taxon, outcome)  %>%
  mutate(diff = !.pred_class == outcome)

# Make an ROC curve
## get probabilities on test set
predictions_prob <- logistic_glm_reps %>%
  predict(new_data = mock_test, type="prob") %>%
  bind_cols(bake(prep(switch_recipe), new_data =  mock_test))

# plot curve
gg.roc_curve <- roc_curve(predictions_prob, truth = outcome, .pred_0) %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity)) +
  geom_path() +
  geom_abline(lty = 3) + 
  coord_equal()

gg.roc_curve
```

# Model comparison

```{R comparison}
# Fit model to bootstrap resamples
#set.seed(556)
set.seed(123)
boots <- bootstraps(mock_dat, times = 1000, strata=fcid, apparent = FALSE)

fit_boots <- boots %>%
  mutate(
    pred_logit = purrr::map(splits, function(x){
      fits <- fit(glm_wf, analysis(x))
      bind_cols(
        assessment(x), 
        predict(fits, assessment(x))) %>%
      mutate(filtered = case_when(
                       .pred_class == 1 ~ abundance_RA,
                       .pred_class == 0 ~ 0)
                     ) %>%
        dplyr::select(fcid, sample_id, sample_name, taxon ,abundance,
                      abundance_RA, abundance_clr, outcome, filtered)
    }),
    pred_logit_reps = purrr::map(splits, function(x){
      fits <- fit(glm_reps_wf_tuned, analysis(x))
      bind_cols(
        assessment(x), 
        predict(fits, assessment(x))) %>%
      mutate(filtered = case_when(
                       .pred_class == 1 ~ abundance_RA,
                       .pred_class == 0 ~ 0)
                     ) %>%
        dplyr::select(fcid, sample_id, sample_name, taxon ,abundance, 
                      abundance_RA, abundance_clr, outcome, filtered)
      }),
    pred_rf = purrr::map(splits, function(x){
      fits <- fit(rf_wf_tuned, analysis(x))
      bind_cols(
        assessment(x), 
        predict(fits, assessment(x))) %>%
      mutate(filtered = case_when(
                       .pred_class == 1 ~ abundance_RA,
                       .pred_class == 0 ~ 0)
                     ) %>%
        dplyr::select(fcid, sample_id, sample_name, taxon ,abundance, 
                      abundance_RA, abundance_clr, outcome, filtered)
      }),
    pred_pos = purrr::map(splits, function(x){
      assessment(x) %>%
        left_join(
          pos_switchrate%>%
          dplyr::select(fcid, estimate = switchrate) 
        ) %>%
        mutate(filtered = abundance_RA - estimate)%>%
        dplyr::select(fcid, sample_id, sample_name, taxon ,abundance, abundance_RA, outcome, filtered)
    }),
    pred_mock = purrr::map(splits, function(x){
      assessment(x) %>%
        left_join(
          analysis(x) %>%
          group_by(fcid, outcome) %>%
          summarise(reads = sum(abundance))%>% 
          pivot_wider(names_from = outcome,
                      values_from = reads) %>%
          mutate(switchrate = `0`/`1`) %>%
          dplyr::select(fcid, estimate = switchrate) 
        ) %>%
        mutate(filtered = abundance_RA - estimate) %>%
        dplyr::select(fcid, sample_id, sample_name, taxon ,abundance, abundance_RA, outcome, filtered)

    }),
    pred_naive = purrr::map(splits, function(x){
      assessment(x) %>%
        mutate(estimate = 0.001) %>%
        mutate(filtered = abundance_RA - estimate)%>%
        dplyr::select(fcid, sample_id, sample_name, taxon ,abundance,
                      abundance_RA, abundance_clr, outcome, filtered)
      }),
    pred_uncorrected = purrr::map(splits, function(x){
      assessment(x) %>%
        mutate(filtered = abundance_RA)%>%
        dplyr::select(fcid, sample_id, sample_name, taxon ,abundance,
                      abundance_RA, abundance_clr, outcome, filtered)
      }),
    pred_index = purrr::map(splits, function(x){
      assessment(x) %>%
        left_join(
          switch_summary %>%
          dplyr::select(fcid, estimate = switchrate) 
        ) %>%
        mutate(filtered = abundance_RA - estimate)%>%
        dplyr::select(fcid, sample_id, sample_name, taxon ,abundance,
                      abundance_RA, abundance_clr, outcome, filtered)
      })
  )

pred_boots <- fit_boots %>%
  pivot_longer(starts_with("pred_"),
               names_to = "est_type",
               values_to = "estimate") %>%
  unnest(estimate) %>%
  left_join(exp) %>%
  dplyr::select(-where(~is.list(.x))) %>%
  mutate(outcome_post= case_when(
    filtered > 0 & is.na(expected) ~ "False Positive",
    filtered > 0 & !is.na(expected) ~ "True Positive",
    filtered <= 0 & expected > 0 ~ "False Negative",
    filtered <= 0 & is.na(expected) ~ as.character(NA)
  )) %>%
  filter(!is.na(outcome_post))

#saveRDS(pred_boots, file="output/index_switch_bootstraps.rds")

group.colors <- c(`True Positive` = "#abdda4", `False Positive` = "#d7191c", `False Negative` ="#2b83ba", `True Negative` ="#cccccc")

gg.bias_resolved <- pred_boots %>%
  filter(!(fcid %in% c("CB3DR", "CK3HD") & est_type == "pred_pos")) %>%
  group_by(est_type, outcome_post, fcid) %>%
  summarise(count = n(), count_fp = sum(outcome_post == "FP")) %>%
  group_by(est_type, fcid) %>%
  mutate_at(vars(count), ~ . / sum(.) ) %>%
  mutate(est_type = est_type %>%
           str_replace("pred_logit$", "Logistic Reg") %>%
           str_replace("pred_logit_reps$", "Logistic Reg + Reps") %>%
           str_replace("pred_rf", "Random Forest") %>%
           str_replace("pred_mock", "Mock Communities") %>%
           str_replace("pred_naive", "0.01% Threshold") %>%
           str_replace("pred_pos", "Positive control") %>%
           str_replace("pred_uncorrected", "Uncorrected") %>%
           str_replace("pred_index", "Unassigned indices")
         ) %>%
  mutate(fcid = case_when(
    fcid == "HLVKYDMXX" ~ "NovaSeq",
    TRUE ~ "MiSeq",
  )) %>%
  mutate(est_type = factor(est_type,
                           levels= c(
    "Logistic Reg + Reps",
    "Logistic Reg",
    "Random Forest",
    "Mock Communities",
    "Positive control",
    "Unassigned indices",
    "0.01% Threshold",
    "Uncorrected"))) %>%
  ggplot(aes(x=est_type, y=count, fill=outcome_post)) + 
  geom_col(position="stack", alpha = 0.8) +
  base_theme+
  coord_flip()+
  facet_grid(fcid~.) +
  scale_y_continuous(labels = scales::percent)+ 
  scale_fill_manual(values=group.colors) + 
  theme(legend.position = "bottom") +
  labs(y = NULL,
       x = NULL,
       fill = "Outcome")

gg.bias_resolved
```

# Save figures

```{R save figures}
pdf(file="fig/supplementary/switching.pdf", width = 11, height = 8 , paper="a4r")
  plot(gg.switch)
  plot(gg.assignments)
  plot(gg.bias_sep)
  plot(gg.conf_matrix)
  plot(gg.roc_curve)
  plot(gg.bias_resolved)
try(dev.off(), silent=TRUE)

```
