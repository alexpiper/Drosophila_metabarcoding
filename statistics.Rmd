---
title: "Statistics"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

# Introduction

## Analysis structure

Part 1 - Cleanup & Filtering of index switching

Part 1 - Comparison of 4 primers for bias and detection efficiency
(figure 1)

Part 2 - Comparison of bias between 3 tagged primers

Part 3 - Comparison 


## Load packages
```{r setup}
#Set required packages
.cran_packages <- c("tidyverse",
                    "tidymodels",
                    "patchwork", 
                    "vegan", 
                    "seqinr",
                    "ape", 
                    "RColorBrewer",
                    "ggtree", 
                    "castor", 
                    "picante",
                    "skimr",
                    "devtools")
.bioc_packages <- c("dada2",
                    "phyloseq", 
                    "DECIPHER",
                    "Biostrings",
                    "ShortRead", 
                    "philr",
                    "ALDEx2")

.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install(.bioc_packages[!.inst], ask = F)
}

sapply(c(.cran_packages,.bioc_packages), require, character.only = TRUE)

# Github packages
devtools::install_github("alexpiper/taxreturn")
devtools::install_github("alexpiper/seqateurs")
devtools::install_github("mikemc/speedyseq")
devtools::install_github('ggloor/CoDaSeq/CoDaSeq')
devtools::install_github("mikemc/metacal")

library(speedyseq)
library(taxreturn)
library(seqateurs)
library(CoDaSeq)
library(metacal)

#Source internal functions
source('R/helper_functions.R')
options(stringsAsFactors = FALSE)
```


## Define themes

```{R theme}
library(ggthemes)
base_theme <- theme_tufte() + 
    theme(
        text = element_text(size=9, family = ""),
        strip.text = element_text(size=9, family = ""),
        # axis.text = element_text(size=8, family = ""),
        legend.position = "none"
        )

# Would be nice to modify the strip labels a bit more
```
## Make Phyloseq object

```{r create PS, eval = FALSE}
seqtab <- readRDS("output/rds/seqtab_final.rds")

# Add FCID to run 1 samples
rownames(seqtab)[!str_detect(rownames(seqtab), "Rep") ] <- paste0("CB3DR_", rownames(seqtab)[!str_detect(rownames(seqtab), "Rep") ])

# Add FCID to run2 samples
rownames(seqtab)[str_detect(rownames(seqtab), "Rep") & 
                   !str_detect(rownames(seqtab), "HLVKYDMXX") & 
                   !str_detect(rownames(seqtab), "DL|CL")] <- paste0("CK3HD_", rownames(seqtab)[str_detect(rownames(seqtab), "Rep") & 
                   !str_detect(rownames(seqtab), "HLVKYDMXX") & 
                   !str_detect(rownames(seqtab), "DL|CL")])

	
# Add FCID to run 3 samples
rownames(seqtab)[str_detect(rownames(seqtab), "Rep") & 
                   !str_detect(rownames(seqtab), "HLVKYDMXX") & 
                   str_detect(rownames(seqtab), "DL|CL")] <- paste0("CJKFJ_", rownames(seqtab)[str_detect(rownames(seqtab), "Rep") & 
                   !str_detect(rownames(seqtab), "HLVKYDMXX") & 
                   str_detect(rownames(seqtab), "DL|CL")])

#Reformat sample IDs
rownames(seqtab)  <- rownames(seqtab) %>%
  str_remove("\\..*$") %>%
  str_replace("\\_S[0-9].*\\_...", replacement="_") %>%
  str_replace("_$", "_1") %>%
  str_replace("1in10", "1:10")

tax <- readRDS("output/rds/tax_IdTaxaExact.rds") 
seqs <- DNAStringSet(colnames(seqtab))
names(seqs) <- seqs
phy <- readRDS("output/rds/phytree.rds")$tree


##### Rename problematic samples
#Could do this with the new dplyr functionality
rownames(seqtab)  <- rownames(seqtab) %>%
 str_replace_all("D250M1-", "D250M4REP-") %>% # Works
 str_replace_all("D250M4-", "D250M2REP-") %>% # Works
 str_replace_all("D250M5-", "D250M3REP-") %>% #FAILED library
 str_replace_all("D250M3-", "D250M1REP-") %>% #FP suzukii - low reads
 str_replace_all("D250M2-", "D250M5REP-") %>% #Works
 str_replace_all("D500M1-", "D500M4REP-") %>% #Works 
 str_replace_all("D500M4-", "D500M1REP-") %>% #FP Suzukii
 str_replace_all("D500M5-", "D500M2REP-") %>% #Works
 str_replace_all("D500M3-", "D500M3REP-") %>% #Works but low reads for Suz + Biarmipes 
 str_replace_all("D500M2-", "D500M5REP-") %>% #Works
 str_replace_all("D1000M1-", "D1000M3REP-") %>% #Works
 str_replace_all("D1000M4-", "D1000M1REP-") %>% #Works
 str_replace_all("D1000M5-", "D1000M2REP-") %>% #Works
 str_replace_all("D1000M3-", "D1000M5REP-") %>% #Works
 str_replace_all("D1000M2-", "D1000M4REP-") %>% #Works
 str_replace_all("CM10-", "CM9REP-") %>%
 str_replace_all("CM11-", "CM10REP-") %>%
 str_replace_all("CM9-", "CM11REP-") %>%
 str_replace_all("CML2-", "CML6REP-")%>%
 str_replace_all("CML3-", "CML2REP-")%>%
 str_replace_all("CML4-", "CML3REP-")%>%
 str_replace_all("CML5-", "CML4REP-")%>%
 str_replace_all("CML6-", "CML5REP-")%>%
 str_replace_all("CT5-", "CT4REP-")%>%
 str_replace_all("CT4-", "CT5REP-") %>%
str_replace_all("REP", "")

#Load sample information
## ---- samdat ----
samdf <- read.csv("sample_data/sample_info.csv", header=TRUE) %>% 
  janitor::clean_names() %>%
  mutate(sample_id = case_when(
    fcid=="HLVKYDMXX" ~ paste0(sample_name, "_", replicate),
    !fcid=="HLVKYDMXX" ~ paste0(fcid, "_", sample_name, "_", replicate)
  ))  %>%
  filter(!(index=="ATCGATCG" & index2=="ATCACACG"), #CT11-ex1 duplicated
         !(index=="TCGCTGTT" & index2=="ACTCCATC") # CT12-ex1 duplicated
         ) %>%
  filter(!fcid=="CK3HD") %>%
  mutate(type = case_when(
    str_detect(sample_id, "D[0-9][0-9][0-9]M|D[0-9][0-9][0-9][0-9]M|DM[0-9]")  ~ "DrosMock",
    str_detect(sample_id, "SPD")  ~ "SPD",
    str_detect(sample_id, "ACV")  ~ "ACV",
    str_detect(sample_id, "DC")  ~ "DC",
    str_detect(sample_id, "Sach")  ~ "Sachet",
    str_detect(sample_id, "FF")  ~ "FF",
    str_detect(sample_id, "NTC")  ~ "NTC",
    str_detect(sample_id, "DLarv")  ~ "DrosLarv",
    str_detect(sample_id, "POS|SynMock")  ~ "POS",
    str_detect(sample_id, "extblank|BLANK")  ~ "Extblank",
    str_detect(sample_id, "pcrblank")  ~ "PCRblank",
    str_detect(sample_id, "CT")  ~ "CarpTrap",
    str_detect(sample_id, "CM[0-9]")  ~ "CarpMock",
    str_detect(sample_id, "CML[0-9]")  ~ "CarpLarval"
  )) %>%
  mutate(target_subfragment = case_when(
    str_detect(fprimer, "GGDACWGGWTGAACWGTWTAYCCHCC") & str_detect(rprimer, "GTRATWGCHCCDGCTARWACWGG") ~ "fwhF2-fwhR2n",
    str_detect(fprimer, "ACWGGWTGRACWGTNTAYCC") & str_detect(rprimer, "ARYATDGTRATDGCHCCDGC") ~ "BF1-BR1",
    str_detect(fprimer, "GGDRCWGGWTGAACWGTWTAYCCNCC") & str_detect(rprimer, "TATDGTRATDGCHCCNGC") ~ "SauronS878-HexCOIR4",
    str_detect(fprimer, "GGDACWGGWTGAACWGTWTAYCCHCC") & str_detect(rprimer, "TATDGTRATDGCHCCNGC") ~ "fwhF2-HexCOIR4",
  )) %>%
  magrittr::set_rownames(.$sample_id)

# Will probably need to rename the seqtabs and append the flowcell number onto the samples before they are merged

## ---- phyloseq ----
ps <- phyloseq(tax_table(tax), 
               sample_data(samdf),
               otu_table(seqtab, taxa_are_rows = FALSE),
               phy_tree(phy),
               refseq(seqs))

if(nrow(seqtab) > nrow(sample_data(ps))){warning("Warning: All samples not included in phyloseq object, check sample names match the sample metadata")}

rownames(samdf)[which(!rownames(sample_data(ps))  %in% rownames(samdf))]
rownames(sample_data(ps))[which(!rownames(samdf)  %in% rownames(sample_data(ps)))]

# Rename all taxa
taxa_names(ps) <- paste0("SV", seq(ntaxa(ps)),"-",tax_table(ps)[,7])

saveRDS(ps, "output/rds/ps_idtaxaExact.rds") 

#Rename synthetic orders
tax_table(ps)[,2][which(str_detect(tax_table(ps)[,7], "Synthetic"))] <- "Arthropoda"

#Subset to Drosophila (Remove carpophilus)
ps <- ps %>%
  subset_samples(!str_detect(sample_name, "CM[0-9]|CT[0-9]|CML[0-9]")
  ) %>%
  subset_taxa(Phylum == "Arthropoda") %>%
  filter_taxa( function(x) mean(x) > 0, TRUE) 
dir.create("output/csv")
dir.create("output/csv/unfiltered/")

##Export raw csv
export <- speedyseq::psmelt(ps) %>%
  filter(Abundance > 0)
write.csv(export, file = "output/csv/rawdata.csv")

#Summary export
seqateurs::summarise_taxa(ps, "Species", "sample_name") %>%
  filter(!str_detect(sample_name, "NTC")) %>%
  spread(key="sample_name", value="totalRA") %>%
  write.csv(file = "output/csv/unfiltered/spp_sum.csv")

seqateurs::summarise_taxa(ps, "Genus", "sample_name") %>%
  spread(key="sample_name", value="totalRA") %>%
  write.csv(file = "output/csv/unfiltered/gen_sum.csv")

##Output fasta of all ASV's - Name each one by abundance + taxonomic assignment
seqateurs::ps_to_fasta(ps, "output/all_taxa.fasta")
```


### Summary statistics

```{r sum taxa}
# N unique species and samples
speedyseq::psmelt(ps) %>%
  summarise(n_extracts = n_distinct(sample_name), n_samples = n_distinct(sample_id))

# Spread of reads
speedyseq::psmelt(ps) %>%
  group_by(sample_name) %>%
  summarise(Abundance = sum(Abundance)) %>%
  ungroup() %>%
  summarise(mean = mean(Abundance), 
            se = sd(Abundance)/sqrt(length(Abundance)),
            max = max(Abundance),
            min = min(Abundance))

# Spread of ASVs
speedyseq::psmelt(ps) %>%
  group_by(sample_name) %>%
  dplyr::filter(Abundance > 0) %>%
  summarise(counts = n_distinct(OTU)) %>%
  ungroup() %>%
  summarise(mean = mean(counts), 
            se = sd(counts)/sqrt(length(counts)),
            max = max(counts),
            min = min(counts))

#Fraction of reads assigned to each taxonomic rank
speedyseq::psmelt(ps) %>%
  dplyr::select(rank_names(ps), Abundance) %>%
  pivot_longer(rank_names(ps),
               names_to="rank",
               values_to="name") %>%
  group_by(rank) %>% 
  mutate(name = replace(name, str_detect(name, "__"), NA)) %>% 
  dplyr::summarise(reads_classified = sum(Abundance * !is.na(name))) %>%
  mutate(frac_reads = reads_classified / sum(sample_sums(ps))) %>%
  mutate(rank = factor(rank, rank_names(ps))) %>%
  arrange(rank)

#Fraction of ASV's assigned to each taxonomic rank
tax_table(ps) %>%
  as("matrix") %>%
  as_tibble(rownames="OTU") %>%
    pivot_longer(rank_names(ps),
               names_to="rank",
               values_to="name") %>%
  group_by(rank) %>%
  mutate(name = replace(name, str_detect(name, "__"), NA)) %>% 
  dplyr::summarise(OTUs_classified = sum(!is.na(name))) %>%
  mutate(frac_OTUs = OTUs_classified / ntaxa(ps)) %>%
  mutate(rank = factor(rank, rank_names(ps))) %>%
  arrange(rank)

# Unique taxa at each rank
speedyseq::psmelt(ps) %>%
  dplyr::select(rank_names(ps)) %>%
    pivot_longer(rank_names(ps),
               names_to="rank",
               values_to="name") %>%
  mutate(name = replace(name, str_detect(name, "__"), NA)) %>% 
  drop_na() %>%
  group_by(rank) %>%
  summarise_all(list(n_distinct)) %>%
  mutate(rank = factor(rank, rank_names(ps))) %>%
  arrange(rank)
```


### Prevalence assesment

```{R prevalence}
#Prevalence matrix
prevdf <- ps %>%
    otu_table %>%
  apply(2, function(x) ifelse(x > 0, 1, 0)) %>%
  colSums() %>%
  as.data.frame() %>%
  rownames_to_column("OTU") %>%
  magrittr::set_colnames(c("OTU", "prevalence")) %>%
  left_join(taxa_sums(ps) %>%
              as.data.frame %>%
  rownames_to_column("OTU")%>%
  magrittr::set_colnames(c("OTU", "abundance"))) %>%
  left_join(tax_table(ps)%>%
               as.data.frame %>%
  rownames_to_column("OTU"))
  
#Prevalence plot
gg.prev <- prevdf %>%
  ggplot(aes(x=abundance, y=prevalence / nsamples(ps), colour=Genus)) +
  geom_point(size = 3, alpha = 0.7) +
  scale_x_log10() +
  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Order) +
  base_theme+
  geom_rangeframe(colour="black")+
  theme(legend.position="none") +
  ggtitle("Phylum Prevalence in All Samples\nColored by Order")

gg.prev

pdf(file="fig/prevalence.pdf", width = 11, height = 8 , paper="a4r")
  plot(gg.prev)
try(dev.off(), silent=TRUE)
```

## Taxon filtering

```{R taxon filt}
get_taxa_unique(ps, "Order")

ps # Check the number of taxa prior to removal
ps0 <- ps %>%
  subset_taxa(
    Phylum == "Arthropoda" & 
    Class %in% c("Insecta", "Arachnida", "Collembola")
  )
ps # Confirm that the taxa were removed
get_taxa_unique(ps0, "Phylum")
get_taxa_unique(ps0, "Class")
get_taxa_unique(ps0, "Order")
```

# Filter index switching


# Comparison of 4 primers for detection and bias

# Overview of run 1

```{r run 1 overview}
ps_run1 <- ps0 %>%
  subset_samples(fcid %in% c("CB3DR")) 
ps_run1 <- ps_run1 %>%
  subset_samples(!str_detect(sample_names(ps_run1),"blank")) %>%
  filter_taxa( function(x) mean(x) > 0, TRUE) 

tax_table(ps_run1)[,7][which(tax_table(ps_run1)[,7]=="Carpophilus_dimidiatus/nr.dimidiatus")] <- "Carpophilus_nr.dimidiatus"
tax_table(ps_run1)[,7][which(tax_table(ps_run1)[,7]=="Brachypeplus_Sp1")] <- "Brachypeplus_Sp"
tax_table(ps_run1)[,7][which(tax_table(ps_run1)[,7]=="Brachypeplus_Sp2")] <- "Brachypeplus_Sp"
ps_run1 <- speedyseq::tax_glom(ps_run1, taxrank="Species")

ps_run1 %>% 
  speedyseq::psmelt() %>%
  group_by(sample_id) %>%
  mutate_at(vars(Abundance), ~ . / sum(.) ) %>% #Convert to proportions
  mutate(plotlabel = case_when(
    Abundance >= 0.01  ~ Species, # Change this to whatever taxrank we want
    Abundance < 0.01 ~ as.character(NA)
    )) %>%
  ggplot(aes(x=sample_name, y=Abundance, fill=plotlabel)) +
  geom_col(position="stack") + 
  facet_grid(target_subfragment~type, scales="free") +
  scale_y_continuous(labels = scales::percent) +
  coord_flip()+
  geom_rangeframe() +
  base_theme+
  theme(legend.position = "bottom") +
  labs(x = "Sample Name",
       y= "Relative abundance",
       fill="Species",
       title = "Run 1 - Primer testing")

# Plot as heatmap
ps_run1 %>%
  speedyseq::psmelt() %>%
  group_by(sample_id) %>%
  mutate_at(vars(Abundance), ~ . / sum(.) ) %>%
  mutate(extract_id = str_remove(sample_name, "^.*-D")) %>%
    ggplot(aes(x=extract_id, y=Species, fill=Abundance)) +
    geom_tile() +
    facet_grid(~target_subfragment, scales="free") +
  geom_rangeframe() +
  base_theme+
  theme(axis.text.x = element_text(angle=45, hjust=1),
          legend.position = "bottom") +
    scale_fill_viridis_c(labels = scales::percent) +
    labs(x="Sample",
         y="Taxon",
         fill="Relative abundance",
         title="Run 1 - Primer testing")


#Compositional PCA
pca_dat <- ps_run1 %>% 
  speedyseq::tax_glom("Species") %>%
  otu_table %>%
  as("matrix") %>%
  as.data.frame()  
pca_dat <- pca_dat[,colSums(pca_dat) > 100]
pca_dat <- zCompositions::cmultRepl(t(pca_dat))
pca_dat <- t(codaSeq.clr(pca_dat))

pca <- prcomp(pca_dat)

#Look at contributions to rownames
tidy(pca$rotation) %>%
  pivot_longer(starts_with("PC"),
               names_to = "component",
               values_to="value") %>%
  dplyr::rename(terms = .rownames) %>%
  filter(component %in% paste0("PC",1:5)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(value, terms, fill = terms)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~component, nrow = 1) +
  labs(y = NULL) 

#PCA 

# Get pca data
pca_data <- pca$x %>%
  as_tibble(rownames = "sample_id") %>%
  dplyr::select(1:6)%>%
  left_join(sample_data(ps_run1) %>%
              as("matrix") %>%
  as.data.frame() %>%
    dplyr::select(sample_id, sample_name, type, target_subfragment) %>%
    distinct()) %>%
  mutate(extract_id = sample_name %>%
           str_remove_all("BF1-BR1-|fwhF2-fwhR2n-|SauronS878-HexCOIR4-|fwhF2-HexCOIR4-"))

#Get PCA loadings
pca_loadings <- data.frame(OTU = rownames(pca$rotation), pca$rotation[, 1:2])
mult <- min(
    (max(pca_data$PC1) - min(pca_data$PC1)/(max(pca_loadings$PC1)-min(pca_loadings$PC1))),
    (max(pca_data$PC2) - min(pca_data$PC2)/(max(pca_loadings$PC2)-min(pca_loadings$PC2)))
    )
pca_loadings <- transform(pca_loadings,
        v1 = .7 * mult * (pca_loadings$PC1),
        v2 = .7 * mult * (pca_loadings$PC1)
        )

# calculate percent variance explained for the axis labels
pc1 <- round(pca$sdev[1]^2/sum(pca$sdev^2),2)
pc2 <- round(pca$sdev[2]^2/sum(pca$sdev^2),2)
pc_ylab <- paste("PC1: ", pc1, sep="")
pc_xlab <- paste("PC2: ", pc2, sep="")

# Plot PCA
gg.pca <- ggplot(data=pca_data, aes(x=PC2, y=PC3)) + 
  geom_point(aes(colour = extract_id, shape = target_subfragment), alpha=0.8, size=3) +
  scale_colour_brewer(palette="Paired") +
  geom_hline(yintercept = 0, linetype=2, alpha=0.5) +  
  geom_vline(xintercept = 0, linetype=2, alpha=0.5) +
  xlab(pc_xlab) + 
  ylab(pc_ylab) +
  #Add loadings
  geom_text(data=pca_loadings, aes(x=v1, y=v2, label=OTU), 
            size = 5, vjust=1,hjust=1, color="red", check_overlap = TRUE,
            alpha=0.5)+
  geom_segment(data=pca_loadings, aes(x=0, y=0, xend=v1, yend=v2),
               arrow=arrow(length=unit(0.2,"cm")), alpha=0.5, color="red") +
  base_theme+
  theme(legend.position = "bottom") +
  geom_rangeframe() +
coord_fixed(ratio=pc1/pc2) # Scale plot by variance explained

gg.pca
```
# Heatmap of jaccard simiarity to show all are detected in all samples??

## Effect of primer on bias


```{r Drosophila bias}
# Merge replicates
ps.merged <- ps0 %>%
    merge_samples(group = "sample_name", fun="sum")

#This loses the sample metadata - Need to add it agian
sample_data(ps.merged) <- sample_data(ps0) %>%
  filter(!duplicated(sample_name)) %>%
  magrittr::set_rownames(.$sample_name)

ps_bias <- ps.merged %>%
  filter_taxa( function(x) mean(x) > 0, TRUE) 

tax_table(ps_bias)[,7][which(tax_table(ps_bias)[,7]=="Carpophilus_dimidiatus/nr.dimidiatus")] <- "Carpophilus_nr.dimidiatus"
tax_table(ps_bias)[,7][which(tax_table(ps_bias)[,7]=="Brachypeplus_Sp1")] <- "Brachypeplus_Sp"
tax_table(ps_bias)[,7][which(tax_table(ps_bias)[,7]=="Brachypeplus_Sp2")] <- "Brachypeplus_Sp"
ps_bias <- speedyseq::tax_glom(ps_bias, taxrank="Species")

exp <- read_csv("sample_data/expected_quant_merged.csv") %>%
  dplyr::rename(sample_name = Sample) %>%
  pivot_longer(-sample_name,
               names_to= "taxon",
               values_to= "expected") %>%
  mutate(taxon = str_replace(taxon, pattern=" ",replacement="_"),
         sample_name = str_remove(sample_name, "-exp*.$")) %>%
  dplyr::filter(!is.na(sample_name),
  !str_detect(sample_name, "CM[0-9]|CT[0-9]|CML[0-9]|Syn"),
  expected > 0) %>%
  distinct()

#plot expected
exp %>% 
  group_by(sample_name) %>%
  mutate_at(vars(expected), ~ . / sum(.) ) %>% #Convert to proportions
  ggplot(aes(x=sample_name, y=expected, fill=taxon)) +
  geom_col(position="stack") + 
  scale_fill_brewer(palette="Spectral") +
  scale_y_continuous(labels=scales::percent) +
  geom_rangeframe() +
  base_theme+
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle=45, hjust=1)) +
  labs(x = "Sample Name",
       y= "Relative abundance",
       title="Expected mock communities",
       fill="Species")

#Get observed
sam <- speedyseq::psmelt(ps_bias) %>%
  janitor::clean_names() %>%
  mutate(taxon = species) %>%
  filter(!str_detect(genus, "__")) %>%#Remove unclassified
  dplyr::select(sample_name, taxon, abundance, target_subfragment, fcid, material_type = type) %>%
  mutate(sample_name = sample_name %>%
           str_remove_all("BF1-BR1-|SauronS878-HexCOIR4-|fwhF2-HexCOIR4-|fwhF2-fwhR2n-") %>%
           str_remove("HLVKYDMXX_"),
         sample_id = paste0(fcid, "_", sample_name),
         sample_name = sample_name %>%
           str_remove("-ex[0-9]")) 

#Join tables 
joint <- sam %>%
  filter(taxon %in% exp$taxon,
         sample_name %in% exp$sample_name) %>%
  left_join(exp, by = c("sample_name","taxon")) %>%
  dplyr::rename(observed = abundance) %>%
  mutate(expected = replace_na(expected, 0),
         observed0 = (observed + 0.5) * (expected > 0),
         error = observed0 / expected) %>%
  distinct() %>%
  group_by(sample_id) %>%
  mutate_at(vars(observed, expected), ~ . / sum(.) ) %>% #Convert to proportions
  ungroup()


# Visualise the error in all pairwise ratios
gg.ratio <- joint %>%
  dplyr::filter(expected > 0 ) %>%
  dplyr::mutate(Taxon = taxon %>%
                 str_replace("^.+_", paste0(str_extract(taxon, "."), "_"))) %>%
    compute_ratios(group_vars = c("sample_id", "material_type", "target_subfragment")) %>%
  mutate(Pair = paste(Taxon.x, Taxon.y, sep = ":")) %>% 
  ggplot(aes(Pair, expected, colour=sample_id)) +
  geom_hline(yintercept = 1, alpha=0.8) +
  geom_jitter(alpha=0.7) +
  geom_rangeframe(colour="black")+
  scale_y_log10() +
  base_theme+
  facet_grid(target_subfragment~.)+
    theme(legend.position = "none",
          axis.text.x = element_text(angle=45, hjust=1))+
  labs(y= "Error in taxon ratios (log10)") 

gg.ratio

# Estimate bias on CLR transformed ratios
bias.clr <- joint %>%
  filter(material_type=="DrosMock") %>%
  filter(expected > 0) %>%
  group_by(sample_id) %>%
  mutate(clr_error = clr(observed0 /expected)) %>%
  ungroup() %>%
  group_by(target_subfragment, material_type)  %>%
    nest() %>%
    mutate(fit = map(data, ~lm(clr_error ~ 0 + taxon , data = .)), 
           tidied = map(fit, broom::tidy),
           aug = map(fit, broom::augment)
    ) %>%
  dplyr::select(-fit) %>%
  unnest(tidied) %>%
  mutate(estimate =  exp(estimate),
         taxon = str_remove(term, "taxon")) %>%
   dplyr::select(target_subfragment, material_type, taxon, estimate) 

# See how well bias estiamte fits data
library(plotly)

preds <- joint %>%
  left_join(bias.clr) %>%
  #filter(!is.na(estimate)) %>%
  dplyr::mutate(predicted = expected * estimate) %>%
  group_by(sample_id) %>%
  mutate_at(vars(predicted), ~ . / sum(., na.rm=TRUE) ) %>%
  filter(expected > 0) %>%
  filter(observed > 0)

library(ggthemes)
ggplot(preds,  aes(x=logit(predicted), y=logit(observed), color = taxon))+
  geom_abline(intercept = 0, slope = 1, color = "grey") +
    geom_jitter(width = 0.1, height = 0, alpha=0.7) +
    geom_rangeframe(color = "black") + 
  facet_grid(fcid~target_subfragment)+
    labs(x = "log-odds(Predicted proportion)", 
        y = "log-odds(Observed proportion)",
        colour = "Taxon",
        title="Bias model fits") +
    coord_fixed() + 
  base_theme +
  theme(
        panel.spacing.x = unit(1, "lines"),
        legend.position = "bottom",
    )

# Plot bias estimates
preds %>%
  distinct() %>%
  ggplot(aes(x=taxon, y=estimate-1, fill=target_subfragment)) +
    geom_col()+
    facet_grid(target_subfragment~material_type) +
  coord_flip() +
  geom_rangeframe() +
  base_theme+
  scale_fill_brewer(palette="Paired") +
  labs(
    x="Taxon",
    y= "Bias / Geometric mean")


```


## Effect of primer on detection probability
How do the primers affect its probability of detection (presence/absence). We used a generalized linear mixed effects model of presence/absense as a function of primer
primer. To account for the paired design (where both types of samples were derived from the samen community), we defined Sample ID as a random effect.
Since the response was binomial, we assumed a logit‐link and binomially distributed error
```{r}
# Use joint to get a table of expected/absent
det_table <- joint %>% 
  filter(material_type=="DrosMock") %>%
  mutate(detected = case_when(
    expected > 0 & observed > 0 ~ 1,
    expected > 0 & observed == 0 ~ 0,
    TRUE ~ as.numeric(NA)
    )) %>%
  mutate(extract_id = sample_name %>%
           str_remove_all("BF1-BR1-|fwhF2-fwhR2n-|SauronS878-HexCOIR4-|fwhF2-HexCOIR4-"))

# Estimate detection efficiency of all taxa - problem is all are detected and none are failed!
# Need to filter for index switching
# 
library(lme4)
detmodel <- det_table %>%
  filter(fcid=="CB3DR") %>%
  dplyr::select(sample_id, extract_id, taxon, detected, target_subfragment) %>%
  #group_by(taxon) %>%
  nest() %>%
  mutate(fit = map(data, ~glmer(detected ~ target_subfragment + (1|extract_id), family=binomial, data = .)), 
           tidied = map(fit, broom::tidy),
           aug = map(fit, broom::augment)

  ) %>%
  dplyr::select(-fit) %>%
  unnest(tidied) 

# Estimate detection efficiency of targets
library(lme4)
det_suzukii <- ps_qual %>%
  filter(fcid=="CB3DR") %>%
  group_by(Species) %>%
  nest() %>%
  mutate(fit = map(data, ~glmer(detection ~ target_subfragment + (1|extract_id), family=binomial, data = .)), 
           tidied = map(fit, broom::tidy),
           aug = map(fit, broom::augment)

  ) %>%
  dplyr::select(-fit) %>%
  unnest(tidied) 

det_suzukii
```


#FIGURE 1  Comparison of primers for detection, bias, and PCA of overlap  

# Supplementary Comparison of primer replicates for detection and bias

Run 2 - see the differences in bias between replicates

```{R run2}


```

# Overlap between replicates

Venn diagrams? - Heatmap of presence absense

Species accumulation curve- adding more extraction reps, pcr reps, biological samples, sequence depth

Want to show - Different extraction replicates adds more - but this is probably due to contamination
PCR replicates doesnt add more

# Merge technical replicates

```{r merge replicates}
# Merge replicates
ps.merged <- ps0 %>%
    merge_samples(group = "Sample_Name", fun="sum")

#This loses the sample metadata - Need to add it agian
sample_data(ps.merged) <- sample_data(ps0) %>%
  filter(!duplicated(Sample_Name)) %>%
  magrittr::set_rownames(.$Sample_Name)

ps1 <- ps.merged
```

# Minimum read filtering

```{r minimum reads}
### Remove positive controls
##check mocks
ps1 <- subset_samples(ps1, !str_detect(sample_names(ps1), "POS"))
#message((nsamples(ps1) - nsamples(ps1)), " outlier samples dropped")

ps1 <- prune_samples(sample_sums(ps1) >0 , ps1)

#Plot rarefaction curve
out <- rarecurve(otu_table(ps1), step=10000)

rare <- lapply(out, function(x){
  b <- as.data.frame(x)
  b <- data.frame(OTU = b[,1], count = rownames(b))
  b$count <- as.numeric(gsub("N", "",  b$count))
  return(b)
})
names(rare) <- sample_names(ps1)

rare <- map_dfr(rare, function(x){
  z <- data.frame(x)
  return(z)
}, .id = "sample")

# threshold for read removal
threshold = 1000

gg.rare <- ggplot(data = rare)+
  geom_line(aes(x = count, y = OTU, group=sample), alpha=0.5)+
  geom_point(data = rare %>% 
               group_by(sample) %>% 
               top_n(1, count),
             aes(x = count, y = OTU, colour=(count > threshold))) +
  geom_label(data = rare %>% 
               group_by(sample) %>% 
               top_n(1, count),
             aes(x = count, y = OTU,label=sample, colour=(count > threshold)),
             hjust=-0.05)+
  scale_x_continuous(labels =  scales::scientific_format()) +
  geom_vline(xintercept=threshold, linetype="dashed") +
  labs(colour = "Sample kept?") +
  xlab("Sequence reads") +
  ylab("Observed ASV's")

gg.rare

#Write out figure
pdf(file="fig/rarefaction.pdf", width = 11, height = 8 , paper="a4r")
  plot(gg.rare)
try(dev.off(), silent=TRUE)

#Remove all samples under the minimum read threshold 
ps2 <- prune_samples(sample_sums(ps1)>=threshold, ps1) 
ps2 <- filter_taxa(ps2, function(x) mean(x) > 0, TRUE) #Drop missing taxa from table
message(nsamples(ps1) - nsamples(ps2), " Samples and ", ntaxa(ps1) - ntaxa(ps2), " taxa under read threshold Dropped")
```


## Alpha diversity metrics

```{r alpha div}
dir.create("output/alpha")
# Get richness measures
richness <- phyloseq::estimate_richness(ps2,measures=c("Chao1", "Shannon", "Simpson")) %>% #
  rownames_to_column("Sample_Name") %>%
  mutate(Sample_Name = str_replace(Sample_Name, "\\.", "-"))


#Set number of randomisations for calculating significance
# Calculate Faith's PD-index & Species richness - with Standard errors
sespd <- picante::ses.pd(as(phyloseq::otu_table(ps2), "matrix"),  phyloseq::phy_tree(ps2), null.model = "taxa.labels", include.root = F, runs = 9)

# Join together
div_table <- sespd %>%
  rownames_to_column("Sample_Name") %>%
  dplyr::select(Sample_Name, ntaxa, pd.obs) %>%
  dplyr::rename(pd = pd.obs, alpha = ntaxa) %>%
  left_join(richness, by="Sample_Name") %>%
  left_join(sample_data(ps2) %>% 
              as.data.frame() %>%
              filter(!duplicated(Sample_Name)) %>%
              dplyr::select(replicate, Sample_Name, type),
            by = "Sample_Name") 
# Summarise means
div_table %>%
  summarise_if(is.numeric, mean)

# Difference in alpha diversity between replicates
#report::report(aov(alpha ~replicate, data=div_table))
#report::report(aov(Shannon ~replicate, data=div_table))
#report::report(aov(pd ~replicate, data=div_table))
#
# Difference in alpha diversity between trap types
report::report(aov(alpha ~type, data=div_table))
report::report(aov(Shannon ~type, data=div_table))
report::report(aov(pd ~type, data=div_table))
```

## Rarefied

```{r alpha rarefied}
# Rarefied richness
ps2_rare <- rarefy_even_depth(ps2, sample.size = min(sample_sums(ps2)),
  rngseed = 666, replace = TRUE, trimOTUs = TRUE, verbose = TRUE)

# Get richness measures
richness_rare <- phyloseq::estimate_richness(ps2_rare,measures=c("Chao1", "Shannon", "Simpson")) %>% #
  rownames_to_column("Sample_ID") %>%
  mutate(Sample_ID = str_replace(Sample_ID, "\\.", "-"))

#Set number of randomisations for calculating significance
# Calculate Faith's PD-index & Species richness - with Standard errors
sespd_rare <- picante::ses.pd(as(phyloseq::otu_table(ps2_rare), "matrix"),  phyloseq::phy_tree(ps2_rare), null.model = "taxa.labels", include.root = F, runs = 9)

# Join together
div_table_rare <-  sespd %>%
  rownames_to_column("Sample_ID") %>%
  dplyr::select(Sample_ID, ntaxa, pd.obs) %>%
  dplyr::rename(pd = pd.obs, alpha = ntaxa) %>%
  left_join(richness, by="Sample_ID") %>%
  left_join(sample_data(ps2) %>% 
              as.data.frame() %>%
              filter(!duplicated(Sample_ID)) %>%
              dplyr::select(replicate, Sample_ID, Sample_Name, type),
            by = "Sample_ID") 
# Summarise means
div_table_rare %>%
  summarise_if(is.numeric, mean)

# Difference in alpha diversity between replicates
report::report(aov(alpha ~replicate, data=div_table_rare))
report::report(aov(Shannon ~replicate, data=div_table_rare))
report::report(aov(pd ~replicate, data=div_table_rare))

# Difference in alpha diversity between trap types
report::report(aov(alpha ~type, data=div_table_rare))
report::report(aov(Shannon ~type, data=div_table_rare))
report::report(aov(pd ~type, data=div_table_rare))
```

## Beta diversity metrics

```{r Distances}
ps2_dist <- ps2
# Get OTU tables
otutab <- otu_table(ps2_dist)
#Impute zeroes for compositional distances
otutab_n0 <- as.matrix(zCompositions::cmultRepl(otutab, method="CZM", output="p-counts"))
#Root phylogenetic tree
phy_tree(ps2_dist) <- multi2di(phy_tree(ps2_dist))

#Calculate different distance metrics
metrics <- c("Bray", "Jaccard", "Aitchison", "Philr", "Unifrac", "WUnifrac")
distlist <- vector("list", length=length(metrics))
names(distlist) <- metrics

distlist$Jaccard <- as.matrix(vegdist(otutab, method="jac",binary = T))
distlist$Bray <- as.matrix(vegdist(otutab, method="bray"))
distlist$Aitchison <- as.matrix(vegdist(CoDaSeq::codaSeq.clr(otutab_n0), method="euclidean"))
distlist$Philr <- as.matrix(vegdist(philr::philr(otutab_n0, phy_tree(ps2),
                                                part.weights='enorm.x.gm.counts',
                                                ilr.weights='blw.sqrt'), method="euclidean"))
distlist$Unifrac <- as.matrix(phyloseq::UniFrac(ps2_dist, weighted=FALSE, parallel = TRUE))
distlist$WUnifrac <- as.matrix(phyloseq::UniFrac(ps2_dist, weighted=TRUE, parallel = TRUE))

```

# Adonis and betadisper
```{r betatest}
# Adonis test
metadata <- sample_data(ps2) %>%
  as_data_frame()

# Test difference by community type
adonis_results <- distlist %>%
  purrr::map(function(x) {
    bind_rows(
    broom::tidy(adonis(x~type, method="euclidean", data=metadata)$aov.tab) %>% dplyr::slice(1)
    )
})  %>%
  bind_rows(.id="dist")

# Check homogeneity
betadisper_results <- distlist %>%
  purrr::map(function(x) {
    y <- as.dist(x[metadata$Sample_Name, metadata$Sample_Name])
  bind_rows(
    as.data.frame(permutest(vegan::betadisper(y, metadata$type))$tab) %>%
      dplyr::slice(1) %>% 
      mutate(term="type")
  )
})  %>%
  bind_rows(.id="dist")

dir.create("output/beta")
write_csv(adonis_results, "output/beta/adonis.csv")
write_csv(betadisper_results, "output/beta/adonis.csv")
```

# PCA plots

```{r pca plots}
phy_tree(ps2) <- multi2di(phy_tree(ps2))
phy_tree(ps2) <- makeNodeLabel(phy_tree(ps2), method="number", prefix='n')

# Get philr distance
ps2.philr <- philr::philr(otutab_n0, phy_tree(ps2),
                     part.weights='enorm.x.gm.counts', 
                     ilr.weights='blw.sqrt')
#PCA 
pca <- prcomp(ps2.philr)

#Name balances
pcnames <-  sapply(rownames(pca$rotation), function(x) name.balance(phy_tree(ps2), tax_table(ps2), x))
pcnames <- make.unique(pcnames, sep = ".")
rownames(pca$rotation) <- pcnames

# Get pca data
pca_data <- data.frame(Sample_Name= rownames(pca$x), pca$x[, 1:2])%>%
  left_join(as_data_frame(sample_data(ps2)), by="Sample_Name")

#Get PCA loadings
pca_loadings <- data.frame(OTU = rownames(pca$rotation), pca$rotation[, 1:2])
mult <- min(
    (max(pca_data$PC1) - min(pca_data$PC1)/(max(pca_loadings$PC1)-min(pca_loadings$PC1))),
    (max(pca_data$PC2) - min(pca_data$PC2)/(max(pca_loadings$PC2)-min(pca_loadings$PC2)))
    )
pca_loadings <- transform(pca_loadings,
        v1 = .7 * mult * (pca_loadings$PC1),
        v2 = .7 * mult * (pca_loadings$PC1)
        )

# calculate percent variance explained for the axis labels
pc1 <- round(pca$sdev[1]^2/sum(pca$sdev^2),2)
pc2 <- round(pca$sdev[2]^2/sum(pca$sdev^2),2)
pc_ylab <- paste("PC1: ", pc1, sep="")
pc_xlab <- paste("PC2: ", pc2, sep="")

# Plot PCA
gg.pca <- ggplot(data=pca_data, aes(x=PC2, y=PC1)) + 
  geom_point(aes(fill = type),alpha=0.8, size=3,shape=21, colour="black") +
  theme_classic() +
  scale_fill_brewer(palette="Paired") +
  geom_hline(yintercept = 0, linetype=2, alpha=0.5) +  
  geom_vline(xintercept = 0, linetype=2, alpha=0.5) +
  xlab(pc_xlab) + 
  ylab(pc_ylab) +
  scale_y_continuous(position = "right") + 
  #Add loadings
  geom_text(data=pca_loadings, aes(x=v1, y=v2, label=OTU), 
            size = 5, vjust=1, color="red", check_overlap = TRUE)+
  geom_segment(data=pca_loadings, aes(x=0, y=0, xend=v1, yend=v2),
               arrow=arrow(length=unit(0.2,"cm")), alpha=0.75, color="red")
#coord_fixed(ratio=pc2/pc1) # Scale plot by variance explained

gg.pca

# Heirarchial clustering
dend <- hclust(vegdist(ps2.philr, method="euclidean"), method="average")

p3 <- ggtree(as.phylo(dend) ) + 
  theme_tree2()

colours_p3 <- p3$data %>%
  left_join(as_data_frame(sample_data(ps2)) %>%
              dplyr::select(Sample_Name, type) %>%
  dplyr::rename(label = Sample_Name)
    )
p3 <- p3 %<+% colours_p3  + 
  geom_tippoint(aes(colour=as.factor(type)))  + 
  geom_tiplab(aes(colour=as.factor(type)))+
  scale_colour_brewer(palette="Paired") +
    scale_x_continuous(expand=c(0, 30)) 

# Plot together
p3 + gg.pca

tidied_pca <- broom::tidy(pca, matrix="rotation") %>%
  magrittr::set_colnames(c("term", "component", "value"))

library(tidytext)
tidied_pca %>%
  dplyr::filter(component < 5) %>%
  group_by(component) %>%
  top_n(6, abs(value)) %>%
  ungroup() %>%
  mutate(term = reorder_within(term, abs(value), component)) %>%
  dplyr::mutate(component = factor(paste0("PC",component))) %>%
  ggplot(aes(x=abs(value), y=term, fill = value > 0)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~component, scales = "free") +
  scale_y_reordered() +
    labs(
    x = "Absolute value of contribution",
    y = NULL, 
    fill = "Positive?"
  ) +
  theme_classic() 

# Scree plot
sdev <- pca$sdev
percent_variation <- sdev^2 / sum(sdev^2)

tibble(
  component = unique(tidied_pca$component),
  percent_var = percent_variation ## use cumsum() to find cumulative, if you prefer
) %>%
  dplyr::filter(component < 11) %>%
  mutate(component = factor(component)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(component, percent_var)) +
  geom_col() +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = NULL, y = "Percent variance explained by each PCA component") +
  theme_classic()
```

# Fit GLMnet

from philr tutorial https://bioconductor.org/packages/devel/bioc/vignettes/philr/inst/doc/philr-intro.html
```{r glmnet}
library(glmnet)

# Predict mock vs real
sample_data(ps2)$mock <- factor(get_variable(ps2, "type") %in% c("Mock", "POS"))

glmmod <- glmnet(ps2.philr, sample_data(ps2)$type, alpha=1, family="multinomial")

# Get coords usign tidy insteaed
tidied <- tidy(glmmod) %>% 
  filter(!term == "(Intercept)",
         !term == ""
         )%>%
  mutate(node = name.to.nn(phy_tree(ps2), term))

ggplot(tidied, aes(step, estimate, group = term)) +
  geom_line()

#tc.colors <- c('#a6cee3', '#1f78b4')
p <- ggtree(phy_tree(ps2), layout='fan') +
  geom_balance(node=2843, alpha=0.6) # get node number from the tidied dev.node
p <- annotate_balance(phy_tree(ps2), 'n16', p=p, labels = c('n16+', 'n16-'),
                 offset.text=0.15, bar=FALSE)
annotate_balance(tree, 'n730', p=p, labels = c('n730+', 'n730-'),
                 offset.text=0.15, bar=FALSE)
```


## Occupancy modelling

### eDNAoccupancy
```{r edna occupancy}

library(eDNAoccupancy)
data(fungusDetectionData)
data(fungusSurveyData)

# Make detection table
ps_qual <- ps %>%
  speedyseq::tax_glom(taxrank="Species") %>%
  transform_sample_counts(function (x) (x > 0) * 1) %>%
  #merge_samples(group = "ExtractID") %>%
  speedyseq::psmelt() %>%
  select(Sample, Abundance, Species) %>%
  separate(Sample, into=c("site", "rep"), sep="-rep") %>%
  mutate(rep=paste0("pcr",rep)) %>%
  separate(site, into=c("site", "sample"), sep="-ex") %>%
  pivot_wider(names_from=rep, values_from = Abundance, values_fill=list(Abundance = 0)) 

det_suzukii <- ps_qual %>%
  mutate(site = str_replace(site, "DM", "D100M")) %>%
  filter(Species=="Drosophila_suzukii") %>%
  filter(str_detect(site,"D100M|D250M|D500M|D1000M")) %>%
  select(site, sample, pcr1, pcr2, pcr3) %>%
  mutate(sample = as.integer(sample)) %>%
  arrange(sample) %>%
  as.data.frame()

suzukii_detections = occData(det_suzukii, siteColName = 'site',
                            sampleColName = 'sample')

#Make covariate tables

# Read in expected table
exp <- read_csv("sample_data/expected_quant_merged.csv") %>%
  gather(Species, Actual, -X1) %>%
  mutate(Species = str_replace(Species, pattern=" ",replacement="_")) %>%
  filter(str_detect(X1,"D100M|D250M|D500M|D1000M|DLarv")) %>%
  drop_na() %>%
  set_colnames(c("Sample","Species","Actual"))
# Add true presence

#Add community size covariate

commsize <- exp %>%
  group_by(Sample) %>%
  summarise(commsize = sum(Actual)) %>%
  mutate(Sample = str_replace_all(Sample, pattern="(-)(.*?)(?=$)", replacement=""))

survey_data <- samdf %>%
  remove_rownames() %>%
  mutate(Sample = str_replace_all(ExtractID, pattern="(-)(.*?)(?=$)", replacement="")) %>%
  select(Sample, geo_loc_name, material) %>%
  left_join(commsize, by="Sample") %>%
  rename(site = Sample) %>%
  filter(str_detect(site,"D100M|D250M|D500M|D1000M")) %>%
  unique()

# Add alpha diversity covariates

# Try using hill numbers for these https://github.com/anttonalberdi/hilldiv

#estimate richness
alpha_table <- phyloseq::estimate_richness(ps2)

# Calculate Faith's PD-index
pdtable <- picante::pd(as(phyloseq::otu_table(ps2), "matrix"), phyloseq::phy_tree(ps2), include.root = F)




 ## number of detections per sample
 head(suzukii_detections$y)
 ## number of PCR replicates per sample
 head(suzukii_detections$K)

#We fit a multi-scale occupancy model without covariates and print a summary of the parameter estimates using the following code.

 set.seed(69)
 fit = occModel(detectionMats=suzukii_detections, niter=11000,
                niterInterval=5000)
 posteriorSummary(fit, burnin=1000, mcError=TRUE)


## Center and scale numeric-valued covariate measurements
survey_data.sc = scaleData(survey_data)

set.seed(0157)
fit = occModel(formulaSite          = ~ 1,
               formulaSiteAndSample = ~ commsize,
               formulaReplicate     = ~ commsize,
               detectionMats        = suzukii_detections,
               siteData             = survey_data.sc,
               niter                = 6000,
               niterInterval        = 2000,
               siteColName = 'site'
               )
posteriorSummary(fit, burnin=1000, mcError=TRUE)


#If we want to assess whether the Markov chain used to compute these estimates appears to have converged, trace plots of the parameters may be created as follows (Fig.~\ref{fig:TracePlotFungusAnalysis}).
plotTrace(fit, c('beta.(Intercept)', 'alpha.(Intercept)', 'alpha.frogs',
            'delta.(Intercept)'),  burnin=1000)

#Autocorrelation plots of the parameters are created similarly
 plotACF(fit, c('beta.(Intercept)', 'alpha.(Intercept)', 'alpha.frogs',
             'delta.(Intercept)'),  burnin=1000)

#After inspection of these plots, suppose we decide that the MCMC algorithm needs to be run longer, either to eliminate the transient portion of the Markov chain or to reduce Monte Carlo errors in the parameter estimates.  We can resume the MCMC algorithm for the currently fitted model as follows.
 fit = updateOccModel(fit, niter=5000, niterInterval=2000)
 posteriorSummary(fit, burnin=1000,  mcError=TRUE)

 #These estimates of the parameters are computed using the updated Markov chain containing \rinline{fit$niterations} iterations.  The Monte Carlo errors in these parameter estimates are slightly lower, but the estimates are otherwise similar to those computed with only \rinline{fit$niterations-5000} iterations.

#In addition to estimating posterior summaries of the model's formal parameters, we also may be interested in estimating posterior summaries of derived parameters.  For example, in the second model fitted to the \emph{Bd} data, the probability of eDNA occurrence in ponds was assumed to be constant ($\psi$), the conditional probability of eDNA occurrence in samples was assumed to be a function of the frog density index \code{frogs}, and the conditional probability of eDNA detection was assumed to be constant ($p$).  The posterior medians of these derived parameters are estimated as follows.

psi = posteriorSummaryOfSiteOccupancy(fit, burnin=1000)
theta = posteriorSummaryOfSampleOccupancy(fit, burnin=1000)
p = posteriorSummaryOfDetection(fit, burnin=1000)

 ## output estimates of posterior medians
 cbind(psi=psi$median, theta=theta$median[,1], p=p$median[,1])

 frogs = fungusSurveyData[, 'frogs']
 plot(frogs, theta$median[,1], ylim=c(0,1), xlim=c(0,0.8), cex=2)
 segments(frogs, theta$lower[,1], frogs, theta$upper[,1], lwd=2)
 
#One way to assess the relative importance of such estimated relationships is to compare competing models using model-selection criteria.  For example, we compute the PPLC and WAIC criteria for the previously fitted model as follows.
 posteriorPredictiveLoss(fit, burnin=1000)
 WAIC(fit, burnin=1000)

```

###Seak occupancy

Seak occupancy modelling - The model is fitted within a Bayesian framework and any of the model parameters can be functions of covariates. The implemented algorithm performs Bayesian variable selection and the output includes posterior summaries of all parameters as well as posterior probabilities of inclusion (see examples for a more detailed description of how to interpret the output).

The model has been developed for single species qPCR data. The data are the number of positive qPCRs (eDNA score) for each water sample collected at surveyed sites. The model allows us to estimate the probability of species presence at each survey site, while accounting for the probabilities of a false positive and false negative error at stage 1 (field) and stage 2 (lab).



Occupancy modelling calculates the probability of detection from a number of replicates. ie - 6 replicates positive = 100% probaiblity , 5/6 = 85% probability

Nested levels = Replicated extractions, replicated PCRs .

Could fit a single specied


For model taking into accoutn false poositives and negatives: https://seak.shinyapps.io/eDNA/

This requires format

Columns = Sample (extraciton replicate ) so 2 columns
Rows = site (trap)
cell value = number of positive PCR replicates (out of 3)
Column 3 = True presence or absense 1 or 0
column 4,5,6 etc other covariates. Sequencing depth, community size, species richness,trap type, phylogenetic richness... etc



```{r occupancy}
#convert to presence/absense
ps_qual <- ps %>%
  speedyseq::tax_glom(taxrank="Species") %>%
  transform_sample_counts(function (x) (x > 0) * 1) %>%
  merge_samples(group = "Sample_Name") %>%
  speedyseq::psmelt() %>%
  dplyr::select(Sample, Abundance, Species) %>%
  mutate(Sample = str_remove(Sample, "^.*_")) %>%
  separate(Sample, into=c("Sample", "exrep"), sep="-ex") %>%
  pivot_wider(names_from=exrep, values_from = Abundance, values_fill=list(Abundance = 0)) %>%
  dplyr::select(Sample, Species, `1`, `2`,)

# Read in expected table
exp <- read_csv("sample_data/expected_quant_merged.csv") %>%
  gather(Species, Actual, -X1) %>%
  mutate(Species = str_replace(Species, pattern=" ",replacement="_")) %>%
  #filter(str_detect(X1,"D100M|D250M|D500M|D1000M|DLarv")) %>%
  drop_na() %>%
  set_colnames(c("Sample","Species","Actual"))
# Add true presence

true_pres <- exp %>%
  mutate(Sample = str_replace_all(Sample, pattern="(-)(.*?)(?=$)", replacement="")) %>%
  mutate(Actual = case_when(
    Actual > 0 ~ 1,
    Actual == 0 ~ 0
  )) %>%
  unique()
  
#Add community size covariate - need to estimate for others

commsize <- exp %>%
  group_by(Sample) %>%
  summarise(commsize = sum(Actual)) %>%
  mutate(Sample = str_replace_all(Sample, pattern="(-)(.*?)(?=$)", replacement=""))

# add seqdepth covariate

#filterdepth

#richness
richness <- ps_qual %>%
  mutate(Sample = str_replace(Sample, "DM", "D100M")) %>%
  ungroup() %>%
  mutate(total = `1`+`2`) %>%
  filter(total > 0) %>%
  group_by(Sample) %>%
  summarise(richness= n())  

# Species evenness

# Phylogenetic diversity


#trap_type
comm_type <- exp %>%
  mutate(Sample = str_replace_all(Sample, pattern="(-)(.*?)(?=$)", replacement="")) %>%
  mutate(comm_type = case_when(
    str_detect(Sample, "D100M|D250M|D500M|D1000M") ~ "Mock",
    str_detect(Sample, "DLarv") ~ "Larvae",
    str_detect(Sample, "ACV") ~ "ACV",
    str_detect(Sample, "FF") ~ "FF",
    str_detect(Sample, "SPD") ~ "SPD",
    str_detect(Sample, "DC") ~ "DC",
  )) %>%
  dplyr::select(Sample, comm_type) %>%
  unique()
  

# Get suzukii only
det_suzukii <- ps_qual %>%
  mutate(Sample = str_replace(Sample, "DM", "D100M")) %>%
  left_join(true_pres, by=c("Sample", "Species"))%>%
  left_join(commsize, by="Sample") %>%
  left_join(richness, by="Sample") %>%
  left_join(comm_type, by="Sample") %>%
  filter(Species == "Drosophila_suzukii") %>%
  dplyr::select(-Species) %>%
  unique() %>%
  mutate(Actual = replace_na(Actual, 0))  %>%
  filter(!is.na(commsize)) %>%
  mutate(commsize = scale(commsize, center = TRUE, scale = TRUE))  %>%
  #mutate(random = scale(rbinom(nrow(.), 100, 0.7), center = TRUE, scale=TRUE)) %>%
  #mutate(random2 = scale(rbinom(nrow(.), 100, 0.4), center = TRUE, scale=TRUE)) %>%
  mutate(richness = scale(richness, center = TRUE, scale = TRUE))  %>%
  filter(!str_detect(Sample, "DLarv"))# %>%
  #set_rownames(.$Sample) #%>%
  dplyr::select(-Sample)
  
write.csv(det_suzukii, "test_occupancy_suzukii.csv", row.names=FALSE)

```

For sequencing depth covariate could you just rarefy to certain depth, recalculate detection, then rbind a longer table together in a loop
Same with filtering threshold



these could be fit seperately for our 3 target species

Then we can look at how the detection probability changes across different filtering thresholds used to remove index switching?


To test if probability of detection differs as a function of sample water volume, we used the eDNAoccupancy R package (version 0.2.4; Dorazio & Erickson, 2017) to model probabilities of eDNA detection. This package fits Bayesian, multi‐scale occupancy models to our data, which included three, nested levels of sampling: stream location, replicated water samples collected from each stream, and subsamples (i.e., PCR technical replicates) of each water sample. 



https://onlinelibrary.wiley.com/doi/full/10.1002/edn3.23

https://besjournals.onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2011.00156.x

https://www.pnas.org/content/pnas/116/18/8931.full.pdf

Based on the overall model, a total of seven water samples was
required to achieve >95% detection probabilities of S. mansoni
eDNA at water sample level (θ = 0.35) [as calculated by using
the equation P = 1 − (1 − θ)
n (27)]. By using the same approach,
the model-based estimated number of qPCR replicates required
to achieve detection probabilities >95% ranged from three to
nine replicates between sites


## Check for concordance between mock and real


```{r PCA}
# Read in expected table
exp <- read_csv("sample_data/expected_quant_merged.csv") %>%
  gather(Species, Abundance, -X1) %>%
  mutate(Species = str_replace(Species, pattern=" ",replacement="_")) %>%
  filter(str_detect(X1,"D100M|D250M|D500M|D1000M|DLarv")) %>%
  drop_na() %>%
  set_colnames(c("Sample","Species","Actual"))

# Prepare observed table
sam <- ps.merged %>%
  speedyseq::tax_glom("Species") %>%
  transform_sample_counts(function (x) x/sum(x)) %>%
  speedyseq::psmelt() %>%
  mutate(Species = str_replace(Species, pattern="Drosophila_mauritiana/simulans", replacement= "Drosophila_simulans")) %>%
  mutate(Species = str_replace(Species, pattern="Drosophila_albomicans", replacement= "Drosophila_immigrans")) %>%
  filter(Sample %in% exp$Sample) %>%
  arrange(Abundance) %>%
  distinct() %>%
  select(Sample, Species, Abundance)

# Join tables
joint <- sam %>%
  filter(Species %in% exp$Species) %>%
  group_by(Species, Sample) %>% 
  summarise(Abundance = sum(Abundance)) %>%
  ungroup() %>%
  #mutate(Type = ifelse(Sample %in% controls, "Est", "Eval")) %>%
  bind_rows(exp %>%
              mutate(Actual = replace_na(Actual, 0)) %>%
              rename(Abundance = Actual) %>%
              filter(str_detect(Sample, pattern="-ex1"))  %>%
              mutate(Sample = str_replace_all(Sample, pattern="-ex1", replacement="-A")
            
            )) %>%
  group_by(Sample) %>%  
  mutate_at(vars(Abundance), ~ . / sum(.)) %>% # Convert to proportions
  #mutate(Abundance = Abundance + 0.0001) %>% # Add pseudocount
  #mutate(Abundance = clr(Abundance)) %>%
  ungroup()

# PCA
joint_pca <- joint %>%
  pivot_wider(
    names_from = Species, #  Switch this to transpose
    values_from = Abundance,
    values_fill = list(Abundance=0),
  ) %>%
  mutate(Extract = Sample %>% str_replace_all(pattern="(-)(.*?)(?=$)", replacement="")) %>%
  mutate(Mock = Sample %>% 
           str_replace_all(pattern="(-)(.*?)(?=$)", replacement="") %>%
           str_replace_all(pattern="(^)(.*?)(?<=M)", replacement="")) %>%
  nest(data = everything()) %>%
  mutate(pca = map(data, ~ prcomp(.x %>% select(-Sample, -Extract, -Mock), 
                                  center = TRUE, scale = TRUE)),
         pca_aug = map2(pca, data, ~augment(.x, data = .y))) 

joint_pca$pca %>%
  map(~tidy(.x, data = .y, "pcs")) %>%
  as.data.frame() %>%
  ggplot(aes(x = PC, y=percent)) +
  geom_bar(stat="identity") + labs(x="PC",y="Variance Explained")


library(RColorBrewer)
col <- colorRampPalette(brewer.pal(11, "Spectral"))(25)

joint_pca %>%
  mutate(
    pca_graph = map2(
      .x = pca,
      .y = data,
      ~ autoplot(.x, loadings = TRUE, loadings.label = TRUE,
                 loadings.label.repel = FALSE,
                 data = .y, label = TRUE,
                 label.label = "Sample",
                 label.repel = TRUE, 
                 colour='Extract') +
       #theme_bw() +
        labs(x = "Principal Component 1",
             y = "Principal Component 2",
             title = "First two principal components of PCA for expected and observed") +
        coord_fixed()#+
       # scale_colour_manual(values=col)
    )
  ) %>%
  pull(pca_graph)


## Heirarchial clustering


# Output drosophila summary
ps.merged %>% 
  subset_taxa(Family=="Drosophilidae") %>%
  microbiome::transform("compositional") %>%
  summarise_taxa("Species", "sample_id") %>%
  filter(!str_detect(sample_id, "NTC")) %>%
  #filter(str_detect(Species, "Drosophila|Scaptodrosophila")) %>%
  spread(key="sample_id", value="totalRA") %>%
  write.csv(file = "output/csv/unfiltered/drosophila_spp_sum.csv")

```


```{R extra}
## Mclarens  naive approach
otutab <- otu_table(ps_bias)

#Impute zeroes for compositional distances
otutab_n0 <- otu_table(zCompositions::cmultRepl(otutab, method="CZM", output="p-counts"), taxa_are_rows = FALSE)

sam <- sample_data(ps_bias) %>% as("data.frame") %>% as_tibble(rownames = "Sample")

otu.clr <- otutab_n0 %>% transform_sample_counts(clr)
fit.clr <- lm(otu.clr ~ 0 + Sample_Name, sam) #Sample_Name*target_subfragment - should be able to account for all priemrs if we add this to the model
tb.clr <- broom::tidy(fit.clr, conf.int = TRUE) %>%
    dplyr::rename(OTU = response)

library(ggstance)
tb.clr %>%
    ggplot(aes(x = estimate, y = OTU)) +
    geom_vline(xintercept = 0) +
  geom_point() +
    #geom_pointrangeh(aes(xmin = conf.low, xmax = conf.high)) +
    scale_color_brewer(type = "qual", palette = 6) +
    labs(title = "LFC in differential efficiency")

#Test plot bias

p <- ggplot(bias0, aes(Taxon, y=Gm_mean-1,fill=Taxon)) +
    geom_bar(stat="identity")+
    geom_errorbar(aes(ymin = (Gm_mean-1) - (Gm_se-1), ymax = (Gm_mean-1) + (Gm_se-1), width=0.2)) +
    geom_point(aes(y=Gm_mean-1)) +
    scale_fill_brewer(palette="Spectral")+
    scale_colour_brewer(palette="Spectral") + 
  theme_bw() +
  theme(axis.text.x = element_text(angle=90,hjust=1,vjust=0)) + 
  ylab("Bias") +
  ggtitle(primers[i]) +
  expand_limits(y = c(-2, 4)) +
  theme(legend.position = "none")
 
plist[[i]] = p
 
#Get pairwise bias
bias.pw <- bias %>%
    compute_ratios(group_vars = c()) %>%
    mutate(Pair = paste(Taxon.x, Taxon.y, sep = ":"))

#Get pairwise boostrap estimates
bootreps.pw <- bootreps %>%
    compute_ratios(group_vars = ".id")
summary.pw <- bootreps.pw %>%
    group_by(Taxon.x, Taxon.y) %>%
    summarize(Gm_mean = gm_mean(Bhat), Gm_se = gm_sd(Bhat))
bias.pw0 <- left_join(bias.pw, summary.pw, by = c("Taxon.x", "Taxon.y"))

#Plot bias estimates
ratios <- joint %>%
    compute_ratios %>%
    mutate(Pair = paste(Taxon.x, Taxon.y, sep = ":")) %>%
    filter(!is.nan(Error), Taxon.x < Taxon.y)
ratios.pred <- bias.pw0 %>%
    mutate(Pair = paste(Taxon.x, Taxon.y, sep = ":")) %>%
    filter(Taxon.x < Taxon.y)

gg.bias <- ggplot(ratios, aes(Pair, Error, color = Sample)) +
    geom_hline(yintercept = 1, color = "grey") +
    geom_pointrange(data = ratios.pred, aes(y = Bhat, 
            ymin = Bhat / Gm_se^2, ymax = Bhat * Gm_se^2), 
        color = "black") +
    geom_jitter(width = 0.2) +
    scale_y_log10() +
    coord_flip()


```
