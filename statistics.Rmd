---
title: "Drosophila Metabarcoding"
title: "Statistical analysis"
author: "Alexander Piper"
date: "`r Sys.Date()`"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

# Introduction

## Analysis structure

Part 1 - Cleanup & Filtering of index switching

Part 1 - Comparison of 4 primers for bias and detection efficiency
(figure 1)

Part 2 - Comparison of bias between 3 tagged primers

Part 3 - Comparison 


## Load packages
```{r setup}
#Set required packages
.cran_packages <- c("tidyverse",
                    "tidymodels",
                    "patchwork", 
                    "vegan", 
                    "seqinr",
                    "ape", 
                    "RColorBrewer",
                    "ggtree", 
                    "castor", 
                    "picante",
                    "ggrepel",
                    "devtools")
.bioc_packages <- c("dada2",
                    "phyloseq", 
                    "DECIPHER",
                    "Biostrings",
                    "ShortRead", 
                    "philr",
                    "ALDEx2")

.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install(.bioc_packages[!.inst], ask = F)
}

sapply(c(.cran_packages,.bioc_packages), require, character.only = TRUE)

# Github packages
devtools::install_github("alexpiper/taxreturn")
devtools::install_github("alexpiper/seqateurs")
devtools::install_github("mikemc/speedyseq")
devtools::install_github('ggloor/CoDaSeq/CoDaSeq')
devtools::install_github("mikemc/metacal")

library(speedyseq)
library(taxreturn)
library(seqateurs)
library(CoDaSeq)
library(metacal)

#Source internal functions
source('R/helper_functions.R')

#Source themes
source('R/themes.R')
```

## Read in phyloseq object

```{r phyloseq}
ps2 <- readRDS("output/rds/ps_filtered.rds")
```

# Run 1 - primer comparison

## Overview of run 1

```{r run 1 overview}
ps_run1 <- ps2 %>%
  subset_samples(fcid %in% c("CB3DR")) 
ps_run1 <- ps_run1 %>%
  subset_samples(!str_detect(sample_names(ps_run1),"blank")) %>%
  filter_taxa( function(x) mean(x) > 0, TRUE) 

ps_run1 %>% 
  speedyseq::psmelt() %>%
  group_by(sample_id) %>%
  mutate_at(vars(Abundance), ~ . / sum(.) ) %>% #Convert to proportions
  mutate(plotlabel = case_when(
    Abundance >= 0.01  ~ Species, # Change this to whatever taxrank we want
    Abundance < 0.01 ~ as.character(NA)
    )) %>%
  ggplot(aes(x=sample_name, y=Abundance, fill=plotlabel)) +
  geom_col(position="stack") + 
  facet_grid(target_subfragment~type, scales="free") +
  scale_y_continuous(labels = scales::percent) +
  coord_flip()+
  base_theme+
  theme(legend.position = "bottom") +
  labs(x = "Sample Name",
       y= "Relative abundance",
       fill="Species",
       title = "Run 1 - Primer testing")

# Plot as heatmap
ps_run1 %>%
  speedyseq::psmelt() %>%
  #filter(Genus=="Drosophila") %>%
  group_by(sample_id) %>%
  mutate_at(vars(Abundance), ~ . / sum(.) ) %>%
  mutate(extract_id = str_remove(sample_name, "^.*-D")) %>%
    ggplot(aes(x=extract_id, y=Species, fill=Abundance)) +
    geom_tile() +
    facet_grid(~target_subfragment, scales="free") +
  base_theme+
  theme(axis.text.x = element_text(angle=45, hjust=1),
          legend.position = "bottom") +
    scale_fill_viridis_c(labels = scales::percent) +
    labs(x="Sample",
         y="Taxon",
         fill="Relative abundance",
         title="Run 1 - Primer testing")


#Compositional PCA using PhilR
# Get OTU tables
otutab <- otu_table(ps_run1)
#Impute zeroes for compositional distances
otutab_n0 <- as.matrix(zCompositions::cmultRepl(otutab, method="CZM", output="p-counts"))
#Root phylogenetic tree
phy_tree(ps_run1) <- multi2di(phy_tree(ps_run1))
# Get philr distance
ps_run1.philr <- philr::philr(otutab_n0, phy_tree(ps_run1),
                     part.weights='enorm.x.gm.counts', 
                     ilr.weights='blw.sqrt')

# Add extract id
sample_data(ps_run1) <- sample_data(ps_run1) %>%
  as("data.frame") %>%
  mutate(extract_id = sample_name %>%
           str_remove_all("BF1-BR1-|fwhF2-fwhR2n-|SauronS878-HexCOIR4-|fwhF2-HexCOIR4-")) %>%
  magrittr::set_rownames(.$sample_id)


#Philr PCOA
philr.dist <- dist(ps_run1.philr, method="euclidean")
philr.pcoa <- ordinate(ps_run1, 'PCoA', distance=philr.dist)
gg.run1pca <- plot_ordination(ps_run1, philr.pcoa, color = "extract_id", shape = "target_subfragment") +
  geom_point(size=3, alpha=0.8) +
  geom_line(aes(group=extract_id), alpha=0.8) +
  geom_hline(yintercept = 0, linetype=2, alpha=0.5) +  
  geom_vline(xintercept = 0, linetype=2, alpha=0.5) +
  base_theme +
  #coord_fixed() +
  scale_colour_brewer(palette="Paired") +
  theme(legend.position = "bottom", legend.margin=margin()) +
  labs(shape = "Primer pair",
       colour = "Sample")

gg.run1pca
```

## Bias

```{r Drosophila bias}
ps_bias <- ps_run1

exp <- read_csv("sample_data/expected_quant_merged.csv") %>%
  dplyr::rename(sample_name = Sample) %>%
  pivot_longer(-sample_name,
               names_to= "taxon",
               values_to= "expected") %>%
  mutate(taxon = str_replace(taxon, pattern=" ",replacement="_"),
         sample_name = str_remove(sample_name, "-exp*.$")) %>%
  dplyr::filter(!is.na(sample_name),
  !str_detect(sample_name, "CM[0-9]|CT[0-9]|CML[0-9]|Syn"),
  expected > 0) %>%
  distinct()

#plot expected
exp %>% 
  dplyr::filter(str_detect(sample_name, "^D")) %>%
  group_by(sample_name) %>%
  mutate_at(vars(expected), ~ . / sum(.) ) %>% #Convert to proportions
  ggplot(aes(x=sample_name, y=expected, fill=taxon)) +
  geom_col(position="stack") + 
  scale_fill_brewer(palette="Spectral") +
  scale_y_continuous(labels=scales::percent) +
  base_theme+
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle=45, hjust=1)) +
  labs(x = "Sample Name",
       y= "Relative abundance",
       title="Expected mock communities",
       fill="Species")

#Get observed
sam <- speedyseq::psmelt(ps_bias) %>%
  janitor::clean_names() %>%
  mutate(taxon = species) %>%
  filter(!str_detect(genus, "__")) %>%#Remove unclassified
  dplyr::select(sample_name, taxon, abundance, target_subfragment, fcid, material_type = type) %>%
  mutate(sample_name = sample_name %>%
           str_remove_all("BF1-BR1-|SauronS878-HexCOIR4-|fwhF2-HexCOIR4-|fwhF2-fwhR2n-") %>%
           str_remove("HLVKYDMXX_"),
         sample_id = paste0(fcid, "_", sample_name),
         sample_name = sample_name %>%
           str_remove_all("HLVKYDMXX_|CK3HD_|CB3DR_|CJKFJ_")) 

#Join tables 
joint <- sam %>%
  filter(taxon %in% exp$taxon,
         sample_name %in% exp$sample_name) %>%
  left_join(exp, by = c("sample_name","taxon")) %>%
  dplyr::rename(observed = abundance) %>%
  mutate(expected = replace_na(expected, 0),
         observed0 = (observed + 0.5) * (expected > 0),
         error = observed0 / expected) %>%
  distinct() %>%
  group_by(sample_id) %>%
  mutate_at(vars(observed, expected), ~ . / sum(.) ) %>% #Convert to proportions
  ungroup()


# Visualise the error in all pairwise ratios
gg.ratio <- joint %>%
  dplyr::filter(expected > 0 ) %>%
  dplyr::mutate(Taxon = taxon %>%
                 str_replace("^.+_", paste0(str_extract(taxon, "."), "_"))) %>%
    compute_ratios(group_vars = c("sample_id", "material_type", "target_subfragment")) %>%
  mutate(Pair = paste(Taxon.x, Taxon.y, sep = ":")) %>% 
  ggplot(aes(Pair, expected, colour=sample_id)) +
  geom_hline(yintercept = 1, alpha=0.8) +
  geom_jitter(alpha=0.7) +
  scale_y_log10() +
  base_theme+
  facet_grid(target_subfragment~.)+
    theme(legend.position = "none",
          axis.text.x = element_text(angle=45, hjust=1))+
  labs(y= "Error in taxon ratios (log10)") 

gg.ratio

# Estimate bias on geometrically centred ratios
bias <- joint %>%
  filter(material_type=="DrosMock") %>%
  filter(expected > 0) %>%
  group_by(target_subfragment, material_type)  %>%
    nest() %>%
    mutate(fit = map(data, ~lm(metacal::center_elts(observed0 /expected) ~ 0 + taxon , data = .)), 
           tidied = map(fit, broom::tidy),
           aug = map(fit, broom::augment)
    ) %>%
  dplyr::select(-fit) %>%
  unnest(tidied) %>%
  mutate(taxon = str_remove(term, "taxon")) %>%
   dplyr::select(target_subfragment, material_type, taxon, estimate) 

# Bootstrap estimation
set.seed(606)
boot_models <- joint %>%
  filter(material_type=="DrosMock") %>%
  filter(expected > 0) %>%
  group_by(target_subfragment) %>%
  group_modify(~{
    bootstraps(.x, times=1000, apparant=TRUE)  %>%
    mutate(fit = map(splits, ~lm(metacal::center_elts(observed0 /expected) ~ 0 + taxon , data = .)), 
           coef = map(fit, broom::tidy)) %>%
    int_pctl(coef) 
    }) %>%
  mutate(taxon = str_remove(term, "taxon")) %>%
  dplyr::select(target_subfragment, taxon, lower = .lower, estimate = .estimate, upper = .upper)

# See how well bias estiamte fits data

preds <- joint %>%
  left_join(boot_models) %>%
  dplyr::mutate(predicted = expected * estimate) %>%
  group_by(sample_id) %>%
  mutate_at(vars(predicted), ~ . / sum(., na.rm=TRUE) ) %>%
  filter(expected > 0) %>%
  filter(observed > 0)

# Get RMSE
errors <- preds %>%
  group_by(target_subfragment) %>%
  rmse(truth = logit(observed), estimate = logit(predicted)) %>%
  dplyr::select(target_subfragment, rmse = .estimate)

gg.bias_fits <- preds %>%
  mutate(taxon = str_replace(taxon, "_", " ")) %>%
  left_join(errors) %>%
  mutate(rmse = paste0("logit(RMSE) = ",round(rmse, 2))) %>%
  ggplot(aes(x=logit(predicted), y=logit(observed), color = taxon))+
  geom_abline(intercept = 0, slope = 1, color = "grey") +
    geom_jitter(width = 0.1, height = 0, alpha=0.7, size=2) +
  geom_text(aes(x=-6, y=-1, label=rmse), check_overlap = TRUE, inherit.aes = FALSE)+
  facet_wrap(~target_subfragment)+
  coord_fixed()+
  scale_color_brewer(palette = "Paired")+
  base_theme +
  theme(
        panel.spacing.x = unit(1, "lines"),
        legend.position = "bottom",
        legend.text = element_text(face = "italic", size=10)
    ) +
   labs(x = "log-odds(Predicted proportion)", 
     y = "log-odds(Observed proportion)",
     colour = "Taxon") 


gg.bias_fits

# Write out bias explained for supplementary 
pdf(file="fig/bias_model_fit.pdf", width = 11, height = 8 , paper="a4r")
  plot(gg.bias_fits)
try(dev.off(), silent=TRUE)


# Plot bias estimates
gg.bias <- preds %>%
  ungroup() %>%
  dplyr::select(taxon, estimate, upper, lower, target_subfragment) %>%
  distinct()%>%
  mutate(taxon = str_replace(taxon, "^.*_", "D. ")) %>%
  ggplot(aes(x = taxon, y = estimate-1, colour = target_subfragment, group = target_subfragment)) +
  geom_hline(yintercept = 0, alpha=0.5, colour = "grey20") +
  geom_pointrange(aes(ymin = lower-1, ymax = upper-1), position=position_dodge(width=0.5))+
  coord_flip() +
  #facet_grid(target_subfragment~.) +
  base_theme+
  scale_colour_brewer(palette="Paired") +
  labs(
    x = NULL,
    y = "Efficiency / Geometric mean") +
  theme(axis.text.y = element_text(face = "italic"),
        legend.position = "bottom")

gg.bias

#bias is missing for BF1 biarmipes because it was low reads
```

## Classification summary

The ratio of root assigned reads to those under species level can be used as a proxy for taxonomic assignment
```{r, run 1 tax summary}
# Subset to run 1
ps <- readRDS("output/rds/ps_idtaxaExact.rds")%>%
  subset_samples(fcid %in% c("CB3DR")) 

tax_summary <- speedyseq::psmelt(ps) %>%
  dplyr::select(target_subfragment, sample_id, rank_names(ps), Abundance) %>%
  pivot_longer(rank_names(ps),
               names_to="rank",
               values_to="name") %>%
  group_by(target_subfragment, rank) %>% 
  mutate(name = replace(name, str_detect(name, "__"), NA),
         rank = str_replace(rank, "Kingdom", "Root")) %>% 
    mutate(detection = case_when(
    Abundance > 0 ~ 1,
    Abundance == 0 ~ 0
  )) %>%
  #dplyr::filter(!is.na(name)) %>%
  dplyr::summarise(reads_classified = sum(Abundance * !is.na(name)),
                   asvs_classified = sum(detection * !is.na(name)))

# Lineplot
tax_plot_data <- tax_summary %>%
  ungroup %>%
  filter(!rank=="Root") %>%
  left_join(tax_summary %>% 
              filter(rank=="Root") %>%
              dplyr::select(target_subfragment, root_reads = reads_classified, root_asv = asvs_classified)) %>%
  mutate(read_prop = reads_classified / root_reads,
         asv_prop = asvs_classified / root_asv)%>% 
  dplyr::select(target_subfragment, rank, contains("prop"))  %>%
  pivot_longer(contains("prop"),
               names_to="type",
               values_to = "value") %>%
  mutate(type = type %>% 
           str_replace("asv_prop", "ASVs classified") %>%
           str_replace("read_prop", "Sequences classified")) %>%
  mutate(rank = factor(rank, levels = rank_names(ps)[2:length(rank_names(ps))]))

gg.reads_classified <- tax_plot_data  %>%
  ggplot(aes(x=rank, y=value, colour = target_subfragment, group=target_subfragment)) +
  geom_line() +
  geom_text_repel(data= tax_plot_data %>%
              filter(rank=="Species"),
            #aes(label = percent(read_prop, accuracy = 0.1)),
            aes(label = target_subfragment), nudge_x = 1, hjust=1,
            direction = "y", segment.alpha = 0)+
  base_theme +
  facet_wrap(~type, scales = "free_y", nrow = 2)+
  #facet_grid(~type, cols=1, rows=2) +
  scale_colour_brewer(palette="Paired") +
  scale_y_continuous(labels = scales::percent) +
  labs(x = NULL,
       y=NULL) 

gg.reads_classified
```

## Detection probability
How do the primers affect its probability of detection (presence/absence). We used a generalized linear mixed effects model of presence/absense as a function of primer
primer. To account for the paired design (where both types of samples were derived from the same community), we defined Sample ID as a random effect.
Since the response was binomial, we assumed a logit‐link and binomially distributed error

```{r detection probability}
# Use joint to get a table of expected/absent
det_table <- joint %>% 
  filter(material_type=="DrosMock") %>%
  mutate(detected = case_when(
    expected > 0 & observed > 0 ~ 1,
    expected > 0 & observed == 0 ~ 0,
    TRUE ~ as.numeric(NA)
    )) %>%
  filter(!is.na(detected)) %>% #Still some false positives remeaining!
  mutate(extract_id = sample_name %>%
           str_remove_all("BF1-BR1-|fwhF2-fwhR2n-|SauronS878-HexCOIR4-|fwhF2-HexCOIR4-"))

# Estimate detection efficiency of all taxa - Better done within tidymodels?
library(lme4)
detmodel <- det_table %>%
  filter(fcid=="CB3DR") %>%
  dplyr::select(sample_id, extract_id, taxon, detected, target_subfragment) %>%
  #group_by(taxon) %>%
  nest() %>%
  mutate(fit = map(data, ~glmer(detected ~ target_subfragment + (1|extract_id), family=binomial, data = .)), 
           tidied = map(fit, broom::tidy),
           aug = map(fit, broom::augment)

  ) %>%
  dplyr::select(-fit) %>%
  unnest(tidied) 

# Estimate detection efficiency of targets - Doesnt work because they were pretty much all detected!
library(lme4)
det_suzukii <- det_table %>%
  filter(fcid=="CB3DR") %>%
  group_by(taxon) %>%
  nest() %>%
  mutate(fit = map(data, ~glmer(detected ~ target_subfragment + (1|extract_id), family=binomial, data = .)), 
           tidied = map(fit, broom::tidy),
           aug = map(fit, broom::augment)

  ) %>%
  dplyr::select(-fit) %>%
  unnest(tidied) 

det_suzukii
```


## Multifig1

Comparison of primers for bias, off-target amp, and PCA of overlap  

```{r run 1 multifig}
# PCA, off target, and bias
fig1a <- gg.reads_classified / gg.run1pca 
 
fig1 <- fig1a - gg.bias + plot_layout(widths = c(2,1)) + plot_annotation(tag_levels = 'A') & theme(plot.margin = unit(c(1,1,1,1), "mm"))
  
fig1 

# Write out figure 1
pdf(file="fig/run1_multifig.pdf", width = 11, height = 8 , paper="a4r")
  plot(fig1)
try(dev.off(), silent=TRUE)

# Problems to fix -  how does the PCA change with the filtered vs unfiltered data?
# look at level of off-target amp
```

# Supplementary Comparison of primer replicates for detection and bias

# Run 2 - comparison between replicate primers

Run 2 - see the differences in bias between replicates

```{R run2}
# RUN 2
ps_run2 <- readRDS("output/rds/ps_idtaxaExact.rds") %>%
  subset_samples(fcid %in% c("CK3HD")) %>%
  filter_taxa( function(x) mean(x) > 0, TRUE) %>%
  speedyseq::tax_glom(taxrank="Species")

exp <- read_csv("sample_data/expected_quant_merged.csv") %>%
  dplyr::rename(sample_name = Sample) %>%
  pivot_longer(-sample_name,
               names_to= "taxon",
               values_to= "expected") %>%
  mutate(taxon = str_replace(taxon, pattern=" ",replacement="_"),
         sample_name = str_remove(sample_name, "-exp*.$")) %>%
  dplyr::filter(!is.na(sample_name),
  !str_detect(sample_name, "CM[0-9]|CT[0-9]|CML[0-9]|Syn"),
  expected > 0) %>%
  distinct()

#Get observed

sam <- ps_run2%>%
  speedyseq::psmelt() %>%
  janitor::clean_names() %>%
  mutate(taxon = species) %>%
  filter(!str_detect(genus, "__")) %>%#Remove unclassified
  dplyr::select(sample_name, sample_id, replicate, taxon, abundance, target_subfragment, fcid, material_type = type) %>%
  mutate(sample_name = sample_name %>%
           str_remove_all("BF1-BR1-|SauronS878-HexCOIR4-|fwhF2-HexCOIR4-|fwhF2-fwhR2n-") %>%
           str_remove_all("HLVKYDMXX_|CK3HD_|CB3DR_|CJKFJ_")) 

#Join tables 
joint <- sam %>%
  filter(taxon %in% exp$taxon,
         sample_name %in% exp$sample_name) %>%
  left_join(exp, by = c("sample_name","taxon")) %>%
  dplyr::rename(observed = abundance) %>%
  mutate(expected = replace_na(expected, 0),
         observed0 = (observed + 0.5) * (expected > 0),
         error = observed0 / expected) %>%
  distinct() %>%
  group_by(sample_id) %>%
  mutate_at(vars(observed, expected), ~ . / sum(.) ) %>% #Convert to proportions
  ungroup()

# Bootstrap estimation
set.seed(606)
boot_models <- joint %>%
  filter(material_type=="DrosMock") %>%
  filter(expected > 0) %>%
  group_by(target_subfragment, replicate) %>%
  group_modify(~{
    bootstraps(.x, times=1000, apparant=TRUE)  %>%
    mutate(fit = map(splits, ~lm(metacal::center_elts(observed0 /expected, na.rm = TRUE) ~ 0 + taxon , data = .)), 
           coef = map(fit, broom::tidy)) %>%
    int_pctl(coef) 
    }) %>%
  mutate(taxon = str_remove(term, "taxon")) %>%
  dplyr::select(target_subfragment, replicate, taxon, lower = .lower, estimate = .estimate, upper = .upper)

# See how well bias estiamte fits data

preds <- joint %>%
  left_join(boot_models) %>%
  dplyr::mutate(predicted = expected * estimate) %>%
  group_by(sample_id) %>%
  mutate_at(vars(predicted), ~ . / sum(., na.rm=TRUE) ) %>%
  filter(expected > 0) %>%
  filter(observed > 0)

# Plot bias estimates for the 3 separate primers
gg.biasreps <- preds %>%
  ungroup() %>%
  dplyr::select(taxon, estimate, upper, lower, target_subfragment, replicate) %>%
  distinct()%>%
  mutate(replicate = factor(replicate, levels = c("1","2","3"))) %>%
  mutate(taxon = str_replace(taxon, "^.*_", "D. ")) %>%
  ggplot(aes(x = taxon, y = estimate-1, colour = replicate, group =replicate)) +
  geom_hline(yintercept = 0, alpha=0.5, colour = "grey20") +
  geom_pointrange(aes(ymin = lower-1, ymax = upper-1), position=position_dodge(width=0.5))+
  facet_grid(~target_subfragment) +
  coord_flip() +
  base_theme+
  scale_colour_brewer(palette="Paired") +
  labs(
    x = NULL,
    y = "Efficiency / Geometric mean",
    colour = "Tagged PCR primer") +
  theme(axis.text.y = element_text(face = "italic"),
        legend.position = "bottom")

gg.biasreps

# Write supplementary figure
pdf(file="fig/run2_biasreps.pdf", width = 11, height = 8 , paper="a4r")
  plot(gg.biasreps)
try(dev.off(), silent=TRUE)
```

# Run 3 - full dataset

## Subset to just run 3
```{r}
ps_run3 <- ps2 %>%
  subset_samples(fcid %in% c("HLVKYDMXX")) %>%
  filter_taxa( function(x) mean(x) > 0, TRUE) %>%
  speedyseq::tax_glom(taxrank="Species")

```
## Alpha diversity metrics

```{r alpha div}
dir.create("output/alpha")

# Get a histogram of taxon sums
taxa_sums(ps_run3) %>%
  as_tibble(rownames = "OTU") %>%
  filter(value > 0) %>%
  ggplot(aes(x = value)) +
  geom_histogram() 

# Get richness measures
richness <- phyloseq::estimate_richness(ps_run3, measures=c("Chao1", "Shannon", "Simpson")) %>% #
  rownames_to_column("sample_name") %>%
  mutate(sample_name = str_replace(sample_name, "\\.", "-"))

#Richness is giving a warning because its acting on the trimemd dataset

#Set number of randomisations for calculating significance
# Calculate Faith's PD-index & Species richness - with Standard errors
sespd <- picante::ses.pd(as(phyloseq::otu_table(ps_run3), "matrix"),  phyloseq::phy_tree(ps_run3), null.model = "taxa.labels", include.root = F, runs = 9)

# Join together
div_table <- sespd %>%
  rownames_to_column("sample_name") %>%
  dplyr::select(sample_name, ntaxa, pd.obs) %>%
  dplyr::rename(pd = pd.obs, alpha = ntaxa) %>%
  left_join(richness, by="sample_name") %>%
  left_join(sample_data(ps_run3) %>% 
              as("data.frame") %>%
              filter(!duplicated(sample_id)) %>%
              dplyr::select(replicate, sample_name = sample_id, type),
            by = "sample_name") 

# Filter to just the field collected types
div_table <- div_table %>%
  filter(type %in% c("DC", "ACV", "FF", "SPD"))

# Summarise means
div_table %>%
  summarise(across(where(is.numeric), mean, na.rm=TRUE))

# Difference in alpha diversity between replicates
#report::report(aov(alpha ~replicate, data=div_table))
#report::report(aov(Shannon ~replicate, data=div_table))
#report::report(aov(pd ~replicate, data=div_table))
#
# Difference in alpha diversity between trap types
report::report(aov(alpha ~type, data=div_table))
broom::tidy(TukeyHSD(aov(alpha ~type, data=div_table)))

report::report(aov(Shannon ~type, data=div_table))
broom::tidy(TukeyHSD(aov(Shannon ~type, data=div_table)))

report::report(aov(pd ~type, data=div_table))
broom::tidy(TukeyHSD(aov(pd ~type, data=div_table)))

# SHould do on the original data without merging by spp

```

## Beta diversity metrics

```{r Distances}
# Get OTU tables
otutab <- otu_table(ps_run3)
#Impute zeroes for compositional distances
otutab_n0 <- as.matrix(zCompositions::cmultRepl(otutab, method="CZM", output="p-counts"))
#Root phylogenetic tree
phy_tree(ps_run3) <- multi2di(phy_tree(ps_run3))

#Calculate different distance metrics
metrics <- c("Bray", "Jaccard", "Aitchison", "Philr", "Unifrac", "WUnifrac")
distlist <- vector("list", length=length(metrics))
names(distlist) <- metrics

distlist$Jaccard <- as.matrix(vegdist(otutab, method="jac",binary = T))
distlist$Bray <- as.matrix(vegdist(otutab, method="bray"))
distlist$Aitchison <- as.matrix(vegdist(CoDaSeq::codaSeq.clr(otutab_n0), method="euclidean"))
distlist$Philr <- as.matrix(vegdist(philr::philr(otutab_n0, phy_tree(ps_run3),
                                                part.weights='enorm.x.gm.counts',
                                                ilr.weights='blw.sqrt'), method="euclidean"))
distlist$Unifrac <- as.matrix(phyloseq::UniFrac(ps_run3_dist, weighted=FALSE, parallel = TRUE))
distlist$WUnifrac <- as.matrix(phyloseq::UniFrac(ps_run3_dist, weighted=TRUE, parallel = TRUE))

# Probably only need to use philr dist
```

# Adonis and betadisper
```{r betatest}
# Adonis test
metadata <- sample_data(ps_run3_dist) %>%
  as("data.frame")

# Test difference by community type
adonis_results <- distlist %>%
  purrr::map(function(x) {
    bind_rows(
    broom::tidy(adonis(x~type, method="euclidean", data=metadata)$aov.tab) %>% dplyr::slice(1)
    )
})  %>%
  bind_rows(.id="dist")

# Check homogeneity
betadisper_results <- distlist %>%
  purrr::map(function(x) {
    y <- as.dist(x[metadata$sample_id, metadata$sample_id])
  bind_rows(
    as.data.frame(permutest(vegan::betadisper(y, metadata$type))$tab) %>%
      dplyr::slice(1) %>% 
      mutate(term="type")
  )
})  %>%
  bind_rows(.id="dist")

dir.create("output/beta")
write_csv(adonis_results, "output/beta/adonis.csv")
write_csv(betadisper_results, "output/beta/adonis.csv")
```

# PCA plots

```{r pca plots}
phy_tree(ps_run3) <- multi2di(phy_tree(ps_run3))
phy_tree(ps_run3) <- makeNodeLabel(phy_tree(ps_run3), method="number", prefix='n')

# Get philr distance
ps_run3.philr <- philr::philr(otutab_n0, phy_tree(ps_run3),
                     part.weights='enorm.x.gm.counts', 
                     ilr.weights='blw.sqrt')

#Philr PCOA

philr.dist <- dist(ps_run3.philr , method="euclidean")
philr.pcoa <- ordinate(ps_run3, 'PCoA', distance=philr.dist)

gg.pca <- plot_ordination(ps_run3, philr.pcoa, color = "type") +
  geom_point(size=3, alpha=0.8) +
  geom_hline(yintercept = 0, linetype=2, alpha=0.5) +  
  geom_vline(xintercept = 0, linetype=2, alpha=0.5) +
  base_theme +
  #coord_fixed() +
  scale_colour_brewer(palette="Paired") +
  theme(legend.position = "bottom") +
  labs(colour = "Sample Type")

gg.pca

# Heirarchial clustering
dend <- hclust(philr.dist, method="average")

p3 <- ggtree(as.phylo(dend) ) + 
  theme_tree2()

colours_p3 <- p3$data %>%
  left_join(as_data_frame(sample_data(ps_run3)) %>%
              dplyr::select(sample_id, type) %>%
  dplyr::rename(label = sample_id)
    )

p3 <- p3 %<+% colours_p3  + 
  geom_tippoint(aes(colour=as.factor(type)))  + 
  geom_tiplab(aes(colour=as.factor(type)))+
  scale_colour_brewer(palette="Paired") +
    scale_x_continuous(expand=c(0, 30)) +
  theme(legend.position = "bottom")

# Plot together
p3 + gg.pca

# Plot a heatmap

#Prepare co-occurance matrix
coocur <- ps_run3 %>%
    otu_table %>%
    as.matrix()


# Sample tree 
h_tree <- as.phylo(dend)

# P cophenetic distance
s_tree <- phy_tree(ps_run3)

s_tree <- drop.tip(s_tree, setdiff(s_tree$tip.label, colnames(coocur)))
coocur <- coocur[h_tree$tip.label, s_tree$tip.label]

#Could do the imputing on coocur

# Cophyloplot
coocur.lut <- which(coocur >0, arr.ind=TRUE)
assoc <- cbind(rownames(coocur)[coocur.lut[,1]], colnames(coocur)[coocur.lut[,2]])
# Rotate the nodes using phytools
obj <- cophylo(tr1=h_tree, tr2=s_tree, assoc=assoc, rotate=TRUE) 

# Extract the goods for ggtree
tree1 <- obj[["trees"]][[1]]
p1 <- ggtree(tree1, ladderize=FALSE) + geom_tiplab()

# OTU tree
tree2 <- obj[["trees"]][[2]]
p2 <- ggtree(tree2, ladderize=FALSE) + geom_tiplab()

# Tanglegram
dd <- obj$assoc %>%
  as_data_frame() %>%
  magrittr::set_colnames(c("label.x", "label.y")) %>%
  left_join(p1$data %>% dplyr::select(label, y) %>% dplyr::rename(label.x = label), by="label.x") %>%
  left_join(p2$data %>% dplyr::select(label, y) %>% dplyr::rename(label.y = label), by="label.y") %>%
  rownames_to_column("assoc")

gg.heatmap <- dd %>%
  dplyr::rename(Sample_Name = label.x,
                OTU = label.y,
                pos_x = y.x,
                pos_y = y.y) %>%
  dplyr::select(Sample_Name, OTU, pos_x, pos_y) %>%
  dplyr::mutate(Sample_Name = factor(Sample_Name),
                Sample_Name = fct_reorder(Sample_Name, pos_x),
                OTU = factor(OTU),
                OTU = fct_reorder(OTU, pos_y)) %>%
   ggplot(aes(x=Sample_Name, y=OTU)) +
  geom_tile() +
  base_theme+
  theme(axis.text.x = element_text(angle=45, hjust=1),
        axis.title.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank(),
        legend.position = "none") 

#Adjusted trees - Sca

top <- wrap_elements(grid::textGrob('')) +(p1+ coord_flip() + scale_x_reverse(expand=c(0,0))+ scale_y_continuous(expand=c(0,0))) + plot_layout(widths=c(1,3)) 
bottom <- p2+ scale_y_continuous(expand=c(0,0)) +gg.heatmap + plot_layout(widths=c(1,3))

gg.treemap <- top / bottom + plot_layout(heights=c(1,3))                                                         

gg.treemap

gg.heatmap <- psmelt(ps_run3) %>%
  dplyr::select(Abundance, label = sample_id, OTU, rank_names(ps_run3)) %>%
  left_join(p3$data) %>%
  group_by(label) %>%
  mutate(Abundance = replace(Abundance, Abundance==0, 0.5)) %>%
  mutate(Abundance = metacal::clr(Abundance, na.rm = TRUE)) %>%
  ungroup %>%
  ggplot(aes(x = label, y = Species, fill = Abundance )) +
  geom_tile() +
  base_theme
  
(p3 + coord_flip() + scale_x_reverse()) / gg.heatmap

gg.heatmap <- dd %>%
  dplyr::rename(Sample_Name = label.x,
                OTU = label.y,
                pos_x = y.x,
                pos_y = y.y) %>%
  dplyr::select(Sample_Name, OTU, signif, pos_x, pos_y) %>%
  dplyr::mutate(Sample_Name = factor(Sample_Name),
                Sample_Name = fct_reorder(Sample_Name, pos_x),
                OTU = factor(OTU),
                OTU = fct_reorder(OTU, pos_y)) %>%
   ggplot(aes(x=Sample_Name, y=OTU, fill=as.factor(signif))) +
  geom_tile() +
  theme_bw() +
  theme(axis.text.x = element_text(angle=45, hjust=1),
        axis.title.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank(),
        legend.position = "none") +
  scale_y_discrete(position = "right")+
  scale_fill_manual(values=c("steelblue","darkorange1"), na.translate=FALSE) 
#Adjusted trees - Sca
p3 <- p2 + 
  geom_text2(aes(subset=!isTip, label=group %>% na_if(0)), hjust=1, check_overlap=TRUE)
top <- wrap_elements(grid::textGrob('')) +(p1+ coord_flip() + scale_x_reverse(expand=c(0,0))+ scale_y_continuous(expand=c(0,0))) + plot_layout(widths=c(1,3)) 
bottom <- p3+ scale_y_continuous(expand=c(0,0)) +gg.heatmap + plot_layout(widths=c(1,3))
gg.treemap <- top / bottom + plot_layout(heights=c(1,3))                                                         
gg.treemap
pdf(file="figs/psyllid_microbiome_heatmap.pdf",  width = 8, height = 11, paper="a4")
  plot(gg.treemap)
try(dev.off(), silent=TRUE)




```

# Fit GLMnet

from philr tutorial https://bioconductor.org/packages/devel/bioc/vignettes/philr/inst/doc/philr-intro.html
```{r glmnet}
library(glmnet)

# Predict mock vs real
sample_data(ps2)$mock <- factor(get_variable(ps2, "type") %in% c("Mock", "POS"))

glmmod <- glmnet(ps2.philr, sample_data(ps2)$type, alpha=1, family="multinomial")

# Get coords usign tidy insteaed
tidied <- tidy(glmmod) %>% 
  filter(!term == "(Intercept)",
         !term == ""
         )%>%
  mutate(node = name.to.nn(phy_tree(ps2), term))

ggplot(tidied, aes(step, estimate, group = term)) +
  geom_line()

#tc.colors <- c('#a6cee3', '#1f78b4')
p <- ggtree(phy_tree(ps2), layout='fan') +
  geom_balance(node=2843, alpha=0.6) # get node number from the tidied dev.node
p <- annotate_balance(phy_tree(ps2), 'n16', p=p, labels = c('n16+', 'n16-'),
                 offset.text=0.15, bar=FALSE)
annotate_balance(tree, 'n730', p=p, labels = c('n730+', 'n730-'),
                 offset.text=0.15, bar=FALSE)
```


# Phylogeny of trap catches

```{r Phylogeny}

# For presentation
test <- ps2 %>% 
  phyloseq::subset_samples(sample_name == "HLVKYDMXX_T10SPD-ex1") %>%
    #filter_taxa( function(x) mean(x) > 0, TRUE) %>%
  tax_glom("Species")

tree <- phy_tree(test)

ggtree(tree, layout="circular") + coord_polar(theta='y')+ scale_x_reverse(limits=c(4, 0)) + geom_tippoint(color="steelblue", size=2, alpha=.8)

ggtree(tree) + geom_tippoint(color="steelblue", size=2, alpha=.8)


```

# Phylofactorisation

Need to decide if i want to associate abundance on the phylogeny,

or presence absense, which isnt gaussian distributed and therefore requires use of theh 'geeneralised phylofactorisation'

```{r phylofactor}
devtools::install_github('reptalex/phylofactor')
library(phylofactor)
# Example data
data("FTmicrobiome")


# Get OTU table
OTUTable <- FTmicrobiome$OTUTable   #Our OTU table. Rows are OTUs and columns are samples
OTUTable[1:5,1:5]
#Note doesnt seem to have column names - is this necessaty

# Get OTU tables
otutab <- otu_table(ps_run3)
#Impute zeroes for compositional distances
otutab_n0 <- t(as.matrix(zCompositions::cmultRepl(otutab, method="CZM", output="p-counts")))
#Root phylogenetic tree
phy_tree(ps_run3) <- multi2di(phy_tree(ps_run3))

# Get independant variable
metadata <- sample_data(ps_run3) %>%
  as("data.frame") %>%
  dplyr::arrange(sample_id, colnames(otutab_n0)) %>%
  mutate(type = factor(type))


length(metadata) == length(colnames(otutab_n0))

# get tree
tree<- multi2di(phy_tree(ps_run3))
#plot tree
ggtree(tree)

# Get taxonomy and convert format
tax <- tax_table(ps_run3) %>%
  as("matrix") %>%
  as_tibble(rownames = "OTU") %>%
  mutate(across(rank_names(ps_run3), ~replace(.x, str_detect(.x, "__"), ""))) %>%
  pivot_longer(rank_names(ps_run3),
               names_to="rank",
               values_to="name") %>%
  mutate(name = paste0(str_to_lower(str_extract(rank, ".")), "__", name)) %>%
  pivot_wider(names_from = rank,
              values_from = name) %>%
  unite(taxonomy, rank_names(ps_run3), sep="; ") %>%
  as.data.frame()
  
#Phylofactor
trap_factor <- PhyloFactor(Data = otutab_n0,
                           tree = tree,
                           X = metadata, 
                           frmla = type~Data,
                           family=binomial,
                           nfactors=NULL)
trap_factor

# Will need to integrate the sampling week into this model somehow!

# Plto phylo heatmap
cols <- viridis::viridis(3)
pf.heatmap(tree=tree, Data=otutab_n0,color=NA)


library(phytools)
clr <- function(Matrix) apply(Matrix,MARGIN=2,FUN=function(x) log(x)-mean(log(x)))

par(mfrow=c(1,1))
phylo.heatmap(tree, clr(trap_factor$Data))

# Do a regular heatmap of the species most associated with clustering of samples. Then we can use the regression functions behind phylofactor?

# also do a circular heatmap with them


# Get taxonomy - needs to be in qiime format? - may need to convert
taxonomy <- FTmicrobiome$taxonomy   #Our taxonomy
taxonomy[1:3,]
test <- taxonomy %>% separate(taxonomy, sep=";", into = c("Kingdom", "phylum", "class", "order", "family","genus", "species"))

# Filter to common OTUS - may not be necessary for me if i glom at species and am filtering using the logit already
common.otus <- which(rowSums(OTUTable>0)>10)

OTUTable <- OTUTable[common.otus,]                        
tree <- ape::drop.tip(tree,setdiff(tree$tip.label,rownames(OTUTable)))  #trim our tree accordingly

#Optional - replace zeroes with my own method as phylofactor just automatically uses a pseudocount 

#Phylofactor
PF <- PhyloFactor(OTUTable,tree,body.site,nfactors=3)
class(PF)

# Plto phylo heatmap
library(phytools)
clr <- function(Matrix) apply(Matrix,MARGIN=2,FUN=function(x) log(x)-mean(log(x)))

par(mfrow=c(1,1))
phylo.heatmap(tree,clr(PF$Data))
```


## Occupancy modelling

### eDNAoccupancy
```{r edna occupancy}

library(eDNAoccupancy)
data(fungusDetectionData)
data(fungusSurveyData)

# Make detection table
ps_qual <- ps %>%
  speedyseq::tax_glom(taxrank="Species") %>%
  transform_sample_counts(function (x) (x > 0) * 1) %>%
  #merge_samples(group = "ExtractID") %>%
  speedyseq::psmelt() %>%
  select(Sample, Abundance, Species) %>%
  separate(Sample, into=c("site", "rep"), sep="-rep") %>%
  mutate(rep=paste0("pcr",rep)) %>%
  separate(site, into=c("site", "sample"), sep="-ex") %>%
  pivot_wider(names_from=rep, values_from = Abundance, values_fill=list(Abundance = 0)) 

det_suzukii <- ps_qual %>%
  mutate(site = str_replace(site, "DM", "D100M")) %>%
  filter(Species=="Drosophila_suzukii") %>%
  filter(str_detect(site,"D100M|D250M|D500M|D1000M")) %>%
  select(site, sample, pcr1, pcr2, pcr3) %>%
  mutate(sample = as.integer(sample)) %>%
  arrange(sample) %>%
  as.data.frame()

suzukii_detections = occData(det_suzukii, siteColName = 'site',
                            sampleColName = 'sample')

#Make covariate tables

# Read in expected table
exp <- read_csv("sample_data/expected_quant_merged.csv") %>%
  gather(Species, Actual, -X1) %>%
  mutate(Species = str_replace(Species, pattern=" ",replacement="_")) %>%
  filter(str_detect(X1,"D100M|D250M|D500M|D1000M|DLarv")) %>%
  drop_na() %>%
  set_colnames(c("Sample","Species","Actual"))
# Add true presence

#Add community size covariate

commsize <- exp %>%
  group_by(Sample) %>%
  summarise(commsize = sum(Actual)) %>%
  mutate(Sample = str_replace_all(Sample, pattern="(-)(.*?)(?=$)", replacement=""))

survey_data <- samdf %>%
  remove_rownames() %>%
  mutate(Sample = str_replace_all(ExtractID, pattern="(-)(.*?)(?=$)", replacement="")) %>%
  select(Sample, geo_loc_name, material) %>%
  left_join(commsize, by="Sample") %>%
  rename(site = Sample) %>%
  filter(str_detect(site,"D100M|D250M|D500M|D1000M")) %>%
  unique()

# Add alpha diversity covariates

# Try using hill numbers for these https://github.com/anttonalberdi/hilldiv

#estimate richness
alpha_table <- phyloseq::estimate_richness(ps2)

# Calculate Faith's PD-index
pdtable <- picante::pd(as(phyloseq::otu_table(ps2), "matrix"), phyloseq::phy_tree(ps2), include.root = F)




 ## number of detections per sample
 head(suzukii_detections$y)
 ## number of PCR replicates per sample
 head(suzukii_detections$K)

#We fit a multi-scale occupancy model without covariates and print a summary of the parameter estimates using the following code.

 set.seed(69)
 fit = occModel(detectionMats=suzukii_detections, niter=11000,
                niterInterval=5000)
 posteriorSummary(fit, burnin=1000, mcError=TRUE)


## Center and scale numeric-valued covariate measurements
survey_data.sc = scaleData(survey_data)

set.seed(0157)
fit = occModel(formulaSite          = ~ 1,
               formulaSiteAndSample = ~ commsize,
               formulaReplicate     = ~ commsize,
               detectionMats        = suzukii_detections,
               siteData             = survey_data.sc,
               niter                = 6000,
               niterInterval        = 2000,
               siteColName = 'site'
               )
posteriorSummary(fit, burnin=1000, mcError=TRUE)


#If we want to assess whether the Markov chain used to compute these estimates appears to have converged, trace plots of the parameters may be created as follows (Fig.~\ref{fig:TracePlotFungusAnalysis}).
plotTrace(fit, c('beta.(Intercept)', 'alpha.(Intercept)', 'alpha.frogs',
            'delta.(Intercept)'),  burnin=1000)

#Autocorrelation plots of the parameters are created similarly
 plotACF(fit, c('beta.(Intercept)', 'alpha.(Intercept)', 'alpha.frogs',
             'delta.(Intercept)'),  burnin=1000)

#After inspection of these plots, suppose we decide that the MCMC algorithm needs to be run longer, either to eliminate the transient portion of the Markov chain or to reduce Monte Carlo errors in the parameter estimates.  We can resume the MCMC algorithm for the currently fitted model as follows.
 fit = updateOccModel(fit, niter=5000, niterInterval=2000)
 posteriorSummary(fit, burnin=1000,  mcError=TRUE)

 #These estimates of the parameters are computed using the updated Markov chain containing \rinline{fit$niterations} iterations.  The Monte Carlo errors in these parameter estimates are slightly lower, but the estimates are otherwise similar to those computed with only \rinline{fit$niterations-5000} iterations.

#In addition to estimating posterior summaries of the model's formal parameters, we also may be interested in estimating posterior summaries of derived parameters.  For example, in the second model fitted to the \emph{Bd} data, the probability of eDNA occurrence in ponds was assumed to be constant ($\psi$), the conditional probability of eDNA occurrence in samples was assumed to be a function of the frog density index \code{frogs}, and the conditional probability of eDNA detection was assumed to be constant ($p$).  The posterior medians of these derived parameters are estimated as follows.

psi = posteriorSummaryOfSiteOccupancy(fit, burnin=1000)
theta = posteriorSummaryOfSampleOccupancy(fit, burnin=1000)
p = posteriorSummaryOfDetection(fit, burnin=1000)

 ## output estimates of posterior medians
 cbind(psi=psi$median, theta=theta$median[,1], p=p$median[,1])

 frogs = fungusSurveyData[, 'frogs']
 plot(frogs, theta$median[,1], ylim=c(0,1), xlim=c(0,0.8), cex=2)
 segments(frogs, theta$lower[,1], frogs, theta$upper[,1], lwd=2)
 
#One way to assess the relative importance of such estimated relationships is to compare competing models using model-selection criteria.  For example, we compute the PPLC and WAIC criteria for the previously fitted model as follows.
 posteriorPredictiveLoss(fit, burnin=1000)
 WAIC(fit, burnin=1000)

```

###Seak occupancy

Seak occupancy modelling - The model is fitted within a Bayesian framework and any of the model parameters can be functions of covariates. The implemented algorithm performs Bayesian variable selection and the output includes posterior summaries of all parameters as well as posterior probabilities of inclusion (see examples for a more detailed description of how to interpret the output).

The model has been developed for single species qPCR data. The data are the number of positive qPCRs (eDNA score) for each water sample collected at surveyed sites. The model allows us to estimate the probability of species presence at each survey site, while accounting for the probabilities of a false positive and false negative error at stage 1 (field) and stage 2 (lab).



Occupancy modelling calculates the probability of detection from a number of replicates. ie - 6 replicates positive = 100% probaiblity , 5/6 = 85% probability

Nested levels = Replicated extractions, replicated PCRs .

Could fit a single specied


For model taking into accoutn false poositives and negatives: https://seak.shinyapps.io/eDNA/

This requires format

Columns = Sample (extraciton replicate ) so 2 columns
Rows = site (trap)
cell value = number of positive PCR replicates (out of 3)
Column 3 = True presence or absense 1 or 0
column 4,5,6 etc other covariates. Sequencing depth, community size, species richness,trap type, phylogenetic richness... etc



```{r occupancy}
#convert to presence/absense
ps_qual <- ps %>%
  speedyseq::tax_glom(taxrank="Species") %>%
  transform_sample_counts(function (x) (x > 0) * 1) %>%
  merge_samples(group = "Sample_Name") %>%
  speedyseq::psmelt() %>%
  dplyr::select(Sample, Abundance, Species) %>%
  mutate(Sample = str_remove(Sample, "^.*_")) %>%
  separate(Sample, into=c("Sample", "exrep"), sep="-ex") %>%
  pivot_wider(names_from=exrep, values_from = Abundance, values_fill=list(Abundance = 0)) %>%
  dplyr::select(Sample, Species, `1`, `2`,)

# Read in expected table
exp <- read_csv("sample_data/expected_quant_merged.csv") %>%
  gather(Species, Actual, -X1) %>%
  mutate(Species = str_replace(Species, pattern=" ",replacement="_")) %>%
  #filter(str_detect(X1,"D100M|D250M|D500M|D1000M|DLarv")) %>%
  drop_na() %>%
  set_colnames(c("Sample","Species","Actual"))
# Add true presence

true_pres <- exp %>%
  mutate(Sample = str_replace_all(Sample, pattern="(-)(.*?)(?=$)", replacement="")) %>%
  mutate(Actual = case_when(
    Actual > 0 ~ 1,
    Actual == 0 ~ 0
  )) %>%
  unique()
  
#Add community size covariate - need to estimate for others

commsize <- exp %>%
  group_by(Sample) %>%
  summarise(commsize = sum(Actual)) %>%
  mutate(Sample = str_replace_all(Sample, pattern="(-)(.*?)(?=$)", replacement=""))

# add seqdepth covariate

#filterdepth

#richness
richness <- ps_qual %>%
  mutate(Sample = str_replace(Sample, "DM", "D100M")) %>%
  ungroup() %>%
  mutate(total = `1`+`2`) %>%
  filter(total > 0) %>%
  group_by(Sample) %>%
  summarise(richness= n())  

# Species evenness

# Phylogenetic diversity


#trap_type
comm_type <- exp %>%
  mutate(Sample = str_replace_all(Sample, pattern="(-)(.*?)(?=$)", replacement="")) %>%
  mutate(comm_type = case_when(
    str_detect(Sample, "D100M|D250M|D500M|D1000M") ~ "Mock",
    str_detect(Sample, "DLarv") ~ "Larvae",
    str_detect(Sample, "ACV") ~ "ACV",
    str_detect(Sample, "FF") ~ "FF",
    str_detect(Sample, "SPD") ~ "SPD",
    str_detect(Sample, "DC") ~ "DC",
  )) %>%
  dplyr::select(Sample, comm_type) %>%
  unique()
  

# Get suzukii only
det_suzukii <- ps_qual %>%
  mutate(Sample = str_replace(Sample, "DM", "D100M")) %>%
  left_join(true_pres, by=c("Sample", "Species"))%>%
  left_join(commsize, by="Sample") %>%
  left_join(richness, by="Sample") %>%
  left_join(comm_type, by="Sample") %>%
  filter(Species == "Drosophila_suzukii") %>%
  dplyr::select(-Species) %>%
  unique() %>%
  mutate(Actual = replace_na(Actual, 0))  %>%
  filter(!is.na(commsize)) %>%
  mutate(commsize = scale(commsize, center = TRUE, scale = TRUE))  %>%
  #mutate(random = scale(rbinom(nrow(.), 100, 0.7), center = TRUE, scale=TRUE)) %>%
  #mutate(random2 = scale(rbinom(nrow(.), 100, 0.4), center = TRUE, scale=TRUE)) %>%
  mutate(richness = scale(richness, center = TRUE, scale = TRUE))  %>%
  filter(!str_detect(Sample, "DLarv"))# %>%
  #set_rownames(.$Sample) #%>%
  dplyr::select(-Sample)
  
write.csv(det_suzukii, "test_occupancy_suzukii.csv", row.names=FALSE)

```

For sequencing depth covariate could you just rarefy to certain depth, recalculate detection, then rbind a longer table together in a loop
Same with filtering threshold



these could be fit seperately for our 3 target species

Then we can look at how the detection probability changes across different filtering thresholds used to remove index switching?


To test if probability of detection differs as a function of sample water volume, we used the eDNAoccupancy R package (version 0.2.4; Dorazio & Erickson, 2017) to model probabilities of eDNA detection. This package fits Bayesian, multi‐scale occupancy models to our data, which included three, nested levels of sampling: stream location, replicated water samples collected from each stream, and subsamples (i.e., PCR technical replicates) of each water sample. 



https://onlinelibrary.wiley.com/doi/full/10.1002/edn3.23

https://besjournals.onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2011.00156.x

https://www.pnas.org/content/pnas/116/18/8931.full.pdf

Based on the overall model, a total of seven water samples was
required to achieve >95% detection probabilities of S. mansoni
eDNA at water sample level (θ = 0.35) [as calculated by using
the equation P = 1 − (1 − θ)
n (27)]. By using the same approach,
the model-based estimated number of qPCR replicates required
to achieve detection probabilities >95% ranged from three to
nine replicates between sites


## Check for concordance between mock and real


```{r PCA}
# Read in expected table
exp <- read_csv("sample_data/expected_quant_merged.csv") %>%
  gather(Species, Abundance, -X1) %>%
  mutate(Species = str_replace(Species, pattern=" ",replacement="_")) %>%
  filter(str_detect(X1,"D100M|D250M|D500M|D1000M|DLarv")) %>%
  drop_na() %>%
  set_colnames(c("Sample","Species","Actual"))

# Prepare observed table
sam <- ps.merged %>%
  speedyseq::tax_glom("Species") %>%
  transform_sample_counts(function (x) x/sum(x)) %>%
  speedyseq::psmelt() %>%
  mutate(Species = str_replace(Species, pattern="Drosophila_mauritiana/simulans", replacement= "Drosophila_simulans")) %>%
  mutate(Species = str_replace(Species, pattern="Drosophila_albomicans", replacement= "Drosophila_immigrans")) %>%
  filter(Sample %in% exp$Sample) %>%
  arrange(Abundance) %>%
  distinct() %>%
  select(Sample, Species, Abundance)

# Join tables
joint <- sam %>%
  filter(Species %in% exp$Species) %>%
  group_by(Species, Sample) %>% 
  summarise(Abundance = sum(Abundance)) %>%
  ungroup() %>%
  #mutate(Type = ifelse(Sample %in% controls, "Est", "Eval")) %>%
  bind_rows(exp %>%
              mutate(Actual = replace_na(Actual, 0)) %>%
              rename(Abundance = Actual) %>%
              filter(str_detect(Sample, pattern="-ex1"))  %>%
              mutate(Sample = str_replace_all(Sample, pattern="-ex1", replacement="-A")
            
            )) %>%
  group_by(Sample) %>%  
  mutate_at(vars(Abundance), ~ . / sum(.)) %>% # Convert to proportions
  #mutate(Abundance = Abundance + 0.0001) %>% # Add pseudocount
  #mutate(Abundance = clr(Abundance)) %>%
  ungroup()

# PCA
joint_pca <- joint %>%
  pivot_wider(
    names_from = Species, #  Switch this to transpose
    values_from = Abundance,
    values_fill = list(Abundance=0),
  ) %>%
  mutate(Extract = Sample %>% str_replace_all(pattern="(-)(.*?)(?=$)", replacement="")) %>%
  mutate(Mock = Sample %>% 
           str_replace_all(pattern="(-)(.*?)(?=$)", replacement="") %>%
           str_replace_all(pattern="(^)(.*?)(?<=M)", replacement="")) %>%
  nest(data = everything()) %>%
  mutate(pca = map(data, ~ prcomp(.x %>% select(-Sample, -Extract, -Mock), 
                                  center = TRUE, scale = TRUE)),
         pca_aug = map2(pca, data, ~augment(.x, data = .y))) 

joint_pca$pca %>%
  map(~tidy(.x, data = .y, "pcs")) %>%
  as.data.frame() %>%
  ggplot(aes(x = PC, y=percent)) +
  geom_bar(stat="identity") + labs(x="PC",y="Variance Explained")


library(RColorBrewer)
col <- colorRampPalette(brewer.pal(11, "Spectral"))(25)

joint_pca %>%
  mutate(
    pca_graph = map2(
      .x = pca,
      .y = data,
      ~ autoplot(.x, loadings = TRUE, loadings.label = TRUE,
                 loadings.label.repel = FALSE,
                 data = .y, label = TRUE,
                 label.label = "Sample",
                 label.repel = TRUE, 
                 colour='Extract') +
       #theme_bw() +
        labs(x = "Principal Component 1",
             y = "Principal Component 2",
             title = "First two principal components of PCA for expected and observed") +
        coord_fixed()#+
       # scale_colour_manual(values=col)
    )
  ) %>%
  pull(pca_graph)


## Heirarchial clustering


# Output drosophila summary
ps.merged %>% 
  subset_taxa(Family=="Drosophilidae") %>%
  microbiome::transform("compositional") %>%
  summarise_taxa("Species", "sample_id") %>%
  filter(!str_detect(sample_id, "NTC")) %>%
  #filter(str_detect(Species, "Drosophila|Scaptodrosophila")) %>%
  spread(key="sample_id", value="totalRA") %>%
  write.csv(file = "output/csv/unfiltered/drosophila_spp_sum.csv")

```


# Reproducability Receipt

```{details, echo = FALSE, details.summary = 'Reproducability receipt'}
# datetime
Sys.time()
#repository
git2r::repository()
sessioninfo::session_info()
```

