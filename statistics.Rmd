---
title: "Statistics"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

## Load packages
```{r setup}
#Set required packages
.cran_packages <- c("tidyverse", 
                    "patchwork", 
                    "vegan", 
                    "seqinr",
                    "ape", 
                    "RColorBrewer",
                    "ggtree", 
                    "castor", 
                    "picante",
                    "skimr")
.bioc_packages <- c("dada2",
                    "phyloseq", 
                    "DECIPHER",
                    "Biostrings",
                    "ShortRead", 
                    "philr",
                    "ALDEx2")

.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install(.bioc_packages[!.inst], ask = F)
}

sapply(c(.cran_packages,.bioc_packages), require, character.only = TRUE)

# Github packages
devtools::install_github("alexpiper/taxreturn")
library(taxreturn)
devtools::install_github("alexpiper/seqateurs")
library(seqateurs)
devtools::install_github("mikemc/speedyseq")
library(speedyseq)
#devtools::install_github('ggloor/CoDaSeq/CoDaSeq')
library(CoDaSeq)

#Source internal functions
source('R/helper_functions.R')
options(stringsAsFactors = FALSE)
```

## Make Phyloseq object

Following taxonomic assignment, the sequence table and taxonomic table are merged into a single phyloseq object alongside the sample info csv.

We then make a plot to evaluate the effectiveness of taxonomic assignment to each rank

```{r create PS, eval = FALSE}
## Just subset to the last run
seqtab <- readRDS("output/rds/seqtab_final.rds")
seqtab <- seqtab[str_detect(rownames(seqtab), "HLVKYDMXX"),]
seqtab <- seqtab[,colSums(seqtab) > 0]

rownames(seqtab)  <- rownames(seqtab) %>%
  str_remove("^HLVKYDMXX_") %>%
  str_remove("\\..*$")%>%
  str_replace("\\_.*\\_...", replacement="_") %>%
  str_replace("_$", "_1") 

tax <- readRDS("output/rds/tax_IdTaxaExact.rds") 
seqs <- DNAStringSet(colnames(seqtab))
names(seqs) <- seqs
phy <- readRDS("output/rds/phytree.rds")$tree

#### Rename problematic samples
rownames(seqtab)  <- rownames(seqtab) %>%
 str_replace_all("D250M1-", "D250M4REP-") %>% #Dont think this is necessart
 str_replace_all("D250M2-", "D250M5REP-") %>% # Makes sense on PCA
 str_replace_all("D250M3-", "D250M1REP-") %>% # Way off on PCA
 str_replace_all("D250M4-", "D250M2REP-") %>%
 str_replace_all("D250M5-", "D250M3REP-") %>%
 str_replace_all("D500M1-", "D500M4REP-") %>%
 str_replace_all("D500M2-", "D500M5REP-") %>%
 str_replace_all("D500M3-", "D500M1REP-") %>%
 str_replace_all("D500M4-", "D500M2REP-") %>%
 str_replace_all("D500M5-", "D500M3REP-") %>% # This should maybe be M2?
 str_replace_all("D1000M1-", "D1000M3REP-") %>%
 str_replace_all("D1000M2-", "D1000M4REP-") %>%
 str_replace_all("D1000M3-", "D1000M5REP-") %>%
 str_replace_all("D1000M4-", "D1000M1REP-") %>%
 str_replace_all("D1000M5-", "D1000M2REP-") %>%
 str_replace_all("REP", "")

#Load sample information
## ---- samdat ----
samdf <- read.csv("sample_data/Sample_info.csv", header=TRUE) %>% 
  mutate(Sample_ID = paste0(Sample_Name, "_", replicate) %>%
  str_remove("^HLVKYDMXX_")) %>%
  filter(FCID=="HLVKYDMXX") %>%
  #mutate(Sample_ID = paste0(FCID, "-", Sample_ID)) %>%
  filter(!(index=="ATCGATCG" & index2=="ATCACACG"), #CT11-ex1 duplicated
         !(index=="TCGCTGTT" & index2=="ACTCCATC") # CT12-ex1 duplicated
         ) %>%
  mutate(type = case_when(
    str_detect(Sample_ID, "^D")  ~ "Mock",
    str_detect(Sample_ID, "SPD")  ~ "SPD",
    str_detect(Sample_ID, "ACV")  ~ "ACV",
    str_detect(Sample_ID, "DC")  ~ "DC",
    str_detect(Sample_ID, "FF")  ~ "FF",
    str_detect(Sample_ID, "NTC")  ~ "NTC",
    str_detect(Sample_ID, "POS")  ~ "POS",
    str_detect(Sample_ID, "CT")  ~ "CarpTrap",
    str_detect(Sample_ID, "CM")  ~ "CarpMock"
  )) %>%
  magrittr::set_rownames(.$Sample_ID)

# Will probably need to rename the seqtabs and append the flowcell number onto the samples before they are merged

## ---- phyloseq ----
ps <- phyloseq(tax_table(tax), 
               sample_data(samdf),
               otu_table(seqtab, taxa_are_rows = FALSE),
               phy_tree(phy),
               refseq(seqs))

if(nrow(seqtab) > nrow(sample_data(ps))){warning("Warning: All samples not included in phyloseq object, check sample names match the sample metadata")}

rownames(samdf)[which(!rownames(sample_data(ps))  %in% rownames(samdf))]

# Rename all taxa
taxa_names(ps) <- paste0("SV", seq(ntaxa(ps)),"-",tax_table(ps)[,7])

saveRDS(ps, "output/rds/ps_idtaxaExact.rds") 

#Rename synthetic orders
tax_table(ps)[,2][which(str_detect(tax_table(ps)[,7], "Synthetic"))] <- "Arthropoda"

ps <- ps %>%
  subset_samples(!str_detect(Sample_ID, "^CT|^CM") # remove carpophilus
  ) %>%
  subset_taxa(Phylum == "Arthropoda") %>%
  filter_taxa( function(x) mean(x) > 0, TRUE) 

dir.create("output/csv")
dir.create("output/csv/unfiltered/")

##Export raw csv
export <- speedyseq::psmelt(ps) %>%
  filter(Abundance > 0)
write.csv(export, file = "output/csv/rawdata.csv")

#Summary export
library(data.table)
seqateurs::summarise_taxa(ps, "Species", "Sample_ID") %>%
  filter(str_detect(Sample_ID, "NTC")) %>%
  #filter(str_detect(Species, "Drosophila|Scaptodrosophila")) %>%
  spread(key="Sample_ID", value="totalRA") %>%
  write.csv(file = "output/csv/unfiltered/spp_sum.csv")

seqateurs::summarise_taxa(ps, "Genus", "Sample_ID") %>%
  spread(key="Sample_ID", value="totalRA") %>%
  write.csv(file = "output/csv/unfiltered/gen_sum.csv")

##Output fasta of all ASV's - Name each one by abundance + Taxonomic assignment
seqateurs::ps_to_fasta(ps, "output/all_taxa.fasta")
```


### Summary statistics

```{r sum taxa}
# N unique species and samples
speedyseq::psmelt(ps) %>%
  summarise(n_extracts = n_distinct(Sample_Name), n_samples = n_distinct(Sample_ID))

# Spread of reads
speedyseq::psmelt(ps) %>%
  group_by(Sample_Name) %>%
  summarise(Abundance = sum(Abundance)) %>%
  ungroup() %>%
  summarise(mean = mean(Abundance), 
            se = sd(Abundance)/sqrt(length(Abundance)),
            max = max(Abundance),
            min = min(Abundance))

# Spread of ASVs
speedyseq::psmelt(ps) %>%
  group_by(Sample_Name) %>%
  dplyr::filter(Abundance > 0) %>%
  summarise(counts = n_distinct(OTU)) %>%
  ungroup() %>%
  summarise(mean = mean(counts), 
            se = sd(counts)/sqrt(length(counts)),
            max = max(counts),
            min = min(counts))

#Fraction of reads assigned to each taxonomic rank
speedyseq::psmelt(ps) %>%
  gather("Rank","Name", rank_names(ps)) %>%
  group_by(Rank) %>% 
  mutate(Name = replace(Name, str_detect(Name, "__"), NA)) %>% # This line turns the "__" we added to lower ranks back to NA's
  dplyr::summarise(Reads_classified = sum(Abundance * !is.na(Name))) %>%
  mutate(Frac_reads = Reads_classified / sum(sample_sums(ps))) %>%
  mutate(Rank = factor(Rank, rank_names(ps))) %>%
  arrange(Rank)

#Fraction of ASV's assigned to each taxonomic rank
tax_table(ps) %>%
  as("matrix") %>%
  as_tibble(rownames="OTU") %>%
  gather("Rank","Name",rank_names(ps)) %>%
  group_by(Rank) %>%
  mutate(Name = replace(Name, str_detect(Name, "__"), NA)) %>% # This line turns the "__" we added to lower ranks back to NA's
  dplyr::summarise(OTUs_classified = sum(!is.na(Name))) %>%
  mutate(Frac_OTUs = OTUs_classified / ntaxa(ps)) %>%
  mutate(Rank = factor(Rank, rank_names(ps))) %>%
  arrange(Rank)

# Unique taxa at each rank
speedyseq::psmelt(ps) %>%
  dplyr::select(rank_names(ps)) %>%
  pivot_longer(everything(),
               names_to = "Rank",
               values_to = "value") %>%
  mutate(value = case_when(
    str_detect(value, "__") ~ as.character(NA),
    !str_detect(value, "__") ~ value
  )) %>%
  drop_na() %>%
  group_by(Rank) %>%
  summarise_all(funs(n_distinct)) %>%
  mutate(Rank = factor(Rank, rank_names(ps))) %>%
  arrange(Rank)
```


### Prevalence assesment

```{R prevalence}
# Calculate taxon prevalence across the data set at OTU level

#Prevalence matrix
prevdf <- ps %>%
    otu_table %>%
  apply(2, function(x) ifelse(x > 0, 1, 0)) %>%
  colSums() %>%
  as.data.frame() %>%
  rownames_to_column("OTU") %>%
  magrittr::set_colnames(c("OTU", "prevalence")) %>%
  left_join(taxa_sums(ps) %>%
              as.data.frame %>%
  rownames_to_column("OTU")%>%
  magrittr::set_colnames(c("OTU", "abundance"))) %>%
  left_join(tax_table(ps)%>%
               as.data.frame %>%
  rownames_to_column("OTU"))
  
#Prevalence plot
gg.prev <- prevdf %>%
  ggplot(aes(x=abundance, y=prevalence / nsamples(ps), colour=Genus)) +
  geom_point(size = 3, alpha = 0.7) +
  scale_x_log10() +
  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Order) +
  theme(legend.position="none") +
  ggtitle("Phylum Prevalence in All Samples\nColored by Order")

gg.prev

pdf(file="fig/prevalence.pdf", width = 11, height = 8 , paper="a4r")
  plot(gg.prev)
try(dev.off(), silent=TRUE)

```

## Taxon filtering

```{R taxon filt}
get_taxa_unique(ps, "Order")

ps # Check the number of taxa prior to removal
ps0 <- ps %>%
  subset_taxa(
    Phylum == "Arthropoda" & 
    Class %in% c("Insecta", "Arachnida", "Collembola")
  )
ps # Confirm that the taxa were removed
get_taxa_unique(ps0, "Phylum")
get_taxa_unique(ps0, "Class")
get_taxa_unique(ps0, "Order")
```

# Filter index switching

# Overlap between replicates

Venn diagrams? - Heatmap of presence absense

Species accumulation curve- adding more extraction reps, pcr reps, biological samples, sequence depth

Want to show - Different extraction replicates adds more - but this is probably due to contamination
PCR replicates doesnt add more

# Merge technical replicates

```{r merge replicates}
# Merge replicates
ps.merged <- ps0 %>%
    merge_samples(group = "Sample_Name", fun="sum")

#This loses the sample metadata - Need to add it agian
sample_data(ps.merged) <- sample_data(ps0) %>%
  filter(!duplicated(Sample_Name)) %>%
  magrittr::set_rownames(.$Sample_Name)

ps1 <- ps.merged
```

# Minimum read filtering

```{r minimum reads}
### Remove positive controls
##check mocks
ps1 <- subset_samples(ps1, !str_detect(sample_names(ps1), "POS"))
#message((nsamples(ps1) - nsamples(ps1)), " outlier samples dropped")

ps1 <- prune_samples(sample_sums(ps1) >0 , ps1)

#Plot rarefaction curve
out <- rarecurve(otu_table(ps1), step=10000)

rare <- lapply(out, function(x){
  b <- as.data.frame(x)
  b <- data.frame(OTU = b[,1], count = rownames(b))
  b$count <- as.numeric(gsub("N", "",  b$count))
  return(b)
})
names(rare) <- sample_names(ps1)

rare <- map_dfr(rare, function(x){
  z <- data.frame(x)
  return(z)
}, .id = "sample")

# threshold for read removal
threshold = 1000

gg.rare <- ggplot(data = rare)+
  geom_line(aes(x = count, y = OTU, group=sample), alpha=0.5)+
  geom_point(data = rare %>% 
               group_by(sample) %>% 
               top_n(1, count),
             aes(x = count, y = OTU, colour=(count > threshold))) +
  geom_label(data = rare %>% 
               group_by(sample) %>% 
               top_n(1, count),
             aes(x = count, y = OTU,label=sample, colour=(count > threshold)),
             hjust=-0.05)+
  scale_x_continuous(labels =  scales::scientific_format()) +
  geom_vline(xintercept=threshold, linetype="dashed") +
  labs(colour = "Sample kept?") +
  xlab("Sequence reads") +
  ylab("Observed ASV's")

gg.rare

#Write out figure
pdf(file="fig/rarefaction.pdf", width = 11, height = 8 , paper="a4r")
  plot(gg.rare)
try(dev.off(), silent=TRUE)

#Remove all samples under the minimum read threshold 
ps2 <- prune_samples(sample_sums(ps1)>=threshold, ps1) 
ps2 <- filter_taxa(ps2, function(x) mean(x) > 0, TRUE) #Drop missing taxa from table
message(nsamples(ps1) - nsamples(ps2), " Samples and ", ntaxa(ps1) - ntaxa(ps2), " taxa under read threshold Dropped")
```


## Alpha diversity metrics

```{r alpha div}
dir.create("output/alpha")
# Get richness measures
richness <- phyloseq::estimate_richness(ps2,measures=c("Chao1", "Shannon", "Simpson")) %>% #
  rownames_to_column("Sample_Name") %>%
  mutate(Sample_Name = str_replace(Sample_Name, "\\.", "-"))


#Set number of randomisations for calculating significance
# Calculate Faith's PD-index & Species richness - with Standard errors
sespd <- picante::ses.pd(as(phyloseq::otu_table(ps2), "matrix"),  phyloseq::phy_tree(ps2), null.model = "taxa.labels", include.root = F, runs = 9)

# Join together
div_table <- sespd %>%
  rownames_to_column("Sample_Name") %>%
  dplyr::select(Sample_Name, ntaxa, pd.obs) %>%
  dplyr::rename(pd = pd.obs, alpha = ntaxa) %>%
  left_join(richness, by="Sample_Name") %>%
  left_join(sample_data(ps2) %>% 
              as.data.frame() %>%
              filter(!duplicated(Sample_Name)) %>%
              dplyr::select(replicate, Sample_Name, type),
            by = "Sample_Name") 
# Summarise means
div_table %>%
  summarise_if(is.numeric, mean)

# Difference in alpha diversity between replicates
#report::report(aov(alpha ~replicate, data=div_table))
#report::report(aov(Shannon ~replicate, data=div_table))
#report::report(aov(pd ~replicate, data=div_table))
#
# Difference in alpha diversity between trap types
report::report(aov(alpha ~type, data=div_table))
report::report(aov(Shannon ~type, data=div_table))
report::report(aov(pd ~type, data=div_table))
```

## Rarefied

```{r alpha rarefied}
# Rarefied richness
ps2_rare <- rarefy_even_depth(ps2, sample.size = min(sample_sums(ps2)),
  rngseed = 666, replace = TRUE, trimOTUs = TRUE, verbose = TRUE)

# Get richness measures
richness_rare <- phyloseq::estimate_richness(ps2_rare,measures=c("Chao1", "Shannon", "Simpson")) %>% #
  rownames_to_column("Sample_ID") %>%
  mutate(Sample_ID = str_replace(Sample_ID, "\\.", "-"))

#Set number of randomisations for calculating significance
# Calculate Faith's PD-index & Species richness - with Standard errors
sespd_rare <- picante::ses.pd(as(phyloseq::otu_table(ps2_rare), "matrix"),  phyloseq::phy_tree(ps2_rare), null.model = "taxa.labels", include.root = F, runs = 9)

# Join together
div_table_rare <-  sespd %>%
  rownames_to_column("Sample_ID") %>%
  dplyr::select(Sample_ID, ntaxa, pd.obs) %>%
  dplyr::rename(pd = pd.obs, alpha = ntaxa) %>%
  left_join(richness, by="Sample_ID") %>%
  left_join(sample_data(ps2) %>% 
              as.data.frame() %>%
              filter(!duplicated(Sample_ID)) %>%
              dplyr::select(replicate, Sample_ID, Sample_Name, type),
            by = "Sample_ID") 
# Summarise means
div_table_rare %>%
  summarise_if(is.numeric, mean)

# Difference in alpha diversity between replicates
report::report(aov(alpha ~replicate, data=div_table_rare))
report::report(aov(Shannon ~replicate, data=div_table_rare))
report::report(aov(pd ~replicate, data=div_table_rare))

# Difference in alpha diversity between trap types
report::report(aov(alpha ~type, data=div_table_rare))
report::report(aov(Shannon ~type, data=div_table_rare))
report::report(aov(pd ~type, data=div_table_rare))
```

## Beta diversity metrics

```{r Distances}
ps2_dist <- ps2
# Get OTU tables
otutab <- otu_table(ps2_dist)
#Impute zeroes for compositional distances
otutab_n0 <- as.matrix(zCompositions::cmultRepl(otutab, method="CZM", output="p-counts"))
#Root phylogenetic tree
phy_tree(ps2_dist) <- multi2di(phy_tree(ps2_dist))

#Calculate different distance metrics
metrics <- c("Bray", "Jaccard", "Aitchison", "Philr", "Unifrac", "WUnifrac")
distlist <- vector("list", length=length(metrics))
names(distlist) <- metrics

distlist$Jaccard <- as.matrix(vegdist(otutab, method="jac",binary = T))
distlist$Bray <- as.matrix(vegdist(otutab, method="bray"))
distlist$Aitchison <- as.matrix(vegdist(CoDaSeq::codaSeq.clr(otutab_n0), method="euclidean"))
distlist$Philr <- as.matrix(vegdist(philr::philr(otutab_n0, phy_tree(ps2),
                                                part.weights='enorm.x.gm.counts',
                                                ilr.weights='blw.sqrt'), method="euclidean"))
distlist$Unifrac <- as.matrix(phyloseq::UniFrac(ps2_dist, weighted=FALSE, parallel = TRUE))
distlist$WUnifrac <- as.matrix(phyloseq::UniFrac(ps2_dist, weighted=TRUE, parallel = TRUE))

```

# Adonis and betadisper
```{r betatest}
# Adonis test
metadata <- sample_data(ps2) %>%
  as_data_frame()

# Test difference by community type
adonis_results <- distlist %>%
  purrr::map(function(x) {
    bind_rows(
    broom::tidy(adonis(x~type, method="euclidean", data=metadata)$aov.tab) %>% dplyr::slice(1)
    )
})  %>%
  bind_rows(.id="dist")

# Check homogeneity
betadisper_results <- distlist %>%
  purrr::map(function(x) {
    y <- as.dist(x[metadata$Sample_Name, metadata$Sample_Name])
  bind_rows(
    as.data.frame(permutest(vegan::betadisper(y, metadata$type))$tab) %>%
      dplyr::slice(1) %>% 
      mutate(term="type")
  )
})  %>%
  bind_rows(.id="dist")

dir.create("output/beta")
write_csv(adonis_results, "output/beta/adonis.csv")
write_csv(betadisper_results, "output/beta/adonis.csv")
```

# PCA plots

```{r pca plots}
phy_tree(ps2) <- multi2di(phy_tree(ps2))
phy_tree(ps2) <- makeNodeLabel(phy_tree(ps2), method="number", prefix='n')

# Get philr distance
ps2.philr <- philr::philr(otutab_n0, phy_tree(ps2),
                     part.weights='enorm.x.gm.counts', 
                     ilr.weights='blw.sqrt')
#PCA 
pca <- prcomp(ps2.philr)

#Name balances
pcnames <-  sapply(rownames(pca$rotation), function(x) name.balance(phy_tree(ps2), tax_table(ps2), x))
pcnames <- make.unique(pcnames, sep = ".")
rownames(pca$rotation) <- pcnames

# Get pca data
pca_data <- data.frame(Sample_Name= rownames(pca$x), pca$x[, 1:2])%>%
  left_join(as_data_frame(sample_data(ps2)), by="Sample_Name")

#Get PCA loadings
pca_loadings <- data.frame(OTU = rownames(pca$rotation), pca$rotation[, 1:2])
mult <- min(
    (max(pca_data$PC1) - min(pca_data$PC1)/(max(pca_loadings$PC1)-min(pca_loadings$PC1))),
    (max(pca_data$PC2) - min(pca_data$PC2)/(max(pca_loadings$PC2)-min(pca_loadings$PC2)))
    )
pca_loadings <- transform(pca_loadings,
        v1 = .7 * mult * (pca_loadings$PC1),
        v2 = .7 * mult * (pca_loadings$PC1)
        )

# calculate percent variance explained for the axis labels
pc1 <- round(pca$sdev[1]^2/sum(pca$sdev^2),2)
pc2 <- round(pca$sdev[2]^2/sum(pca$sdev^2),2)
pc_ylab <- paste("PC1: ", pc1, sep="")
pc_xlab <- paste("PC2: ", pc2, sep="")

# Plot PCA
gg.pca <- ggplot(data=pca_data, aes(x=PC2, y=PC1)) + 
  geom_point(aes(fill = type),alpha=0.8, size=3,shape=21, colour="black") +
  theme_classic() +
  scale_fill_brewer(palette="Paired") +
  geom_hline(yintercept = 0, linetype=2, alpha=0.5) +  
  geom_vline(xintercept = 0, linetype=2, alpha=0.5) +
  xlab(pc_xlab) + 
  ylab(pc_ylab) +
  scale_y_continuous(position = "right") + 
  #Add loadings
  geom_text(data=pca_loadings, aes(x=v1, y=v2, label=OTU), 
            size = 5, vjust=1, color="red", check_overlap = TRUE)+
  geom_segment(data=pca_loadings, aes(x=0, y=0, xend=v1, yend=v2),
               arrow=arrow(length=unit(0.2,"cm")), alpha=0.75, color="red")
#coord_fixed(ratio=pc2/pc1) # Scale plot by variance explained

gg.pca

# Heirarchial clustering
dend <- hclust(vegdist(ps2.philr, method="euclidean"), method="average")

p3 <- ggtree(as.phylo(dend) ) + 
  theme_tree2()

colours_p3 <- p3$data %>%
  left_join(as_data_frame(sample_data(ps2)) %>%
              dplyr::select(Sample_Name, type) %>%
  dplyr::rename(label = Sample_Name)
    )
p3 <- p3 %<+% colours_p3  + 
  geom_tippoint(aes(colour=as.factor(type)))  + 
  geom_tiplab(aes(colour=as.factor(type)))+
  scale_colour_brewer(palette="Paired") +
    scale_x_continuous(expand=c(0, 30)) 

# Plot together
p3 + gg.pca

tidied_pca <- broom::tidy(pca, matrix="rotation") %>%
  magrittr::set_colnames(c("term", "component", "value"))

library(tidytext)
tidied_pca %>%
  dplyr::filter(component < 5) %>%
  group_by(component) %>%
  top_n(6, abs(value)) %>%
  ungroup() %>%
  mutate(term = reorder_within(term, abs(value), component)) %>%
  dplyr::mutate(component = factor(paste0("PC",component))) %>%
  ggplot(aes(x=abs(value), y=term, fill = value > 0)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~component, scales = "free") +
  scale_y_reordered() +
    labs(
    x = "Absolute value of contribution",
    y = NULL, 
    fill = "Positive?"
  ) +
  theme_classic() 

# Scree plot
sdev <- pca$sdev
percent_variation <- sdev^2 / sum(sdev^2)

tibble(
  component = unique(tidied_pca$component),
  percent_var = percent_variation ## use cumsum() to find cumulative, if you prefer
) %>%
  dplyr::filter(component < 11) %>%
  mutate(component = factor(component)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(component, percent_var)) +
  geom_col() +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = NULL, y = "Percent variance explained by each PCA component") +
  theme_classic()
```

# Fit GLMnet

from philr tutorial https://bioconductor.org/packages/devel/bioc/vignettes/philr/inst/doc/philr-intro.html
```{r glmnet}
library(glmnet)

# Predict mock vs real
sample_data(ps2)$mock <- factor(get_variable(ps2, "type") %in% c("Mock", "POS"))

glmmod <- glmnet(ps2.philr, sample_data(ps2)$type, alpha=1, family="multinomial")

# Get coords usign tidy insteaed
tidied <- tidy(glmmod) %>% 
  filter(!term == "(Intercept)",
         !term == ""
         )%>%
  mutate(node = name.to.nn(phy_tree(ps2), term))

ggplot(tidied, aes(step, estimate, group = term)) +
  geom_line()

#tc.colors <- c('#a6cee3', '#1f78b4')
p <- ggtree(phy_tree(ps2), layout='fan') +
  geom_balance(node=2843, alpha=0.6) # get node number from the tidied dev.node
p <- annotate_balance(phy_tree(ps2), 'n16', p=p, labels = c('n16+', 'n16-'),
                 offset.text=0.15, bar=FALSE)
annotate_balance(tree, 'n730', p=p, labels = c('n730+', 'n730-'),
                 offset.text=0.15, bar=FALSE)
```


## Occupancy modelling

### eDNAoccupancy
```{r edna occupancy}

library(eDNAoccupancy)
data(fungusDetectionData)
data(fungusSurveyData)

# Make detection table
ps_qual <- ps %>%
  speedyseq::tax_glom(taxrank="Species") %>%
  transform_sample_counts(function (x) (x > 0) * 1) %>%
  #merge_samples(group = "ExtractID") %>%
  speedyseq::psmelt() %>%
  select(Sample, Abundance, Species) %>%
  separate(Sample, into=c("site", "rep"), sep="-rep") %>%
  mutate(rep=paste0("pcr",rep)) %>%
  separate(site, into=c("site", "sample"), sep="-ex") %>%
  pivot_wider(names_from=rep, values_from = Abundance, values_fill=list(Abundance = 0)) 

det_suzukii <- ps_qual %>%
  mutate(site = str_replace(site, "DM", "D100M")) %>%
  filter(Species=="Drosophila_suzukii") %>%
  filter(str_detect(site,"D100M|D250M|D500M|D1000M")) %>%
  select(site, sample, pcr1, pcr2, pcr3) %>%
  mutate(sample = as.integer(sample)) %>%
  arrange(sample) %>%
  as.data.frame()

suzukii_detections = occData(det_suzukii, siteColName = 'site',
                            sampleColName = 'sample')

#Make covariate tables

# Read in expected table
exp <- read_csv("sample_data/expected_quant.csv") %>%
  gather(Species, Actual, -X1) %>%
  mutate(Species = str_replace(Species, pattern=" ",replacement="_")) %>%
  filter(str_detect(X1,"D100M|D250M|D500M|D1000M|DLarv")) %>%
  drop_na() %>%
  set_colnames(c("Sample","Species","Actual"))
# Add true presence

#Add community size covariate

commsize <- exp %>%
  group_by(Sample) %>%
  summarise(commsize = sum(Actual)) %>%
  mutate(Sample = str_replace_all(Sample, pattern="(-)(.*?)(?=$)", replacement=""))

survey_data <- samdf %>%
  remove_rownames() %>%
  mutate(Sample = str_replace_all(ExtractID, pattern="(-)(.*?)(?=$)", replacement="")) %>%
  select(Sample, geo_loc_name, material) %>%
  left_join(commsize, by="Sample") %>%
  rename(site = Sample) %>%
  filter(str_detect(site,"D100M|D250M|D500M|D1000M")) %>%
  unique()

# Add alpha diversity covariates

# Try using hill numbers for these https://github.com/anttonalberdi/hilldiv

#estimate richness
alpha_table <- phyloseq::estimate_richness(ps2)

# Calculate Faith's PD-index
pdtable <- picante::pd(as(phyloseq::otu_table(ps2), "matrix"), phyloseq::phy_tree(ps2), include.root = F)




 ## number of detections per sample
 head(suzukii_detections$y)
 ## number of PCR replicates per sample
 head(suzukii_detections$K)

#We fit a multi-scale occupancy model without covariates and print a summary of the parameter estimates using the following code.

 set.seed(69)
 fit = occModel(detectionMats=suzukii_detections, niter=11000,
                niterInterval=5000)
 posteriorSummary(fit, burnin=1000, mcError=TRUE)


## Center and scale numeric-valued covariate measurements
survey_data.sc = scaleData(survey_data)

set.seed(0157)
fit = occModel(formulaSite          = ~ 1,
               formulaSiteAndSample = ~ commsize,
               formulaReplicate     = ~ commsize,
               detectionMats        = suzukii_detections,
               siteData             = survey_data.sc,
               niter                = 6000,
               niterInterval        = 2000,
               siteColName = 'site'
               )
posteriorSummary(fit, burnin=1000, mcError=TRUE)


#If we want to assess whether the Markov chain used to compute these estimates appears to have converged, trace plots of the parameters may be created as follows (Fig.~\ref{fig:TracePlotFungusAnalysis}).
plotTrace(fit, c('beta.(Intercept)', 'alpha.(Intercept)', 'alpha.frogs',
            'delta.(Intercept)'),  burnin=1000)

#Autocorrelation plots of the parameters are created similarly
 plotACF(fit, c('beta.(Intercept)', 'alpha.(Intercept)', 'alpha.frogs',
             'delta.(Intercept)'),  burnin=1000)

#After inspection of these plots, suppose we decide that the MCMC algorithm needs to be run longer, either to eliminate the transient portion of the Markov chain or to reduce Monte Carlo errors in the parameter estimates.  We can resume the MCMC algorithm for the currently fitted model as follows.
 fit = updateOccModel(fit, niter=5000, niterInterval=2000)
 posteriorSummary(fit, burnin=1000,  mcError=TRUE)

 #These estimates of the parameters are computed using the updated Markov chain containing \rinline{fit$niterations} iterations.  The Monte Carlo errors in these parameter estimates are slightly lower, but the estimates are otherwise similar to those computed with only \rinline{fit$niterations-5000} iterations.

#In addition to estimating posterior summaries of the model's formal parameters, we also may be interested in estimating posterior summaries of derived parameters.  For example, in the second model fitted to the \emph{Bd} data, the probability of eDNA occurrence in ponds was assumed to be constant ($\psi$), the conditional probability of eDNA occurrence in samples was assumed to be a function of the frog density index \code{frogs}, and the conditional probability of eDNA detection was assumed to be constant ($p$).  The posterior medians of these derived parameters are estimated as follows.

psi = posteriorSummaryOfSiteOccupancy(fit, burnin=1000)
theta = posteriorSummaryOfSampleOccupancy(fit, burnin=1000)
p = posteriorSummaryOfDetection(fit, burnin=1000)

 ## output estimates of posterior medians
 cbind(psi=psi$median, theta=theta$median[,1], p=p$median[,1])

 frogs = fungusSurveyData[, 'frogs']
 plot(frogs, theta$median[,1], ylim=c(0,1), xlim=c(0,0.8), cex=2)
 segments(frogs, theta$lower[,1], frogs, theta$upper[,1], lwd=2)
 
#One way to assess the relative importance of such estimated relationships is to compare competing models using model-selection criteria.  For example, we compute the PPLC and WAIC criteria for the previously fitted model as follows.
 posteriorPredictiveLoss(fit, burnin=1000)
 WAIC(fit, burnin=1000)

```

###Seak occupancy

Seak occupancy modelling - The model is fitted within a Bayesian framework and any of the model parameters can be functions of covariates. The implemented algorithm performs Bayesian variable selection and the output includes posterior summaries of all parameters as well as posterior probabilities of inclusion (see examples for a more detailed description of how to interpret the output).

The model has been developed for single species qPCR data. The data are the number of positive qPCRs (eDNA score) for each water sample collected at surveyed sites. The model allows us to estimate the probability of species presence at each survey site, while accounting for the probabilities of a false positive and false negative error at stage 1 (field) and stage 2 (lab).



Occupancy modelling calculates the probability of detection from a number of replicates. ie - 6 replicates positive = 100% probaiblity , 5/6 = 85% probability

Nested levels = Replicated extractions, replicated PCRs .

Could fit a single specied


For model taking into accoutn false poositives and negatives: https://seak.shinyapps.io/eDNA/

This requires format

Columns = Sample (extraciton replicate ) so 2 columns
Rows = site (trap)
cell value = number of positive PCR replicates (out of 3)
Column 3 = True presence or absense 1 or 0
column 4,5,6 etc other covariates. Sequencing depth, community size, species richness,trap type, phylogenetic richness... etc



```{r occupancy}
#convert to presence/absense
ps_qual <- ps %>%
  speedyseq::tax_glom(taxrank="Species") %>%
  transform_sample_counts(function (x) (x > 0) * 1) %>%
  merge_samples(group = "Sample_Name") %>%
  speedyseq::psmelt() %>%
  dplyr::select(Sample, Abundance, Species) %>%
  mutate(Sample = str_remove(Sample, "^.*_")) %>%
  separate(Sample, into=c("Sample", "exrep"), sep="-ex") %>%
  pivot_wider(names_from=exrep, values_from = Abundance, values_fill=list(Abundance = 0)) %>%
  dplyr::select(Sample, Species, `1`, `2`,)

# Read in expected table
exp <- read_csv("sample_data/expected_quant.csv") %>%
  gather(Species, Actual, -X1) %>%
  mutate(Species = str_replace(Species, pattern=" ",replacement="_")) %>%
  #filter(str_detect(X1,"D100M|D250M|D500M|D1000M|DLarv")) %>%
  drop_na() %>%
  set_colnames(c("Sample","Species","Actual"))
# Add true presence

true_pres <- exp %>%
  mutate(Sample = str_replace_all(Sample, pattern="(-)(.*?)(?=$)", replacement="")) %>%
  mutate(Actual = case_when(
    Actual > 0 ~ 1,
    Actual == 0 ~ 0
  )) %>%
  unique()
  
#Add community size covariate - need to estimate for others

commsize <- exp %>%
  group_by(Sample) %>%
  summarise(commsize = sum(Actual)) %>%
  mutate(Sample = str_replace_all(Sample, pattern="(-)(.*?)(?=$)", replacement=""))

# add seqdepth covariate

#filterdepth

#richness
richness <- ps_qual %>%
  mutate(Sample = str_replace(Sample, "DM", "D100M")) %>%
  ungroup() %>%
  mutate(total = `1`+`2`) %>%
  filter(total > 0) %>%
  group_by(Sample) %>%
  summarise(richness= n())  

# Species evenness

# Phylogenetic diversity


#trap_type
comm_type <- exp %>%
  mutate(Sample = str_replace_all(Sample, pattern="(-)(.*?)(?=$)", replacement="")) %>%
  mutate(comm_type = case_when(
    str_detect(Sample, "D100M|D250M|D500M|D1000M") ~ "Mock",
    str_detect(Sample, "DLarv") ~ "Larvae",
    str_detect(Sample, "ACV") ~ "ACV",
    str_detect(Sample, "FF") ~ "FF",
    str_detect(Sample, "SPD") ~ "SPD",
    str_detect(Sample, "DC") ~ "DC",
  )) %>%
  dplyr::select(Sample, comm_type) %>%
  unique()
  

# Get suzukii only
det_suzukii <- ps_qual %>%
  mutate(Sample = str_replace(Sample, "DM", "D100M")) %>%
  left_join(true_pres, by=c("Sample", "Species"))%>%
  left_join(commsize, by="Sample") %>%
  left_join(richness, by="Sample") %>%
  left_join(comm_type, by="Sample") %>%
  filter(Species == "Drosophila_suzukii") %>%
  dplyr::select(-Species) %>%
  unique() %>%
  mutate(Actual = replace_na(Actual, 0))  %>%
  filter(!is.na(commsize)) %>%
  mutate(commsize = scale(commsize, center = TRUE, scale = TRUE))  %>%
  #mutate(random = scale(rbinom(nrow(.), 100, 0.7), center = TRUE, scale=TRUE)) %>%
  #mutate(random2 = scale(rbinom(nrow(.), 100, 0.4), center = TRUE, scale=TRUE)) %>%
  mutate(richness = scale(richness, center = TRUE, scale = TRUE))  %>%
  filter(!str_detect(Sample, "DLarv"))# %>%
  #set_rownames(.$Sample) #%>%
  dplyr::select(-Sample)
  
write.csv(det_suzukii, "test_occupancy_suzukii.csv", row.names=FALSE)

```

For sequencing depth covariate could you just rarefy to certain depth, recalculate detection, then rbind a longer table together in a loop
Same with filtering threshold



these could be fit seperately for our 3 target species

Then we can look at how the detection probability changes across different filtering thresholds used to remove index switching?


To test if probability of detection differs as a function of sample water volume, we used the eDNAoccupancy R package (version 0.2.4; Dorazio & Erickson, 2017) to model probabilities of eDNA detection. This package fits Bayesian, multi‐scale occupancy models to our data, which included three, nested levels of sampling: stream location, replicated water samples collected from each stream, and subsamples (i.e., PCR technical replicates) of each water sample. 



https://onlinelibrary.wiley.com/doi/full/10.1002/edn3.23

https://besjournals.onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2011.00156.x

https://www.pnas.org/content/pnas/116/18/8931.full.pdf

Based on the overall model, a total of seven water samples was
required to achieve >95% detection probabilities of S. mansoni
eDNA at water sample level (θ = 0.35) [as calculated by using
the equation P = 1 − (1 − θ)
n (27)]. By using the same approach,
the model-based estimated number of qPCR replicates required
to achieve detection probabilities >95% ranged from three to
nine replicates between sites


## Check for concordance between mock and real


```{r PCA}
# Read in expected table
exp <- read_csv("sample_data/expected_quant.csv") %>%
  gather(Species, Abundance, -X1) %>%
  mutate(Species = str_replace(Species, pattern=" ",replacement="_")) %>%
  filter(str_detect(X1,"D100M|D250M|D500M|D1000M|DLarv")) %>%
  drop_na() %>%
  set_colnames(c("Sample","Species","Actual"))

# Prepare observed table
sam <- ps.merged %>%
  speedyseq::tax_glom("Species") %>%
  transform_sample_counts(function (x) x/sum(x)) %>%
  speedyseq::psmelt() %>%
  mutate(Species = str_replace(Species, pattern="Drosophila_mauritiana/simulans", replacement= "Drosophila_simulans")) %>%
  mutate(Species = str_replace(Species, pattern="Drosophila_albomicans", replacement= "Drosophila_immigrans")) %>%
  filter(Sample %in% exp$Sample) %>%
  arrange(Abundance) %>%
  distinct() %>%
  select(Sample, Species, Abundance)

# Join tables
joint <- sam %>%
  filter(Species %in% exp$Species) %>%
  group_by(Species, Sample) %>% 
  summarise(Abundance = sum(Abundance)) %>%
  ungroup() %>%
  #mutate(Type = ifelse(Sample %in% controls, "Est", "Eval")) %>%
  bind_rows(exp %>%
              mutate(Actual = replace_na(Actual, 0)) %>%
              rename(Abundance = Actual) %>%
              filter(str_detect(Sample, pattern="-ex1"))  %>%
              mutate(Sample = str_replace_all(Sample, pattern="-ex1", replacement="-A")
            
            )) %>%
  group_by(Sample) %>%  
  mutate_at(vars(Abundance), ~ . / sum(.)) %>% # Convert to proportions
  #mutate(Abundance = Abundance + 0.0001) %>% # Add pseudocount
  #mutate(Abundance = clr(Abundance)) %>%
  ungroup()

# PCA
joint_pca <- joint %>%
  pivot_wider(
    names_from = Species, #  Switch this to transpose
    values_from = Abundance,
    values_fill = list(Abundance=0),
  ) %>%
  mutate(Extract = Sample %>% str_replace_all(pattern="(-)(.*?)(?=$)", replacement="")) %>%
  mutate(Mock = Sample %>% 
           str_replace_all(pattern="(-)(.*?)(?=$)", replacement="") %>%
           str_replace_all(pattern="(^)(.*?)(?<=M)", replacement="")) %>%
  nest(data = everything()) %>%
  mutate(pca = map(data, ~ prcomp(.x %>% select(-Sample, -Extract, -Mock), 
                                  center = TRUE, scale = TRUE)),
         pca_aug = map2(pca, data, ~augment(.x, data = .y))) 

joint_pca$pca %>%
  map(~tidy(.x, data = .y, "pcs")) %>%
  as.data.frame() %>%
  ggplot(aes(x = PC, y=percent)) +
  geom_bar(stat="identity") + labs(x="PC",y="Variance Explained")


library(RColorBrewer)
col <- colorRampPalette(brewer.pal(11, "Spectral"))(25)

joint_pca %>%
  mutate(
    pca_graph = map2(
      .x = pca,
      .y = data,
      ~ autoplot(.x, loadings = TRUE, loadings.label = TRUE,
                 loadings.label.repel = FALSE,
                 data = .y, label = TRUE,
                 label.label = "Sample",
                 label.repel = TRUE, 
                 colour='Extract') +
       #theme_bw() +
        labs(x = "Principal Component 1",
             y = "Principal Component 2",
             title = "First two principal components of PCA for expected and observed") +
        coord_fixed()#+
       # scale_colour_manual(values=col)
    )
  ) %>%
  pull(pca_graph)


## Heirarchial clustering


# Output drosophila summary
ps.merged %>% 
  subset_taxa(Family=="Drosophilidae") %>%
  microbiome::transform("compositional") %>%
  summarise_taxa("Species", "sample_id") %>%
  filter(!str_detect(sample_id, "NTC")) %>%
  #filter(str_detect(Species, "Drosophila|Scaptodrosophila")) %>%
  spread(key="sample_id", value="totalRA") %>%
  write.csv(file = "output/csv/unfiltered/drosophila_spp_sum.csv")

```

# Detection of targets

# Primer comparison

## Comparison between primers for detection

Doesnt seem to be any scaptodrosophila? need to do exact matching

```{r}
#For run 1
#rm_samples <- c("Undetermined")
#ps1 <- subset_samples(ps, sample_names(ps) !=rm_samples) # Drop Undetermined reads
#ps1 <- prune_samples(sample_sums(ps1)>=20, ps1) # Drop empty samples
#ps2 <- tax_glom(ps1,taxrank="Species") # Change to ps.merged for later runs

#Agglomerate to species
ps2 <- speedyseq::tax_glom(ps.merged,taxrank="Species") # Change to ps.merged for later runs

#For run2 
rm_samples <- c("fwhF2-fwhR2n-CM4","fwhF2-HexCOIR4-CM4")
ps2 <- subset_samples(ps2, !sample_names(ps2) %in% rm_samples) # Drop Undetermined reads

ps2 <- filter_taxa(ps2, function(x) mean(x) > 0, TRUE) #Drop missing taxa from table
ps2 <- prune_samples(sample_sums(ps2)>=20, ps2) # Drop empty samples


#Rough barplot
col2 <- colorRampPalette(brewer.pal(11, "Spectral"))(71)

rm_samples <- sample_names(ps2)[which(str_detect(sample_names(ps2),"blank"))]
psbar <- subset_samples(ps2, !sample_names(ps2) %in% rm_samples) # Drop Undetermined reads

Fig1 <- plot_bar(psbar,fill="Species") +
  theme_bw() +
    #scale_fill_manual(values=col2) + 
  theme(legend.position="none",
        axis.text.x = element_text(angle=90))
#Change sample names for plotting
#
#sample_names(ps2) <- sample_names(ps2) %>%
##  str_split_fixed("-",n=3) %>%
#  as_tibble() %>%
#  pull(V3)

gg.hmap <- plot_heatmap(ps2, "jaccard", "jsd", taxa.label="Species", na.value=NA, taxa.order="Family")   +
  theme_bw() +
  theme(axis.text.x = element_text(angle=60, hjust=1),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        panel.spacing =unit(0.2, "lines"),
        legend.position = "bottom",
        legend.direction = "horizontal") +
  facet_grid(~target_subfragment,scales="free",space="free", drop=TRUE) +
    scale_fill_distiller(palette="Reds", direction= 1, trans = 'log10',  na.value = NA)


#Summarise this also with a jaccard distance comparison!
library(RColorBrewer)
col <- colorRampPalette(brewer.pal(11, "Spectral"))(20)

ps.ord <- subset_taxa(ps2, !Species %in% Syn_taxa)
ps.ord <- filter_taxa(ps.ord, function(x) mean(x) > 0, TRUE) #Drop missing taxa from table
ps.ord <- prune_samples(sample_sums(ps.ord)>=20, ps2) # Drop empty samples
GP.ord <- ordinate(ps.ord, "NMDS", "jaccard")
p1 = plot_ordination(ps.ord, GP.ord, type="samples", color="ExtractID", title="Comparison of 2 primer sets") + 
  theme_bw() +  
  theme(legend.position = "none") +
  #scale_color_manual(values=col)+ 
  geom_point(size=3) 

#,guide=FALSE
```

## Comparison between primers for bias

- Metacal center function
- lm 
- lm with CLR in advance?
- glmnet: multinomial regression with regularization (ie Lasso model)
- nnet::multinomial neural network regression
- multinomial regression with random effects
- Poisson regression with random effects
- Bayesian multinomial logistic normal models
  - Stan
  - Pibble from stray package

Pick the model that reduces the residual mean standard error (RMSE) the most

Should be able to do this within a tidymodels framework with bootsrapping

```{r Drosophila bias}
#devtools::install_github("mikemc/metacal")
library(metacal)
library(tidyverse)

ps_bias <- subset_samples(ps2, type %in% c("Mock"))
tax_table(ps_bias)[,7][which(tax_table(ps_bias)[,7]=="Carpophilus_dimidiatus/nr.dimidiatus")] <- "Carpophilus_nr.dimidiatus"
tax_table(ps_bias)[,7][which(tax_table(ps_bias)[,7]=="Brachypeplus_Sp1")] <- "Brachypeplus_Sp"
tax_table(ps_bias)[,7][which(tax_table(ps_bias)[,7]=="Brachypeplus_Sp2")] <- "Brachypeplus_Sp"
ps_bias <- tax_glom(ps_bias, taxrank="Species")

sample_data(ps_bias)$target_subfragment <- paste0(sample_data(ps_bias)$Fprimer, "_", sample_data(ps_bias)$Rprimer)

sam <- speedyseq::psmelt(ps_bias) %>%
  arrange(Abundance) %>%
  mutate(Taxon = Species) %>%
  dplyr::select(OTU,Sample, Taxon, Abundance) %>%
  mutate(Sample = str_remove(Sample, "HLVKYDMXX_"))

exp <- read_csv("sample_data/expected_quant.csv") %>%
  pivot_longer(-X1,
               names_to= "Species",
               values_to= "Abundance") %>%
  mutate(Species = str_replace(Species, pattern=" ",replacement="_")) %>%
  mutate(X1 = str_split_fixed(X1,"-rep",n=2) %>%
           as_tibble()%>% 
           pull(V1)) %>%
  drop_na() %>%
  magrittr::set_colnames(c("Sample","Taxon","Actual"))

#Join tables 
joint <- sam %>%
  filter(Taxon %in% exp$Taxon) %>%
  left_join(exp, by = c("Sample","Taxon")) %>%
  mutate(Actual = replace_na(Actual, 0)) %>%
  mutate(Observed0 = (Abundance + 0.5) * (Actual > 0)) %>%
  mutate(Error = Observed0 / Actual) %>%
  distinct()

#Note - instead could read in the expected matrix, format to the same as the OTU matrix, then divide them both
# This would allow using bayesian zero replacement

#Build error matrix
error_mat <- build_matrix(joint, Sample, Taxon, Error) 
rows_to_keep <- rowSums(error_mat, na.rm=TRUE) > 0
cols_to_keep <- colSums(error_mat, na.rm=TRUE) > 0
error_mat <- error_mat[rows_to_keep,cols_to_keep]

#Estimate bias using metacal
bias <- center(error_mat, enframe = TRUE) %>%
    dplyr::rename(Bhat = Center)

#Estimate uncertainty in bias estimate using bootstrapping
bootreps <- bootrep_center(error_mat) %>%
    dplyr::rename(Bhat = Center)
bootreps.summary <- bootreps %>%
    group_by(Taxon) %>%
    summarize(Gm_mean = gm_mean(Bhat), Gm_se = gm_sd(Bhat))
bias0 <- left_join(bias, bootreps.summary, by = "Taxon")

# Estiamte using lm instread
bias.lm <- joint %>%
  group_by(Sample) %>%
  mutate_at(vars(Abundance, Actual), ~ . / sum(.) )%>% #Convert to proportions
  dplyr::select(Sample, Taxon, Abundance, Actual) %>% 
  ungroup() %>%
  filter(Actual > 0) %>%
   #group_by(Taxon) %>%
    nest() %>%
    mutate(fit = map(data, ~lm(Abundance ~ 0 + Actual + Taxon, data = .)),
           tidied = map(fit, broom::tidy)) %>%
  unnest(tidied) #%>%
  dplyr::select(Taxon, estimate, std.error)

bias.lm

# Try with tidymodels

# First plot actual vs obsered to see if there is a linear relationship

# Test make bootstraps
data <- joint %>%
  group_by(Sample) %>%
  mutate_at(vars(Abundance, Actual), ~ . / sum(.) )%>% #Convert to proportions - Could i just do a CLR here?
  dplyr::select(Sample, Taxon, Abundance, Actual) %>%
  ungroup() %>%
  filter(Actual > 0) %>%
  group_by(Taxon)

boots <- bootstraps(data, times = 1000, apparent = TRUE)

boot_models <-  boots %>%
      mutate(model = map(splits, ~  lm(Abundance ~ 0 + Actual + Taxon, data = analysis(.))), 
        # Fore intercept to be 0
        coef_info = map(model, tidy))


boot_coefs <- boot_models %>% 
  unnest(coef_info)

percentile_intervals <- int_pctl(boot_models, coef_info)
percentile_intervals

ggplot(boot_coefs, aes(estimate)) +
  geom_histogram(bins = 30) +
  facet_wrap( ~ term, scales = "free") +
  geom_vline(aes(xintercept = .estimate), data = percentile_intervals, col = "red") +
  geom_vline(aes(xintercept = .lower), data = percentile_intervals, col = "blue") +
  geom_vline(aes(xintercept = .upper), data = percentile_intervals, col = "blue")

# HOw to compare these models? - See mikemc paper
boot_aug <- 
  boot_models %>% 
  #sample_n(200) %>% 
  mutate(augmented = map(model, augment)) %>% 
  unnest(augmented)

ggplot(boot_aug, aes(.fitted, Abundance, color = Taxon)) +
    geom_jitter()


## Group split version

group_name <- group_keys(data) %>%
  pull(Taxon)
data <- data %>%
  group_split() %>%
  set_names(group_name)

set.seed(606)
boots <- purrr::map(data, bootstraps, times=100, apparant=TRUE)

# Fit model to bootstraps
boot_models <- boots %>% 
  purrr::map(function(x){ 
    x <- x %>%
      mutate(model = map(splits, ~  lm(Abundance ~ 0 + Actual, data = .)), # Set slope to 0 to jus estimate intercept
         coef_info = map(model, tidy))
    }) 


# Get coefficients
boot_coefs <- boot_models %>% 
      unnest(coef_info)

# Calculate CIs using percentile method
percentile_intervals <- boot_models %>%
  purrr::map(function(x){int_pctl(x, coef_info)}) %>%
  bind_rows(.id="Taxon")

percentile_intervals


## Mclarens  naive approach
otutab <- otu_table(ps_bias)

#Impute zeroes for compositional distances
otutab_n0 <- otu_table(zCompositions::cmultRepl(otutab, method="CZM", output="p-counts"), taxa_are_rows = FALSE)

sam <- sample_data(ps_bias) %>% as("data.frame") %>% as_tibble(rownames = "Sample")

otu.clr <- otutab_n0 %>% transform_sample_counts(clr)
fit.clr <- lm(otu.clr ~ 0 + Sample_Name, sam) #Sample_Name*target_subfragment - should be able to account for all priemrs if we add this to the model
tb.clr <- tidy(fit.clr, conf.int = TRUE) %>%
    dplyr::rename(OTU = response)

library(ggstance)
tb.clr %>%
    ggplot(aes(x = estimate, y = OTU)) +
    geom_vline(xintercept = 0) +
  geom_point() +
    #geom_pointrangeh(aes(xmin = conf.low, xmax = conf.high)) +
    scale_color_brewer(type = "qual", palette = 6) +
    labs(title = "LFC in differential efficiency")

#Test plot bias

p <- ggplot(bias0, aes(Taxon, y=Gm_mean-1,fill=Taxon)) +
    geom_bar(stat="identity")+
    geom_errorbar(aes(ymin = (Gm_mean-1) - (Gm_se-1), ymax = (Gm_mean-1) + (Gm_se-1), width=0.2)) +
    geom_point(aes(y=Gm_mean-1)) +
    scale_fill_brewer(palette="Spectral")+
    scale_colour_brewer(palette="Spectral") + 
  theme_bw() +
  theme(axis.text.x = element_text(angle=90,hjust=1,vjust=0)) + 
  ylab("Bias") +
  ggtitle(primers[i]) +
  expand_limits(y = c(-2, 4)) +
  theme(legend.position = "none")
 
plist[[i]] = p
 
#Get pairwise bias
bias.pw <- bias %>%
    compute_ratios(group_vars = c()) %>%
    mutate(Pair = paste(Taxon.x, Taxon.y, sep = ":"))

#Get pairwise boostrap estimates
bootreps.pw <- bootreps %>%
    compute_ratios(group_vars = ".id")
summary.pw <- bootreps.pw %>%
    group_by(Taxon.x, Taxon.y) %>%
    summarize(Gm_mean = gm_mean(Bhat), Gm_se = gm_sd(Bhat))
bias.pw0 <- left_join(bias.pw, summary.pw, by = c("Taxon.x", "Taxon.y"))

#Plot bias estimates
ratios <- joint %>%
    compute_ratios %>%
    mutate(Pair = paste(Taxon.x, Taxon.y, sep = ":")) %>%
    filter(!is.nan(Error), Taxon.x < Taxon.y)
ratios.pred <- bias.pw0 %>%
    mutate(Pair = paste(Taxon.x, Taxon.y, sep = ":")) %>%
    filter(Taxon.x < Taxon.y)

gg.bias <- ggplot(ratios, aes(Pair, Error, color = Sample)) +
    geom_hline(yintercept = 1, color = "grey") +
    geom_pointrange(data = ratios.pred, aes(y = Bhat, 
            ymin = Bhat / Gm_se^2, ymax = Bhat * Gm_se^2), 
        color = "black") +
    geom_jitter(width = 0.2) +
    scale_y_log10() +
    coord_flip()

```
