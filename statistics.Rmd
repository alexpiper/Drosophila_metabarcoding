---
title: "Drosophila Metabarcoding"
title: "Statistical analysis"
author: "Alexander Piper"
date: "`r Sys.Date()`"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

# Introduction

## Analysis structure

Part 1 - Cleanup & Filtering of index switching

Part 1 - Comparison of 4 primers for bias and detection efficiency (figure 1)

Part 2 - Comparison of bias between 3 tagged primers

Part 3 - Comparison

## Load packages

```{r setup}
#Set required packages
.cran_packages <- c("tidyverse",
                    "tidymodels",
                    "patchwork", 
                    "vegan", 
                    "seqinr",
                    "ape", 
                    "RColorBrewer",
                    "castor", 
                    "picante",
                    "phytools",
                    "ggrepel",
                    "devtools")
.bioc_packages <- c("dada2",
                    "phyloseq", 
                    "ggtree",
                    "DECIPHER",
                    "Biostrings",
                    "ShortRead", 
                    "philr",
                    "ALDEx2")

.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install(.bioc_packages[!.inst], ask = F)
}

sapply(c(.cran_packages,.bioc_packages), require, character.only = TRUE)

# Github packages
devtools::install_github("alexpiper/taxreturn")
devtools::install_github("alexpiper/seqateurs")
devtools::install_github("mikemc/speedyseq")
devtools::install_github('ggloor/CoDaSeq/CoDaSeq')
devtools::install_github("mikemc/metacal")

library(speedyseq)
library(taxreturn)
library(seqateurs)
library(CoDaSeq)
library(metacal)

#Source internal functions
source('R/helper_functions.R')

#Source themes
source('R/themes.R')
```

## Read in phyloseq object

```{r phyloseq}
ps2 <- readRDS("output/rds/ps_filtered.rds")
```

# Run 1 - primer comparison

## Overview of run 1

```{r run 1 overview}
ps_run1 <- ps2 %>%
  subset_samples(fcid %in% c("CB3DR")) 
ps_run1 <- ps_run1 %>%
  subset_samples(!str_detect(sample_names(ps_run1),"blank")) %>%
  filter_taxa( function(x) mean(x) > 0, TRUE) 

ps_run1 %>% 
  speedyseq::psmelt() %>%
  group_by(sample_id) %>%
  mutate_at(vars(Abundance), ~ . / sum(.) ) %>% #Convert to proportions
  mutate(plotlabel = case_when(
    Abundance >= 0.01  ~ Species, # Change this to whatever taxrank we want
    Abundance < 0.01 ~ as.character(NA)
    )) %>%
  ggplot(aes(x=sample_name, y=Abundance, fill=plotlabel)) +
  geom_col(position="stack") + 
  facet_grid(pcr_primers~type, scales="free") +
  scale_y_continuous(labels = scales::percent) +
  coord_flip()+
  base_theme+
  theme(legend.position = "bottom") +
  labs(x = "Sample Name",
       y= "Relative abundance",
       fill="Species",
       title = "Run 1 - Primer testing")

# Reads per sample
ps_run1 %>% 
  speedyseq::psmelt() %>%
  group_by(sample_id, sample_name, pcr_primers) %>%
  summarise(Abundance = sum(Abundance)) %>%
  ggplot(aes(x = sample_name, y = Abundance))+
  geom_col() +
  geom_text(aes(label=Abundance),angle=90,hjust=1,vjust=0.5, colour="white")+
  facet_grid(~pcr_primers,scales="free_x", drop=TRUE) + 
  base_theme

ps_run1 %>% 
  speedyseq::psmelt() %>%
  group_by(sample_id, sample_name, pcr_primers) %>%
  summarise(Abundance = sum(Abundance)) %>%
  ungroup() %>%
  summarise(total = sum(Abundance), mean=mean(Abundance), sd = sd(Abundance), upper = range(Abundance)[2], lower=range(Abundance)[1])

# Taxa per primer
ps_run1 %>% 
  speedyseq::psmelt() %>%
  filter(Abundance > 0, !is.na(Abundance)) %>%
  mutate(type = case_when(
    str_detect(sample_name,"D100M") ~ "MOCK",
    TRUE ~ "TRAP"
  ))%>%
  group_by(type, pcr_primers) %>%
  summarise(unique = n_distinct(Species)) 

# Heatmap separate for primers

# Plot phylogeny
exp <- read_csv("sample_data/expected_quant_merged.csv") %>%
  dplyr::rename(sample_name = Sample) %>%
  pivot_longer(-sample_name,
               names_to= "Species",
               values_to= "expected") %>%
  mutate(taxon = str_replace(taxon, pattern=" ",replacement="_"),
         sample_name = str_remove(sample_name, "-exp*.$")) %>%
  dplyr::filter(!is.na(sample_name),
  !str_detect(sample_name, "CM[0-9]|CT[0-9]|CML[0-9]|Syn"),
  expected > 0) %>%
  distinct()

heatmap_dat <-  ps_run1 %>%
  speedyseq::psmelt() %>%
  dplyr::select(sample_id, OTU, sample_name, Abundance, pcr_primers, Species, type) %>%
  filter(!str_detect(Species, "__")) %>%
  mutate(sample_name = sample_name %>% str_remove("CB3DR_"),
         Species = str_replace(Species, "_", " "),
         type = case_when(
           str_detect(sample_name, "D100") ~ "Mock",
           TRUE ~ "Trap"
         )) %>%
  group_by(sample_id) %>%
  mutate_at(vars(Abundance), ~ . / sum(.) ) %>%
  ungroup() %>%  
  mutate(Abundance = na_if(Abundance, 0))  %>%
  left_join(read_csv("sample_data/expected_quant_merged.csv") %>%
  dplyr::rename(sample_name = Sample) %>%
  pivot_longer(-sample_name,
               names_to= "Species",
               values_to= "expected") %>%
    mutate(Species = Species %>% str_replace("_", " ")), by = c("sample_name","Species")) %>%
  mutate(expected = na_if(expected, 0))  %>%
  mutate(outcome = case_when(
    type == "Mock" & Abundance > 0 & is.na(expected) ~ "FP",
    type == "Mock" & Abundance > 0 & !is.na(expected) ~ "TP",
    type == "Mock" & is.na(Abundance) & expected > 0 ~ "FN"
  )) 

# Plot tree
keeptips <- heatmap_dat %>% 
  filter(Abundance > 0) %>%
  dplyr::select(OTU, Species) %>%
  distinct()

tree <- phy_tree(ps_run1)
tree <- drop.tip(tree, tree$tip.label[!tree$tip.label %in% keeptips$OTU])

tree$tip.label <- tree$tip.label %>%
  tibble::enframe(name=NULL, value="OTU") %>%
  left_join(keeptips) %>%
  pull(Species)

mock_tree <- ggtree(tree, ladderize = TRUE)
library(ggnewscale)

gg.run1_heatmap <- heatmap_dat %>%
  left_join(mock_tree$data %>% dplyr::rename(Species = label)) %>%
  mutate(Species = factor(Species)) %>%
    ggplot(aes(x=sample_name, y=fct_reorder(Species, y), fill=Abundance)) +
    geom_tile() +
  scale_fill_viridis_c(labels = scales::percent, na.value = NA, alpha=0.9) +
  new_scale_fill() +
  geom_tile(aes(fill = outcome))+
  scale_fill_manual(values=c("FP" = "#e41a1c", "TP" = NA, "FN"= "grey60")) +
  base_theme+
  theme(legend.position = "right",
        axis.text.y = element_text(face="italic"),
        axis.title.y = element_blank())+
    labs(x="Sample",
         y="Taxon") +
  facet_grid(~pcr_primers,scales="free_x", drop=TRUE)

mock_tree + gg.run1_heatmap + plot_layout(widths = c(1,4))
```

## Bias

```{r Drosophila bias}
ps_bias <- ps_run1

exp <- read_csv("sample_data/expected_quant_merged.csv") %>%
  dplyr::rename(sample_name = Sample) %>%
  pivot_longer(-sample_name,
               names_to= "taxon",
               values_to= "expected") %>%
  mutate(taxon = str_replace(taxon, pattern=" ",replacement="_"),
         sample_name = str_remove(sample_name, "-exp*.$")) %>%
  dplyr::filter(!is.na(sample_name),
  !str_detect(sample_name, "CM[0-9]|CT[0-9]|CML[0-9]|Syn"),
  expected > 0) %>%
  distinct()

#plot expected
exp %>% 
  dplyr::filter(str_detect(sample_name, "^D")) %>%
  group_by(sample_name) %>%
  mutate_at(vars(expected), ~ . / sum(.) ) %>% #Convert to proportions
  ggplot(aes(x=sample_name, y=expected, fill=taxon)) +
  geom_col(position="stack") + 
  scale_fill_brewer(palette="Spectral") +
  scale_y_continuous(labels=scales::percent) +
  base_theme+
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle=45, hjust=1)) +
  labs(x = "Sample Name",
       y= "Relative abundance",
       title="Expected mock communities",
       fill="Species")

#Get observed
sam <- speedyseq::psmelt(ps_bias) %>%
  janitor::clean_names() %>%
  mutate(taxon = species) %>%
  filter(!str_detect(genus, "__")) %>%#Remove unclassified
  dplyr::select(sample_name, taxon, abundance, pcr_primers, fcid, material_type = type) %>%
  mutate(sample_name = sample_name %>%
           str_remove_all("BF1-BR1-|SauronS878-HexCOIR4-|fwhF2-HexCOIR4-|fwhF2-fwhR2n-") %>%
           str_remove("HLVKYDMXX_"),
         sample_id = paste0(fcid, "_", sample_name),
         sample_name = sample_name %>%
           str_remove_all("HLVKYDMXX_|CK3HD_|CB3DR_|CJKFJ_")) 

#Join tables 
joint <- sam %>%
  filter(taxon %in% exp$taxon,
         sample_name %in% exp$sample_name) %>%
  left_join(exp, by = c("sample_name","taxon")) %>%
  dplyr::rename(observed = abundance) %>%
  filter(observed > 0) %>%
  mutate(expected = replace_na(expected, 0),
         observed0 = (observed + 0.5) * (expected > 0),
         error = observed0 / expected) %>%
  distinct() %>%
  group_by(sample_id) %>%
  mutate_at(vars(observed, expected), ~ . / sum(.) ) %>% #Convert to proportions
  group_by(sample_id) %>%
  group_modify(~{
    clr_denom <- .x %>%
      pull(error) %>%
      gm_mean(na.rm = TRUE)
    .x %>%
      mutate(error_clr = log(error / clr_denom))
  })


# Visualise the error in all pairwise ratios
gg.ratio <- joint %>%
  dplyr::filter(expected > 0 ) %>%
  dplyr::mutate(Taxon = taxon %>%
                 str_replace("^.+_", paste0(str_extract(taxon, "."), "_"))) %>%
    compute_ratios(group_vars = c("sample_id", "material_type", "pcr_primers")) %>%
  mutate(Pair = paste(Taxon.x, Taxon.y, sep = ":")) %>% 
  ggplot(aes(Pair, expected, colour=sample_id)) +
  geom_hline(yintercept = 1, alpha=0.8) +
  geom_jitter(alpha=0.7) +
  scale_y_log10() +
  base_theme+
  facet_grid(pcr_primers~.)+
    theme(legend.position = "none",
          axis.text.x = element_text(angle=45, hjust=1))+
  labs(y= "Error in taxon ratios (log10)") 

gg.ratio

# Estimate bias on geometrically centred ratios
bias <- joint %>%
  filter(material_type=="DrosMock") %>%
  filter(expected > 0) %>%
  group_by(pcr_primers, material_type)  %>%
    nest() %>%
    mutate(fit = purrr::map(data, ~lm(error_clr ~ 0 + taxon , data = .)), 
           tidied =  purrr::map(fit, broom::tidy),
           aug =  purrr::map(fit, broom::augment)
    ) %>%
  dplyr::select(-fit) %>%
  unnest(tidied) %>%
  mutate(taxon = str_remove(term, "taxon"),
         estimate = exp(estimate)) %>%
   dplyr::select(pcr_primers, material_type, taxon, estimate)


# Bootstrap estimation
set.seed(606)
boot_models <- joint %>%
  filter(material_type=="DrosMock") %>%
  filter(expected > 0) %>%
  group_by(pcr_primers) %>%
  group_modify(~{
    bootstraps(.x, times=1000, apparant=TRUE)  %>%
    mutate(fit =  purrr::map(splits, ~lm(error_clr ~ 0 + taxon , data = .)), 
           coef =  purrr::map(fit, function(x){
             broom::tidy(x) %>% 
               mutate(estimate = exp(estimate))})) %>%
    int_pctl(coef) 
    }) %>%
  mutate(taxon = str_remove(term, "taxon")) %>%
  dplyr::select(pcr_primers, taxon, lower = .lower, estimate = .estimate, upper = .upper)

# See how well bias esitmate fits data
preds <- joint %>%
  left_join(boot_models) %>%
  dplyr::mutate(predicted = expected * estimate) %>%
  group_by(sample_id) %>%
  mutate_at(vars(predicted), ~ . / sum(., na.rm=TRUE) ) %>%
  filter(expected > 0) %>%
  filter(observed > 0)

# Get RMSE
errors <- preds %>%
  group_by(pcr_primers) %>%
  rmse(truth = observed, estimate = predicted) %>%
  dplyr::select(pcr_primers, rmse = .estimate)

gg.bias_fits <- preds %>%
  mutate(taxon = str_replace(taxon, "_", " ")) %>%
  left_join(errors) %>%
  mutate(rmse = paste0("RMSE = ", round(rmse, 2))) %>%
  ggplot(aes(x=logit(predicted), y=logit(observed), color = taxon))+
  geom_abline(intercept = 0, slope = 1, color = "grey") +
    geom_jitter(width = 0.1, height = 0, alpha=0.7, size=2) +
  geom_text(aes(x=-6, y=-1, label=rmse), check_overlap = TRUE, inherit.aes = FALSE)+
  facet_wrap(~pcr_primers)+
  coord_fixed()+
  scale_color_brewer(palette = "Paired")+
  base_theme +
  theme(
        panel.spacing.x = unit(1, "lines"),
        legend.position = "bottom",
        legend.text = element_text(face = "italic", size=10)
    ) +
   labs(x = "log-odds(Predicted proportion)", 
     y = "log-odds(Observed proportion)",
     colour = "Taxon") 


gg.bias_fits

# Write out bias explained for supplementary 
pdf(file="fig/supplementary/bias_model_fit.pdf", width = 11, height = 8 , paper="a4r")
  plot(gg.bias_fits)
try(dev.off(), silent=TRUE)


# Plot bias estimates
gg.bias <- preds %>%
  ungroup() %>%
  dplyr::select(taxon, estimate, upper, lower, pcr_primers) %>%
  distinct()%>%
  left_join(mock_tree$data %>% dplyr::mutate(taxon = label %>% str_replace(" ", "_"))) %>%
  mutate(taxon = taxon %>% 
           str_replace("^Drosophila_", "D. ")%>%
           str_replace("^Scaptodrosophila_", "Sca. ")) %>%
  mutate(taxon = factor(taxon))%>%
  ggplot(aes(x = fct_reorder(taxon, y), y = estimate, colour = pcr_primers, group = pcr_primers)) +
  geom_hline(yintercept = 1, alpha=0.5, colour = "grey20") +
  geom_pointrange(aes(ymin = lower, ymax = upper), position=position_dodge(width=0.6))+
  #coord_flip() +
  scale_y_log10()+
  #facet_grid(pcr_primers~.) +
  base_theme+
  scale_colour_brewer(palette="Paired") +
  labs(
    x = NULL,
    colour="PCR primers",
    y = "Efficiency / Geometric mean") +
  theme(axis.text.x = element_text(face = "italic"),
        legend.position = "bottom")

gg.bias

#bias is missing for BF1 biarmipes because it was low reads
```

## Multifig1

Comparison of primers for bias, off-target amp, and PCA of overlap

```{r run 1 multifig}

fig1a <- mock_tree + gg.run1_heatmap + plot_layout(widths = c(1,6))

fig1 <- fig1a / gg.bias + plot_layout(heights = c(2,1))+ plot_annotation(tag_levels = 'A') & theme(plot.margin = unit(c(1,1,1,1), "mm"))

fig1
# Write out figure 1
pdf(file="fig/run1_multifig.pdf", width = 11, height = 8 , paper="a4r")
  plot(fig1)
try(dev.off(), silent=TRUE)
```



## Classification summary

The ratio of root assigned reads to those under species level can be used as a proxy for taxonomic assignment

```{r, run 1 tax summary}
# Subset to run 1
ps <- readRDS("output/rds/ps_idtaxaExact.rds")%>%
  subset_samples(fcid %in% c("CB3DR")) 

tax_summary <- speedyseq::psmelt(ps) %>%
  dplyr::select(pcr_primers, sample_id, rank_names(ps), Abundance) %>%
  pivot_longer(rank_names(ps),
               names_to="rank",
               values_to="name") %>%

  mutate(name = replace(name, str_detect(name, "__"), NA),
         rank = str_replace(rank, "Kingdom", "Root")) %>% 
    mutate(detection = case_when(
    Abundance > 0 ~ 1,
    Abundance == 0 ~ 0
  )) %>%
  group_by(pcr_primers, rank) %>% 
  #dplyr::filter(!is.na(name)) %>%
  dplyr::summarise(reads_classified = sum(Abundance * !is.na(name)),
                   asvs_classified = sum(detection * !is.na(name)))

# Lineplot
tax_plot_data <- tax_summary %>%
  ungroup %>%
  filter(!rank=="Root") %>%
  left_join(tax_summary %>% 
              filter(rank=="Root") %>%
              dplyr::select(pcr_primers, root_reads = reads_classified, root_asv = asvs_classified)) %>%
  mutate(read_prop = reads_classified / root_reads,
         asv_prop = asvs_classified / root_asv)%>% 
  dplyr::select(pcr_primers, rank, contains("prop"))  %>%
  pivot_longer(contains("prop"),
               names_to="type",
               values_to = "value") %>%
  mutate(type = type %>% 
           str_replace("asv_prop", "ASVs classified") %>%
           str_replace("read_prop", "Sequences classified")) %>%
  mutate(rank = factor(rank, levels = rank_names(ps)[2:length(rank_names(ps))]))

gg.reads_classified <- tax_plot_data  %>%
  ggplot(aes(x=rank, y=value, fill = pcr_primers, group=pcr_primers)) +
  geom_col(width=0.7, position=position_dodge(width = 0.8)) +
  #geom_text(aes(label = percent(value, accuracy = 0.1)),
  #          position=position_dodge(width = 0.8), angle=270,hjust =-0.1, colour="white", size=4 )+
  base_theme +
  facet_wrap(~type, nrow = 2)+
  #facet_grid(~type, cols=1, rows=2) +
  scale_fill_brewer(palette="Paired") +
  scale_y_continuous(labels = scales::percent) +
  labs(x = NULL,
       y=NULL)


gg.reads_classified
```


# Supplementary Comparison of primer replicates for detection and bias

# Run 2 - comparison between replicate primers

Run 2 - see the differences in bias between replicates

```{R run2}
# RUN 2
ps_run2 <- readRDS("output/rds/ps_idtaxaExact.rds") %>%
  subset_samples(fcid %in% c("CK3HD")) %>%
  filter_taxa( function(x) mean(x) > 0, TRUE) %>%
  speedyseq::tax_glom(taxrank="Species")

exp <- read_csv("sample_data/expected_quant_merged.csv") %>%
  dplyr::rename(sample_name = Sample) %>%
  pivot_longer(-sample_name,
               names_to= "taxon",
               values_to= "expected") %>%
  mutate(taxon = str_replace(taxon, pattern="_",replacement=" "),
         sample_name = str_remove(sample_name, "-exp*.$")) %>%
  dplyr::filter(!is.na(sample_name),
  !str_detect(sample_name, "CM[0-9]|CT[0-9]|CML[0-9]|Syn"),
  expected > 0) %>%
  distinct()

#Get observed

sam <- ps_run2%>%
  speedyseq::psmelt() %>%
  janitor::clean_names() %>%
  mutate(taxon = species) %>%
  filter(!str_detect(genus, "__")) %>%#Remove unclassified
  dplyr::select(sample_name, sample_id, amp_rep, taxon, abundance, pcr_primers, fcid, material_type = type) %>%
  mutate(sample_name = sample_name %>%
           str_remove_all("BF1-BR1-|SauronS878-HexCOIR4-|fwhF2-HexCOIR4-|fwhF2-fwhR2n-") %>%
           str_remove_all("HLVKYDMXX_|CK3HD_|CB3DR_|CJKFJ_"))

#Join tables 
joint <- sam %>%
  filter(taxon %in% exp$taxon,
         sample_name %in% exp$sample_name,
         abundance > 0) %>%
  left_join(exp, by = c("sample_name","taxon")) %>%
  dplyr::rename(observed = abundance) %>%
  mutate(expected = replace_na(expected, 0),
         observed0 = (observed + 0.5) * (expected > 0),
         error = observed0 / expected) %>%
  distinct() %>%
  group_by(sample_id) %>%
  mutate_at(vars(observed, expected), ~ . / sum(.) ) %>% #Convert to proportions
  ungroup() %>%
  group_by(sample_id) %>%
  group_modify(~{
    clr_denom <- .x %>%
      pull(error) %>%
      gm_mean(na.rm = TRUE)
    .x %>%
      mutate(error_clr = log(error / clr_denom))
  })

# Bootstrap estimation
set.seed(606)
boot_models <- joint %>%
  filter(material_type=="DrosMock") %>%
  filter(expected > 0) %>%
  group_by(pcr_primers, amp_rep) %>%
  group_modify(~{
    bootstraps(.x, times=1000, apparant=TRUE)  %>%
    mutate(fit =  purrr::map(splits, ~lm(error_clr ~ 0 + taxon , data = .)), 
           coef =  purrr::map(fit, function(x){
             broom::tidy(x) %>% 
               mutate(estimate = exp(estimate))})) %>%
    int_pctl(coef) %>%
    mutate(taxon = str_remove(term, "taxon"))
    }) %>%
  dplyr::select(pcr_primers, amp_rep, taxon, lower = .lower, estimate = .estimate, upper = .upper)

# See how well bias estiamte fits data
preds <- joint %>%
  left_join(boot_models) %>%
  dplyr::mutate(predicted = expected * estimate) %>%
  group_by(sample_id) %>%
  mutate_at(vars(predicted), ~ . / sum(., na.rm=TRUE) ) %>%
  filter(expected > 0) %>%
  filter(observed > 0)

# Plot bias estimates for the 3 separate primers
gg.biasreps <- preds %>%
  ungroup() %>%
  dplyr::select(taxon, estimate, upper, lower, pcr_primers, amp_rep) %>%
  distinct()%>%
  mutate(amp_rep = factor(amp_rep, levels = c("1","2","3"))) %>%
  mutate(taxon = str_replace(taxon, "^.*_", "D. ")) %>%
  ggplot(aes(x = taxon, y = estimate, colour = amp_rep, group =amp_rep)) +
  geom_hline(yintercept = 1, alpha=0.5, colour = "grey20") +
  geom_pointrange(aes(ymin = lower, ymax = upper), position=position_dodge(width=0.5))+
  facet_grid(~pcr_primers) +
  coord_flip() +
  base_theme+
  scale_y_log10()+
  scale_colour_brewer(palette="Paired") +
  labs(
    x = NULL,
    y = "Efficiency / Geometric mean",
    colour = "Tagged PCR primer") +
  theme(axis.text.y = element_text(face = "italic"),
        legend.position = "bottom")

gg.biasreps

# Write supplementary figure
pdf(file="fig/supplementary/run2_biasreps.pdf", width = 11, height = 8 , paper="a4r")
  plot(gg.biasreps)
try(dev.off(), silent=TRUE)
```

# Trap catch analysis

## Insects trapped summary

```{r Trapped insects}
trapdat <- read_csv("Fieldwork/trap_data_clean.csv") %>%
  janitor::clean_names()%>%
  mutate(catch = as.numeric(catch)) %>%
  mutate(orchard_type = case_when(
         str_detect(fruit, "Peach") ~ "Stonefruit",
         str_detect(fruit, "Nectarine") ~ "Stonefruit",
         str_detect(fruit, "Cherries") ~ "Cherries",
         TRUE ~ "Cherries"
  )) %>%
  dplyr::filter(!attractant=="Sachet") %>%
  dplyr::select(-treatment)


# Average catch
trapdat %>%
  group_by(week, attractant, orchard, orchard_type) %>%
  dplyr::summarise(catch = sum(catch, na.rm=TRUE))
  
##Total catch by orchard and week
gg.trapweek <- trapdat %>% 
  mutate(week = as.factor(week)) %>%
  ggplot(aes(x=week, y=catch, colour=attractant, group=week))+
  geom_jitter(size=2, alpha=0.6, width=0.2, height=0.2)+
  geom_boxplot(fill=NA, outlier.colour = NA)+
  facet_grid(attractant~orchard_type, scales="free") +
  base_theme +
  scale_colour_brewer(palette="Paired") 

##Total catch by orchard and trap type
gg.trapall <- trapdat %>% 
  ggplot(aes(x=attractant, y=catch, colour=attractant))+
  geom_jitter(size=2, alpha=0.6, width=0.2, height=0.2)+
  geom_boxplot(fill=NA, outlier.colour = NA)+
  facet_grid(~orchard_type) +
  base_theme +
  scale_colour_brewer(palette="Paired")  + 
  labs(x = "Collection method",
       y = "Estimated trap catch")


```

## Subset to just run 3

```{r subset}
ps_run3 <- ps2 %>%
  subset_samples(fcid %in% c("HLVKYDMXX")) %>%
  subset_taxa(Phylum =="Arthropoda") %>%
  #prune_taxa(!str_detect(Species, "Synthetic")) %>%
  filter_taxa( function(x) mean(x) > 0, TRUE)

ps_run3 <-  prune_samples(sample_sums(ps_run3) >0 , ps_run3)

# Need to remove synthetics
```

## Alpha diversity metrics

No significant differences

```{r alpha div}
dir.create("output/alpha")

# Get a histogram of taxon sums
taxa_sums(ps_run3) %>%
  as_tibble(rownames = "OTU") %>%
  filter(value > 0) %>%
  ggplot(aes(x = value)) +
  geom_histogram() 

# Get richness measures
richness <- phyloseq::estimate_richness(ps_run3, measures=c("Chao1", "Shannon", "Simpson")) %>% #
  rownames_to_column("sample_name") %>%
  mutate(sample_name = str_replace(sample_name, "\\.", "-"))

#Richness is giving a warning because its acting on the trimemd dataset

#Set number of randomisations for calculating significance
# Calculate Faith's PD-index & Species richness - with Standard errors
sespd <- picante::ses.pd(as(phyloseq::otu_table(ps_run3), "matrix"),  phyloseq::phy_tree(ps_run3), null.model = "taxa.labels", include.root = F, runs = 9)

# Join together
div_table <- sespd %>%
  rownames_to_column("sample_name") %>%
  dplyr::select(sample_name, ntaxa, pd.obs) %>%
  dplyr::rename(pd = pd.obs, alpha = ntaxa) %>%
  left_join(richness, by="sample_name") %>%
  left_join(sample_data(ps_run3) %>% 
              as("data.frame") %>%
              filter(!duplicated(sample_id)) %>%
              dplyr::select(amp_rep, sample_name = sample_id, type),
            by = "sample_name") 

# Filter to just the field collected types
div_table <- div_table %>%
  filter(type %in% c("DC", "ACV", "FF", "SPD"))

# Summarise means
div_table %>%
  summarise(across(where(is.numeric), mean, na.rm=TRUE))

# Difference in alpha diversity between replicates
#report::report(aov(alpha ~amp_rep, data=div_table))
#report::report(aov(Shannon ~amp_rep, data=div_table))
#report::report(aov(pd ~amp_rep, data=div_table))
#
# Difference in alpha diversity between trap types
report::report(aov(alpha ~type, data=div_table))
broom::tidy(TukeyHSD(aov(alpha ~type, data=div_table)))

report::report(aov(Shannon ~type, data=div_table))
broom::tidy(TukeyHSD(aov(Shannon ~type, data=div_table)))

report::report(aov(pd ~type, data=div_table))
broom::tidy(TukeyHSD(aov(pd ~type, data=div_table)))

# SHould do on the original data without merging by spp

# plot differences in alpha diversity
gg.alpha <- div_table %>% 
  pivot_longer(2:7,
               names_to="metric",
               values_to="value") %>%
  filter(metric %in% c("alpha", "pd", "Shannon")) %>%
  mutate(metric = metric %>% 
           str_replace("alpha", "ASV Richness") %>%
           str_replace("pd", "Phylogenetic Diversity") %>%
           str_replace("Shannon", "Shannon Index")) %>%
  ggplot(aes(x=type, y=value, colour=type)) +
  geom_jitter(size=2, alpha=0.6, width=0.2, height=0)+
  geom_boxplot(fill=NA)+
  coord_flip()+
  base_theme+
  scale_colour_brewer(palette="Paired") +
  facet_wrap(.~metric,ncol=1, scales="free")

gg.alpha

pdf(file="fig/supplementary/trap_catches.pdf", width = 8, height = 6 , paper="a4r")
  plot(gg.trapweek)
  plot(gg.trapall)
  plot(gg.alpha)
try(dev.off(), silent=TRUE)

# This could be nice really small, under the total catch

```

## Beta diversity metrics

```{r Distances}
# Get OTU tables
otutab <- otu_table(ps_run3) %>%
  as("matrix")
#Impute zeroes for compositional distances
otutab_n0 <- as.matrix(zCompositions::cmultRepl(otutab, method="CZM", output="p-counts"))
#Root phylogenetic tree
phy_tree(ps_run3) <- multi2di(phy_tree(ps_run3))
phy_tree(ps_run3) <- makeNodeLabel(phy_tree(ps_run3), method="number", prefix='n')
name.balance(phy_tree(ps_run3), tax_table(ps_run3), 'n1') #Get root

#Calculate different distance metrics
metrics <- c("Bray", "Jaccard", "Aitchison", "Philr", "Unifrac", "WUnifrac")
distlist <- vector("list", length=length(metrics))
names(distlist) <- metrics

distlist$Jaccard <- as.matrix(vegdist(otutab, method="jac",binary = T))
distlist$Bray <- as.matrix(vegdist(otutab, method="bray"))
distlist$Aitchison <- as.matrix(vegdist(CoDaSeq::codaSeq.clr(otutab_n0), method="euclidean"))
distlist$Philr <- as.matrix(vegdist(philr::philr(otutab_n0, phy_tree(ps_run3),
                                                part.weights='enorm.x.gm.counts',
                                                ilr.weights='blw.sqrt'), method="euclidean"))
distlist$Unifrac <- as.matrix(phyloseq::UniFrac(ps_run3, weighted=FALSE, parallel = TRUE))
distlist$WUnifrac <- as.matrix(phyloseq::UniFrac(ps_run3, weighted=TRUE, parallel = TRUE))

# Probably only need to use philr dist
```

# Adonis and betadisper

```{r betatest}
# Adonis test
metadata <- sample_data(ps_run3) %>%
  as("data.frame")

# Test difference by community type
adonis_results <- distlist %>%
  purrr::map(function(x) {
    bind_rows(
    broom::tidy(adonis(x~type, method="euclidean", data=metadata)$aov.tab) #%>% dplyr::slice(1)
    )
})  %>%
  bind_rows(.id="dist")

# Check homogeneity
betadisper_results <- distlist %>%
  purrr::map(function(x) {
    y <- as.dist(x[metadata$sample_id, metadata$sample_id])
  bind_rows(
    as.data.frame(permutest(vegan::betadisper(y, metadata$type))$tab) %>%
      #dplyr::slice(1) %>% 
      mutate(term="type")
  )
})  %>%
  bind_rows(.id="dist")

dir.create("output/beta")
write_csv(adonis_results, "output/beta/adonis.csv")
write_csv(betadisper_results, "output/beta/adonis.csv")
```

# PCA plots

```{r pca plots}
# Get philr distance
philr.dist <- as.dist(distlist$Philr)

#Philr PCOA
philr.pcoa <- ordinate(ps_run3, 'PCoA', distance=philr.dist)

gg.pca <- plot_ordination(ps_run3, philr.pcoa, color = "type") +
  geom_point(size=3, alpha=0.8) +
  geom_hline(yintercept = 0, linetype=2, alpha=0.5) +  
  geom_vline(xintercept = 0, linetype=2, alpha=0.5) +
  base_theme +
  #coord_fixed() +
  scale_colour_brewer(palette="Paired") +
  theme(legend.position = "bottom") +
  labs(colour = "Sample Type")

gg.pca

# Heirarchial clustering
dend <- hclust(philr.dist, method="average")

p3 <- ggtree(as.phylo(dend) ) + 
  theme_tree2()

colours_p3 <- p3$data %>%
  left_join(as_data_frame(sample_data(ps_run3)) %>%
              dplyr::select(sample_id, type) %>%
  dplyr::rename(label = sample_id)
    )

p3 <- p3 %<+% colours_p3  + 
  geom_tippoint(aes(colour=as.factor(type)))  + 
  geom_tiplab(aes(colour=as.factor(type)))+
  scale_colour_brewer(palette="Paired") +
    scale_x_continuous(expand=c(0, 30)) +
  theme(legend.position = "none")

# Plot together
p3 + gg.pca


```

# Plot a heatmap of insect distances vs clustering of samples

```{r Heatmap}
#Prepare co-occurance matrix
coocur <- ps_run3 %>%
    otu_table %>%
    as("matrix")

# Sample tree 
h_tree <- as.phylo(dend)

# P cophenetic distance
s_tree <- phy_tree(ps_run3)

s_tree <- drop.tip(s_tree, setdiff(s_tree$tip.label, colnames(coocur)))
coocur <- coocur[h_tree$tip.label, s_tree$tip.label]

#Could do the imputing on coocur

# Cophyloplot
coocur.lut <- which(coocur >0, arr.ind=TRUE)
assoc <- cbind(rownames(coocur)[coocur.lut[,1]], colnames(coocur)[coocur.lut[,2]])
# Rotate the nodes using phytools
obj <- cophylo(tr1=h_tree, tr2=s_tree, assoc=assoc, rotate=TRUE) 

# Extract the goods for ggtree
tree1 <- obj[["trees"]][[1]]
p1 <- ggtree(tree1, ladderize=FALSE) + geom_tiplab()

# OTU tree
tree2 <- obj[["trees"]][[2]]
p2 <- ggtree(tree2, ladderize=FALSE) + geom_tiplab()

# Tanglegram
dd <- obj$assoc %>%
  as_data_frame() %>%
  magrittr::set_colnames(c("label.x", "label.y")) %>%
  left_join(p1$data %>% dplyr::select(label, y) %>% dplyr::rename(label.x = label), by="label.x") %>%
  left_join(p2$data %>% dplyr::select(label, y) %>% dplyr::rename(label.y = label), by="label.y") %>%
  rownames_to_column("assoc")

gg.heatmap <- dd %>%
  dplyr::rename(Sample_Name = label.x,
                OTU = label.y,
                pos_x = y.x,
                pos_y = y.y) %>%
  dplyr::select(Sample_Name, OTU, pos_x, pos_y) %>%
  dplyr::mutate(Sample_Name = factor(Sample_Name),
                Sample_Name = fct_reorder(Sample_Name, pos_x),
                OTU = factor(OTU),
                OTU = fct_reorder(OTU, pos_y)) %>%
   ggplot(aes(x=Sample_Name, y=OTU)) +
  geom_tile() +
  base_theme+
  theme(axis.text.x = element_text(angle=45, hjust=1),
        axis.title.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank(),
        legend.position = "none") 

#Adjusted trees - Sca

top <- wrap_elements(grid::textGrob('')) +(p1+ coord_flip() + scale_x_reverse(expand=c(0,0))+ scale_y_continuous(expand=c(0,0))) + plot_layout(widths=c(1,3)) 
bottom <- p2+ scale_y_continuous(expand=c(0,0)) +gg.heatmap + plot_layout(widths=c(1,3))

gg.treemap <- top / bottom + plot_layout(heights=c(1,3))                                                         

gg.treemap

gg.heatmap <- psmelt(ps_run3) %>%
  dplyr::select(Abundance, label = sample_id, OTU, rank_names(ps_run3)) %>%
  left_join(p3$data) %>%
  group_by(label) %>%
  mutate(Abundance = replace(Abundance, Abundance==0, 0.5)) %>%
  mutate(Abundance = metacal::clr(Abundance, na.rm = TRUE)) %>%
  ungroup %>%
  ggplot(aes(x = label, y = Species, fill = Abundance )) +
  geom_tile() +
  base_theme
  
(p3 + coord_flip() + scale_x_reverse()) / gg.heatmap

```

# Phylogeny of trap catches

```{r Phylogeny}

taxa_names(ps_run3) <- taxa_names(ps_run3)%>% str_remove("^.*-")

tree <- phy_tree(ps_run3)

# Colour tree by order
#


p1dat <- speedyseq::psmelt(ps_run3) %>%
  dplyr::select(sample_id, OTU, type, Abundance) %>%
  #group_by(sample_id) %>%  
  #mutate_at(vars(Abundance), ~ . / sum(.)) %>%
  filter(Abundance > 0) %>%
  drop_na() %>%
  dplyr::filter(type %in% c("ACV", "DC", "FF", "SPD")) %>%
  group_by(OTU, type) %>%
  summarise(Abundance = sum(Abundance)) %>%
  distinct() %>%
  pivot_wider(names_from = type,
              values_from = Abundance,
              values_fill = 0) %>%
  column_to_rownames("OTU")

tree <- drop.tip(tree, tree$tip.label[!tree$tip.label %in% rownames(p1dat)])

circ <- ggtree(tree, layout = "circular", branch.length = 'none')

p1 <- gheatmap(circ, p1dat, offset=0, width=.4, color="gray20",
               colnames_angle=95, colnames_offset_y = 0) +
    scale_fill_viridis_c(option="D", name="Abundance", alpha=0.9, trans="log10") 

# Also try add week? and orchard?
library(ggnewscale)
p2dat <- speedyseq::psmelt(ps_run3) %>%
  mutate(orchard = case_when(
    str_detect(sample_name,"^T") ~ "Stonefruit",
    str_detect(sample_name,"^M") ~ "Cherries",
    TRUE ~ as.character(NA)
  )) %>%
  dplyr::select(OTU, orchard, Abundance) %>%
    filter(Abundance > 0) %>%
  drop_na() %>%
  group_by(OTU, orchard) %>%
  summarise(Abundance = sum(Abundance)) %>%
  distinct() %>%
  pivot_wider(names_from = orchard,
              values_from = Abundance,
              values_fill = 0) %>%
  column_to_rownames("OTU")
  
p2 <- p1 + new_scale_fill()
gg.phylo <- gheatmap(p2, p2dat, offset=5.5, width=.2,
         colnames_angle=90, colnames_offset_y = .25, color="gray20") +
    scale_fill_viridis_c(option="B", name="Abundance", trans="log10")+
  geom_tiplab(offset=9, align=FALSE, size=3) 

#p3 <- p2 + new_scale_fill()
#gg.phylo <- gheatmap(p3, p2dat %>% dplyr::select(Stonefruit), offset=7, width=.2,
#         colnames_angle=90, colnames_offset_y = .25, color="gray20") +
#    #scale_fill_gradient(low="sandybrown", high="firebrick", trans="log10")+
#    scale_fill_viridis_c(option="B", name="Abundance", trans="log10")+ 
#    geom_tiplab(offset=12, align=FALSE, size=3) 
#
gg.phylo

# Write out bias explained for supplementary 
pdf(file="fig/phylogeny_occurance.pdf", width = 11, height = 8 , paper="a4r")
  plot(gg.phylo)
try(dev.off(), silent=TRUE)
  
# Colour tree by Order - should be able to do this with highlight clade
# need to make the tree better though

# Work out how to properly compositionall merge a sample

```

## Detection probability

How do the primers affect its probability of detection (presence/absence). We used a generalized linear mixed effects model of presence/absense as a function of primer primer. To account for the paired design (where both types of samples were derived from the same community), we defined Sample ID as a random effect. Since the response was binomial, we assumed a logit‐link and binomially distributed error

```{r detection probability}
# Use joint to get a table of expected/absent
det_table <- joint %>% 
  filter(material_type=="DrosMock") %>%
  mutate(detected = case_when(
    expected > 0 & observed > 0 ~ 1,
    expected > 0 & observed == 0 ~ 0,
    TRUE ~ as.numeric(NA)
    )) %>%
  filter(!is.na(detected)) %>% #Still some false positives remeaining!
  mutate(extract_id = sample_name %>%
           str_remove_all("BF1-BR1-|fwhF2-fwhR2n-|SauronS878-HexCOIR4-|fwhF2-HexCOIR4-"))

# Estimate detection efficiency of all taxa - Better done within tidymodels?
library(lme4)
detmodel <- det_table %>%
  filter(fcid=="CB3DR") %>%
  dplyr::select(sample_id, extract_id, taxon, detected, pcr_primers) %>%
  #group_by(taxon) %>%
  nest() %>%
  mutate(fit = map(data, ~glmer(detected ~ pcr_primers + (1|extract_id), family=binomial, data = .)), 
           tidied = map(fit, broom::tidy),
           aug = map(fit, broom::augment)

  ) %>%
  dplyr::select(-fit) %>%
  unnest(tidied) 

# Estimate detection efficiency of targets - Doesnt work because they were pretty much all detected!
library(lme4)
det_suzukii <- det_table %>%
  filter(fcid=="CB3DR") %>%
  group_by(taxon) %>%
  nest() %>%
  mutate(fit = map(data, ~glmer(detected ~ pcr_primers + (1|extract_id), family=binomial, data = .)), 
           tidied = map(fit, broom::tidy),
           aug = map(fit, broom::augment)

  ) %>%
  dplyr::select(-fit) %>%
  unnest(tidied) 

det_suzukii
```

### eDNAoccupancy

```{r edna occupancy}

library(eDNAoccupancy)
data(fungusDetectionData)
data(fungusSurveyData)

# Make detection table
ps_qual <- ps %>%
  speedyseq::tax_glom(taxrank="Species") %>%
  transform_sample_counts(function (x) (x > 0) * 1) %>%
  #merge_samples(group = "ExtractID") %>%
  speedyseq::psmelt() %>%
  select(Sample, Abundance, Species) %>%
  separate(Sample, into=c("site", "rep"), sep="-rep") %>%
  mutate(rep=paste0("pcr",rep)) %>%
  separate(site, into=c("site", "sample"), sep="-ex") %>%
  pivot_wider(names_from=rep, values_from = Abundance, values_fill=list(Abundance = 0)) 

det_suzukii <- ps_qual %>%
  mutate(site = str_replace(site, "DM", "D100M")) %>%
  filter(Species=="Drosophila_suzukii") %>%
  filter(str_detect(site,"D100M|D250M|D500M|D1000M")) %>%
  select(site, sample, pcr1, pcr2, pcr3) %>%
  mutate(sample = as.integer(sample)) %>%
  arrange(sample) %>%
  as.data.frame()

suzukii_detections = occData(det_suzukii, siteColName = 'site',
                            sampleColName = 'sample')

#Make covariate tables

# Read in expected table
exp <- read_csv("sample_data/expected_quant_merged.csv") %>%
  gather(Species, Actual, -X1) %>%
  mutate(Species = str_replace(Species, pattern=" ",replacement="_")) %>%
  filter(str_detect(X1,"D100M|D250M|D500M|D1000M|DLarv")) %>%
  drop_na() %>%
  set_colnames(c("Sample","Species","Actual"))
# Add true presence

#Add community size covariate

commsize <- exp %>%
  group_by(Sample) %>%
  summarise(commsize = sum(Actual)) %>%
  mutate(Sample = str_replace_all(Sample, pattern="(-)(.*?)(?=$)", replacement=""))

survey_data <- samdf %>%
  remove_rownames() %>%
  mutate(Sample = str_replace_all(ExtractID, pattern="(-)(.*?)(?=$)", replacement="")) %>%
  select(Sample, geo_loc_name, material) %>%
  left_join(commsize, by="Sample") %>%
  rename(site = Sample) %>%
  filter(str_detect(site,"D100M|D250M|D500M|D1000M")) %>%
  unique()

# Add alpha diversity covariates

# Try using hill numbers for these https://github.com/anttonalberdi/hilldiv

#estimate richness
alpha_table <- phyloseq::estimate_richness(ps2)

# Calculate Faith's PD-index
pdtable <- picante::pd(as(phyloseq::otu_table(ps2), "matrix"), phyloseq::phy_tree(ps2), include.root = F)




 ## number of detections per sample
 head(suzukii_detections$y)
 ## number of PCR replicates per sample
 head(suzukii_detections$K)

#We fit a multi-scale occupancy model without covariates and print a summary of the parameter estimates using the following code.

 set.seed(69)
 fit = occModel(detectionMats=suzukii_detections, niter=11000,
                niterInterval=5000)
 posteriorSummary(fit, burnin=1000, mcError=TRUE)


## Center and scale numeric-valued covariate measurements
survey_data.sc = scaleData(survey_data)

set.seed(0157)
fit = occModel(formulaSite          = ~ 1,
               formulaSiteAndSample = ~ commsize,
               formulaReplicate     = ~ commsize,
               detectionMats        = suzukii_detections,
               siteData             = survey_data.sc,
               niter                = 6000,
               niterInterval        = 2000,
               siteColName = 'site'
               )
posteriorSummary(fit, burnin=1000, mcError=TRUE)


#If we want to assess whether the Markov chain used to compute these estimates appears to have converged, trace plots of the parameters may be created as follows (Fig.~\ref{fig:TracePlotFungusAnalysis}).
plotTrace(fit, c('beta.(Intercept)', 'alpha.(Intercept)', 'alpha.frogs',
            'delta.(Intercept)'),  burnin=1000)

#Autocorrelation plots of the parameters are created similarly
 plotACF(fit, c('beta.(Intercept)', 'alpha.(Intercept)', 'alpha.frogs',
             'delta.(Intercept)'),  burnin=1000)

#After inspection of these plots, suppose we decide that the MCMC algorithm needs to be run longer, either to eliminate the transient portion of the Markov chain or to reduce Monte Carlo errors in the parameter estimates.  We can resume the MCMC algorithm for the currently fitted model as follows.
 fit = updateOccModel(fit, niter=5000, niterInterval=2000)
 posteriorSummary(fit, burnin=1000,  mcError=TRUE)

 #These estimates of the parameters are computed using the updated Markov chain containing \rinline{fit$niterations} iterations.  The Monte Carlo errors in these parameter estimates are slightly lower, but the estimates are otherwise similar to those computed with only \rinline{fit$niterations-5000} iterations.

#In addition to estimating posterior summaries of the model's formal parameters, we also may be interested in estimating posterior summaries of derived parameters.  For example, in the second model fitted to the \emph{Bd} data, the probability of eDNA occurrence in ponds was assumed to be constant ($\psi$), the conditional probability of eDNA occurrence in samples was assumed to be a function of the frog density index \code{frogs}, and the conditional probability of eDNA detection was assumed to be constant ($p$).  The posterior medians of these derived parameters are estimated as follows.

psi = posteriorSummaryOfSiteOccupancy(fit, burnin=1000)
theta = posteriorSummaryOfSampleOccupancy(fit, burnin=1000)
p = posteriorSummaryOfDetection(fit, burnin=1000)

 ## output estimates of posterior medians
 cbind(psi=psi$median, theta=theta$median[,1], p=p$median[,1])

 frogs = fungusSurveyData[, 'frogs']
 plot(frogs, theta$median[,1], ylim=c(0,1), xlim=c(0,0.8), cex=2)
 segments(frogs, theta$lower[,1], frogs, theta$upper[,1], lwd=2)
 
#One way to assess the relative importance of such estimated relationships is to compare competing models using model-selection criteria.  For example, we compute the PPLC and WAIC criteria for the previously fitted model as follows.
 posteriorPredictiveLoss(fit, burnin=1000)
 WAIC(fit, burnin=1000)

```

\#\#\#Seak occupancy

Seak occupancy modelling - The model is fitted within a Bayesian framework and any of the model parameters can be functions of covariates. The implemented algorithm performs Bayesian variable selection and the output includes posterior summaries of all parameters as well as posterior probabilities of inclusion (see examples for a more detailed description of how to interpret the output).

The model has been developed for single species qPCR data. The data are the number of positive qPCRs (eDNA score) for each water sample collected at surveyed sites. The model allows us to estimate the probability of species presence at each survey site, while accounting for the probabilities of a false positive and false negative error at stage 1 (field) and stage 2 (lab).

Occupancy modelling calculates the probability of detection from a number of replicates. ie - 6 replicates positive = 100% probaiblity , 5/6 = 85% probability

Nested levels = Replicated extractions, replicated PCRs .

Could fit a single specied

For model taking into accoutn false poositives and negatives: <https://seak.shinyapps.io/eDNA/>

This requires format

Columns = Sample (extraciton replicate ) so 2 columns Rows = site (trap) cell value = number of positive PCR replicates (out of 3) Column 3 = True presence or absense 1 or 0 column 4,5,6 etc other covariates. Sequencing depth, community size, species richness,trap type, phylogenetic richness... etc

```{r occupancy}
#convert to presence/absense
ps_qual <- ps %>%
  speedyseq::tax_glom(taxrank="Species") %>%
  transform_sample_counts(function (x) (x > 0) * 1) %>%
  merge_samples(group = "Sample_Name") %>%
  speedyseq::psmelt() %>%
  dplyr::select(Sample, Abundance, Species) %>%
  mutate(Sample = str_remove(Sample, "^.*_")) %>%
  separate(Sample, into=c("Sample", "exrep"), sep="-ex") %>%
  pivot_wider(names_from=exrep, values_from = Abundance, values_fill=list(Abundance = 0)) %>%
  dplyr::select(Sample, Species, `1`, `2`,)

# Read in expected table
exp <- read_csv("sample_data/expected_quant_merged.csv") %>%
  gather(Species, Actual, -X1) %>%
  mutate(Species = str_replace(Species, pattern=" ",replacement="_")) %>%
  #filter(str_detect(X1,"D100M|D250M|D500M|D1000M|DLarv")) %>%
  drop_na() %>%
  set_colnames(c("Sample","Species","Actual"))
# Add true presence

true_pres <- exp %>%
  mutate(Sample = str_replace_all(Sample, pattern="(-)(.*?)(?=$)", replacement="")) %>%
  mutate(Actual = case_when(
    Actual > 0 ~ 1,
    Actual == 0 ~ 0
  )) %>%
  unique()
  
#Add community size covariate - need to estimate for others

commsize <- exp %>%
  group_by(Sample) %>%
  summarise(commsize = sum(Actual)) %>%
  mutate(Sample = str_replace_all(Sample, pattern="(-)(.*?)(?=$)", replacement=""))

# add seqdepth covariate

#filterdepth

#richness
richness <- ps_qual %>%
  mutate(Sample = str_replace(Sample, "DM", "D100M")) %>%
  ungroup() %>%
  mutate(total = `1`+`2`) %>%
  filter(total > 0) %>%
  group_by(Sample) %>%
  summarise(richness= n())  

# Species evenness

# Phylogenetic diversity


#trap_type
comm_type <- exp %>%
  mutate(Sample = str_replace_all(Sample, pattern="(-)(.*?)(?=$)", replacement="")) %>%
  mutate(comm_type = case_when(
    str_detect(Sample, "D100M|D250M|D500M|D1000M") ~ "Mock",
    str_detect(Sample, "DLarv") ~ "Larvae",
    str_detect(Sample, "ACV") ~ "ACV",
    str_detect(Sample, "FF") ~ "FF",
    str_detect(Sample, "SPD") ~ "SPD",
    str_detect(Sample, "DC") ~ "DC",
  )) %>%
  dplyr::select(Sample, comm_type) %>%
  unique()
  

# Get suzukii only
det_suzukii <- ps_qual %>%
  mutate(Sample = str_replace(Sample, "DM", "D100M")) %>%
  left_join(true_pres, by=c("Sample", "Species"))%>%
  left_join(commsize, by="Sample") %>%
  left_join(richness, by="Sample") %>%
  left_join(comm_type, by="Sample") %>%
  filter(Species == "Drosophila_suzukii") %>%
  dplyr::select(-Species) %>%
  unique() %>%
  mutate(Actual = replace_na(Actual, 0))  %>%
  filter(!is.na(commsize)) %>%
  mutate(commsize = scale(commsize, center = TRUE, scale = TRUE))  %>%
  #mutate(random = scale(rbinom(nrow(.), 100, 0.7), center = TRUE, scale=TRUE)) %>%
  #mutate(random2 = scale(rbinom(nrow(.), 100, 0.4), center = TRUE, scale=TRUE)) %>%
  mutate(richness = scale(richness, center = TRUE, scale = TRUE))  %>%
  filter(!str_detect(Sample, "DLarv"))# %>%
  #set_rownames(.$Sample) #%>%
  dplyr::select(-Sample)
  
write.csv(det_suzukii, "test_occupancy_suzukii.csv", row.names=FALSE)

```

For sequencing depth covariate could you just rarefy to certain depth, recalculate detection, then rbind a longer table together in a loop Same with filtering threshold

these could be fit seperately for our 3 target species

Then we can look at how the detection probability changes across different filtering thresholds used to remove index switching?

To test if probability of detection differs as a function of sample water volume, we used the eDNAoccupancy R package (version 0.2.4; Dorazio & Erickson, 2017) to model probabilities of eDNA detection. This package fits Bayesian, multi‐scale occupancy models to our data, which included three, nested levels of sampling: stream location, replicated water samples collected from each stream, and subsamples (i.e., PCR technical replicates) of each water sample.

<https://onlinelibrary.wiley.com/doi/full/10.1002/edn3.23>

<https://besjournals.onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2011.00156.x>

<https://www.pnas.org/content/pnas/116/18/8931.full.pdf>

Based on the overall model, a total of seven water samples was required to achieve \>95% detection probabilities of S. mansoni eDNA at water sample level (θ = 0.35) [as calculated by using the equation P = 1 − (1 − θ) n (27)]. By using the same approach, the model-based estimated number of qPCR replicates required to achieve detection probabilities \>95% ranged from three to nine replicates between sites

## Check for concordance between mock and real

```{r PCA}
# Read in expected table
exp <- read_csv("sample_data/expected_quant_merged.csv") %>%
  gather(Species, Abundance, -X1) %>%
  mutate(Species = str_replace(Species, pattern=" ",replacement="_")) %>%
  filter(str_detect(X1,"D100M|D250M|D500M|D1000M|DLarv")) %>%
  drop_na() %>%
  set_colnames(c("Sample","Species","Actual"))

# Prepare observed table
sam <- ps.merged %>%
  speedyseq::tax_glom("Species") %>%
  transform_sample_counts(function (x) x/sum(x)) %>%
  speedyseq::psmelt() %>%
  mutate(Species = str_replace(Species, pattern="Drosophila_mauritiana/simulans", replacement= "Drosophila_simulans")) %>%
  mutate(Species = str_replace(Species, pattern="Drosophila_albomicans", replacement= "Drosophila_immigrans")) %>%
  filter(Sample %in% exp$Sample) %>%
  arrange(Abundance) %>%
  distinct() %>%
  select(Sample, Species, Abundance)

# Join tables
joint <- sam %>%
  filter(Species %in% exp$Species) %>%
  group_by(Species, Sample) %>% 
  summarise(Abundance = sum(Abundance)) %>%
  ungroup() %>%
  #mutate(Type = ifelse(Sample %in% controls, "Est", "Eval")) %>%
  bind_rows(exp %>%
              mutate(Actual = replace_na(Actual, 0)) %>%
              rename(Abundance = Actual) %>%
              filter(str_detect(Sample, pattern="-ex1"))  %>%
              mutate(Sample = str_replace_all(Sample, pattern="-ex1", replacement="-A")
            
            )) %>%
  group_by(Sample) %>%  
  mutate_at(vars(Abundance), ~ . / sum(.)) %>% # Convert to proportions
  #mutate(Abundance = Abundance + 0.0001) %>% # Add pseudocount
  #mutate(Abundance = clr(Abundance)) %>%
  ungroup()

# PCA
joint_pca <- joint %>%
  pivot_wider(
    names_from = Species, #  Switch this to transpose
    values_from = Abundance,
    values_fill = list(Abundance=0),
  ) %>%
  mutate(Extract = Sample %>% str_replace_all(pattern="(-)(.*?)(?=$)", replacement="")) %>%
  mutate(Mock = Sample %>% 
           str_replace_all(pattern="(-)(.*?)(?=$)", replacement="") %>%
           str_replace_all(pattern="(^)(.*?)(?<=M)", replacement="")) %>%
  nest(data = everything()) %>%
  mutate(pca = map(data, ~ prcomp(.x %>% select(-Sample, -Extract, -Mock), 
                                  center = TRUE, scale = TRUE)),
         pca_aug = map2(pca, data, ~augment(.x, data = .y))) 

joint_pca$pca %>%
  map(~tidy(.x, data = .y, "pcs")) %>%
  as.data.frame() %>%
  ggplot(aes(x = PC, y=percent)) +
  geom_bar(stat="identity") + labs(x="PC",y="Variance Explained")


library(RColorBrewer)
colourCount = length(cls)
getPalette = colorRampPalette(brewer.pal(12, "Spectral"))
colour.pal <- getPalette(colourCount)

joint_pca %>%
  mutate(
    pca_graph = map2(
      .x = pca,
      .y = data,
      ~ autoplot(.x, loadings = TRUE, loadings.label = TRUE,
                 loadings.label.repel = FALSE,
                 data = .y, label = TRUE,
                 label.label = "Sample",
                 label.repel = TRUE, 
                 colour='Extract') +
       #theme_bw() +
        labs(x = "Principal Component 1",
             y = "Principal Component 2",
             title = "First two principal components of PCA for expected and observed") +
        coord_fixed()#+
       # scale_colour_manual(values=col)
    )
  ) %>%
  pull(pca_graph)


## Heirarchial clustering


# Output drosophila summary
ps.merged %>% 
  subset_taxa(Family=="Drosophilidae") %>%
  microbiome::transform("compositional") %>%
  summarise_taxa("Species", "sample_id") %>%
  filter(!str_detect(sample_id, "NTC")) %>%
  #filter(str_detect(Species, "Drosophila|Scaptodrosophila")) %>%
  spread(key="sample_id", value="totalRA") %>%
  write.csv(file = "output/csv/unfiltered/drosophila_spp_sum.csv")

```

# Reproducability Receipt

```{details, echo = FALSE, details.summary = 'Reproducability receipt'}
# datetime
Sys.time()
#repository
git2r::repository()
sessioninfo::session_info()
```
