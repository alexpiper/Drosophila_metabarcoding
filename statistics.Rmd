---
title: "Drosophila Metabarcoding"
title: "Statistical analysis"
author: "Alexander Piper"
date: "`r Sys.Date()`"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

# Introduction

## Analysis structure

Part 1 - Cleanup & Filtering of index switching

Part 1 - Comparison of 4 primers for bias and detection efficiency
(figure 1)

Part 2 - Comparison of bias between 3 tagged primers

Part 3 - Comparison 


## Load packages
```{r setup}
#Set required packages
.cran_packages <- c("tidyverse",
                    "tidymodels",
                    "patchwork", 
                    "vegan", 
                    "seqinr",
                    "ape", 
                    "RColorBrewer",
                    "ggtree", 
                    "castor", 
                    "picante",
                    "devtools")
.bioc_packages <- c("dada2",
                    "phyloseq", 
                    "DECIPHER",
                    "Biostrings",
                    "ShortRead", 
                    "philr",
                    "ALDEx2")

.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install(.bioc_packages[!.inst], ask = F)
}

sapply(c(.cran_packages,.bioc_packages), require, character.only = TRUE)

# Github packages
devtools::install_github("alexpiper/taxreturn")
devtools::install_github("alexpiper/seqateurs")
devtools::install_github("mikemc/speedyseq")
devtools::install_github('ggloor/CoDaSeq/CoDaSeq')
devtools::install_github("mikemc/metacal")

library(speedyseq)
library(taxreturn)
library(seqateurs)
library(CoDaSeq)
library(metacal)

#Source internal functions
source('R/helper_functions.R')

#Source themes
source('R/themes.R')
```

## Read in phyloseq object

```{r phyloseq}
ps2 <- readRDS("output/rds/ps_filtered.rds")
```

# Comparison of 4 primers for detection and bias

# Overview of run 1

```{r run 1 overview}
ps_run1 <- ps2 %>%
  subset_samples(fcid %in% c("CB3DR")) 
ps_run1 <- ps_run1 %>%
  subset_samples(!str_detect(sample_names(ps_run1),"blank")) %>%
  filter_taxa( function(x) mean(x) > 0, TRUE) 

tax_table(ps_run1)[,7][which(tax_table(ps_run1)[,7]=="Carpophilus_dimidiatus/nr.dimidiatus")] <- "Carpophilus_nr.dimidiatus"
tax_table(ps_run1)[,7][which(tax_table(ps_run1)[,7]=="Brachypeplus_Sp1")] <- "Brachypeplus_Sp"
tax_table(ps_run1)[,7][which(tax_table(ps_run1)[,7]=="Brachypeplus_Sp2")] <- "Brachypeplus_Sp"
ps_run1 <- speedyseq::tax_glom(ps_run1, taxrank="Species")

ps_run1 %>% 
  speedyseq::psmelt() %>%
  group_by(sample_id) %>%
  mutate_at(vars(Abundance), ~ . / sum(.) ) %>% #Convert to proportions
  mutate(plotlabel = case_when(
    Abundance >= 0.01  ~ Species, # Change this to whatever taxrank we want
    Abundance < 0.01 ~ as.character(NA)
    )) %>%
  ggplot(aes(x=sample_name, y=Abundance, fill=plotlabel)) +
  geom_col(position="stack") + 
  facet_grid(target_subfragment~type, scales="free") +
  scale_y_continuous(labels = scales::percent) +
  coord_flip()+
  base_theme+
  theme(legend.position = "bottom") +
  labs(x = "Sample Name",
       y= "Relative abundance",
       fill="Species",
       title = "Run 1 - Primer testing")

# Plot as heatmap
ps_run1 %>%
  speedyseq::psmelt() %>%
  #filter(Genus=="Drosophila") %>%
  group_by(sample_id) %>%
  mutate_at(vars(Abundance), ~ . / sum(.) ) %>%
  mutate(extract_id = str_remove(sample_name, "^.*-D")) %>%
    ggplot(aes(x=extract_id, y=Species, fill=Abundance)) +
    geom_tile() +
    facet_grid(~target_subfragment, scales="free") +
  base_theme+
  theme(axis.text.x = element_text(angle=45, hjust=1),
          legend.position = "bottom") +
    scale_fill_viridis_c(labels = scales::percent) +
    labs(x="Sample",
         y="Taxon",
         fill="Relative abundance",
         title="Run 1 - Primer testing")


#Compositional PCA using PhilR
# Get OTU tables
otutab <- otu_table(ps_run1)
#Impute zeroes for compositional distances
otutab_n0 <- as.matrix(zCompositions::cmultRepl(otutab, method="CZM", output="p-counts"))
#Root phylogenetic tree
phy_tree(ps_run1) <- multi2di(phy_tree(ps_run1))
# Get philr distance
ps2.philr <- philr::philr(otutab_n0, phy_tree(ps_run1),
                     part.weights='enorm.x.gm.counts', 
                     ilr.weights='blw.sqrt')
#PCA 
pca <- prcomp(ps2.philr)

# Plot PCA 

# Get pca data
pca_data <- pca$x %>%
  as_tibble(rownames = "sample_name") %>%
  dplyr::select(1:6)%>%
  left_join(sample_data(ps_run1) %>%
              as("data.frame") %>%
    dplyr::select(sample_name, type, target_subfragment) %>%
    distinct()) %>%
  mutate(extract_id = sample_name %>%
           str_remove_all("BF1-BR1-|fwhF2-fwhR2n-|SauronS878-HexCOIR4-|fwhF2-HexCOIR4-"))

#Get PCA loadings
pca_loadings <- data.frame(OTU = rownames(pca$rotation), pca$rotation[, 1:2])
mult <- min(
    (max(pca_data$PC1) - min(pca_data$PC1)/(max(pca_loadings$PC1)-min(pca_loadings$PC1))),
    (max(pca_data$PC2) - min(pca_data$PC2)/(max(pca_loadings$PC2)-min(pca_loadings$PC2)))
    )
pca_loadings <- transform(pca_loadings,
        v1 = .7 * mult * (pca_loadings$PC1),
        v2 = .7 * mult * (pca_loadings$PC1)
        )

# calculate percent variance explained for the axis labels
pc1 <- round(pca$sdev[1]^2/sum(pca$sdev^2),2)
pc2 <- round(pca$sdev[2]^2/sum(pca$sdev^2),2)
pc_ylab <- paste("PC1: ", pc1, sep="")
pc_xlab <- paste("PC2: ", pc2, sep="")

# Plot PCA
gg.pca <- ggplot(data=pca_data, aes(x=PC2, y=PC3)) + 
  geom_point(aes(colour = extract_id, shape = target_subfragment), alpha=0.8, size=3) +
  scale_colour_brewer(palette="Paired") +
  geom_hline(yintercept = 0, linetype=2, alpha=0.5) +  
  geom_vline(xintercept = 0, linetype=2, alpha=0.5) +
  xlab(pc_xlab) + 
  ylab(pc_ylab) +
  #Add loadings
  geom_text(data=pca_loadings, aes(x=v1, y=v2, label=OTU), 
            size = 5, vjust=1,hjust=1, color="red", check_overlap = TRUE,
            alpha=0.5)+
  geom_segment(data=pca_loadings, aes(x=0, y=0, xend=v1, yend=v2),
               arrow=arrow(length=unit(0.2,"cm")), alpha=0.5, color="red") +
  base_theme+
  theme(legend.position = "bottom") +
coord_fixed(ratio=pc1/pc2) # Scale plot by variance explained

gg.pca

# Plot Loading contribution
tidied_pca <- broom::tidy(pca, matrix="rotation") %>%
  magrittr::set_colnames(c("term", "component", "value"))

library(tidytext)
tidied_pca %>%
  dplyr::filter(component < 5) %>%
  group_by(component) %>%
  #top_n(6, abs(value)) %>%
  ungroup() %>%
  mutate(term = reorder_within(term, abs(value), component)) %>%
  dplyr::mutate(component = factor(paste0("PC",component))) %>%
  ggplot(aes(x=abs(value), y=term, fill = value > 0)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~component, scales = "free", nrow=1) +
  scale_y_reordered() +
    labs(
    x = "Absolute value of contribution",
    y = NULL, 
    fill = "Positive?"
  ) +
  base_theme +
  theme(legend.position = "bottom")

# Scree plot
sdev <- pca$sdev
percent_variation <- sdev^2 / sum(sdev^2)

tibble(
  component = unique(tidied_pca$component),
  percent_var = percent_variation ## use cumsum() to find cumulative, if you prefer
) %>%
  dplyr::filter(component < 11) %>%
  mutate(component = factor(component)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(component, percent_var)) +
  geom_col() +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = NULL, y = "Percent variance explained by each PCA component") +
  base_theme +
  theme(axis.text.x = element_text(angle=0))

```
# Heatmap of jaccard simiarity to show all are detected in all samples??

## Effect of primer on bias

```{r Drosophila bias}
ps_bias <- ps2

exp <- read_csv("sample_data/expected_quant_merged.csv") %>%
  dplyr::rename(sample_name = Sample) %>%
  pivot_longer(-sample_name,
               names_to= "taxon",
               values_to= "expected") %>%
  mutate(taxon = str_replace(taxon, pattern=" ",replacement="_"),
         sample_name = str_remove(sample_name, "-exp*.$")) %>%
  dplyr::filter(!is.na(sample_name),
  !str_detect(sample_name, "CM[0-9]|CT[0-9]|CML[0-9]|Syn"),
  expected > 0) %>%
  distinct()

#plot expected
exp %>% 
  dplyr::filter(str_detect(sample_name, "^D")) %>%
  group_by(sample_name) %>%
  mutate_at(vars(expected), ~ . / sum(.) ) %>% #Convert to proportions
  ggplot(aes(x=sample_name, y=expected, fill=taxon)) +
  geom_col(position="stack") + 
  scale_fill_brewer(palette="Spectral") +
  scale_y_continuous(labels=scales::percent) +
  base_theme+
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle=45, hjust=1)) +
  labs(x = "Sample Name",
       y= "Relative abundance",
       title="Expected mock communities",
       fill="Species")

#Get observed
sam <- speedyseq::psmelt(ps_bias) %>%
  janitor::clean_names() %>%
  mutate(taxon = species) %>%
  filter(!str_detect(genus, "__")) %>%#Remove unclassified
  dplyr::select(sample_name, taxon, abundance, target_subfragment, fcid, material_type = type) %>%
  mutate(sample_name = sample_name %>%
           str_remove_all("BF1-BR1-|SauronS878-HexCOIR4-|fwhF2-HexCOIR4-|fwhF2-fwhR2n-") %>%
           str_remove("HLVKYDMXX_"),
         sample_id = paste0(fcid, "_", sample_name),
         sample_name = sample_name %>%
           str_remove("-ex[0-9]")) 

#Join tables 
joint <- sam %>%
  filter(taxon %in% exp$taxon,
         sample_name %in% exp$sample_name) %>%
  left_join(exp, by = c("sample_name","taxon")) %>%
  dplyr::rename(observed = abundance) %>%
  mutate(expected = replace_na(expected, 0),
         observed0 = (observed + 0.5) * (expected > 0),
         error = observed0 / expected) %>%
  distinct() %>%
  group_by(sample_id) %>%
  mutate_at(vars(observed, expected), ~ . / sum(.) ) %>% #Convert to proportions
  ungroup()


# Visualise the error in all pairwise ratios
gg.ratio <- joint %>%
  dplyr::filter(expected > 0 ) %>%
  dplyr::mutate(Taxon = taxon %>%
                 str_replace("^.+_", paste0(str_extract(taxon, "."), "_"))) %>%
    compute_ratios(group_vars = c("sample_id", "material_type", "target_subfragment")) %>%
  mutate(Pair = paste(Taxon.x, Taxon.y, sep = ":")) %>% 
  ggplot(aes(Pair, expected, colour=sample_id)) +
  geom_hline(yintercept = 1, alpha=0.8) +
  geom_jitter(alpha=0.7) +
  scale_y_log10() +
  base_theme+
  facet_grid(target_subfragment~.)+
    theme(legend.position = "none",
          axis.text.x = element_text(angle=45, hjust=1))+
  labs(y= "Error in taxon ratios (log10)") 

gg.ratio

# Estimate bias on geometrically centred ratios
bias <- joint %>%
  filter(material_type=="DrosMock") %>%
  filter(expected > 0) %>%
  group_by(target_subfragment, material_type)  %>%
    nest() %>%
    mutate(fit = map(data, ~lm(metacal::center_elts(observed0 /expected) ~ 0 + taxon , data = .)), 
           tidied = map(fit, broom::tidy),
           aug = map(fit, broom::augment)
    ) %>%
  dplyr::select(-fit) %>%
  unnest(tidied) %>%
  mutate(taxon = str_remove(term, "taxon")) %>%
   dplyr::select(target_subfragment, material_type, taxon, estimate) 

# See how well bias estiamte fits data
library(plotly)

preds <- joint %>%
  left_join(bias) %>%
  dplyr::mutate(predicted = expected * estimate) %>%
  group_by(sample_id) %>%
  mutate_at(vars(predicted), ~ . / sum(., na.rm=TRUE) ) %>%
  filter(expected > 0) %>%
  filter(observed > 0)


ggplot(preds,  aes(x=logit(predicted), y=logit(observed), color = taxon))+
  geom_abline(intercept = 0, slope = 1, color = "grey") +
    geom_jitter(width = 0.1, height = 0, alpha=0.7) +
  facet_grid(fcid~target_subfragment)+
    labs(x = "log-odds(Predicted proportion)", 
        y = "log-odds(Observed proportion)",
        colour = "Taxon",
        title="Bias model fits") +
  coord_fixed()+
  base_theme +
  theme(
        panel.spacing.x = unit(1, "lines"),
        legend.position = "bottom",
    )

# Plot bias estimates
preds %>%
  distinct() %>%
  ggplot(aes(x=taxon, y=estimate-1, fill=target_subfragment)) +
    geom_col()+
    facet_grid(target_subfragment~material_type) +
  coord_flip() +
  geom_rangeframe() +
  base_theme+
  scale_fill_brewer(palette="Paired") +
  labs(
    x="Taxon",
    y= "Bias / Geometric mean")

```


## Effect of primer on detection probability
How do the primers affect its probability of detection (presence/absence). We used a generalized linear mixed effects model of presence/absense as a function of primer
primer. To account for the paired design (where both types of samples were derived from the samen community), we defined Sample ID as a random effect.
Since the response was binomial, we assumed a logit‐link and binomially distributed error

```{r detection probability}
# Use joint to get a table of expected/absent
det_table <- joint %>% 
  filter(material_type=="DrosMock") %>%
  mutate(detected = case_when(
    expected > 0 & observed > 0 ~ 1,
    expected > 0 & observed == 0 ~ 0,
    TRUE ~ as.numeric(NA)
    )) %>%
  mutate(extract_id = sample_name %>%
           str_remove_all("BF1-BR1-|fwhF2-fwhR2n-|SauronS878-HexCOIR4-|fwhF2-HexCOIR4-"))

# Estimate detection efficiency of all taxa - problem is all are detected and none are failed!
# Need to filter for index switching
# 
library(lme4)
detmodel <- det_table %>%
  filter(fcid=="CB3DR") %>%
  dplyr::select(sample_id, extract_id, taxon, detected, target_subfragment) %>%
  #group_by(taxon) %>%
  nest() %>%
  mutate(fit = map(data, ~glmer(detected ~ target_subfragment + (1|extract_id), family=binomial, data = .)), 
           tidied = map(fit, broom::tidy),
           aug = map(fit, broom::augment)

  ) %>%
  dplyr::select(-fit) %>%
  unnest(tidied) 

# Estimate detection efficiency of targets
library(lme4)
det_suzukii <- ps_qual %>%
  filter(fcid=="CB3DR") %>%
  group_by(Species) %>%
  nest() %>%
  mutate(fit = map(data, ~glmer(detection ~ target_subfragment + (1|extract_id), family=binomial, data = .)), 
           tidied = map(fit, broom::tidy),
           aug = map(fit, broom::augment)

  ) %>%
  dplyr::select(-fit) %>%
  unnest(tidied) 

det_suzukii
```


#FIGURE 1  Comparison of primers for detection, bias, and PCA of overlap  

# Supplementary Comparison of primer replicates for detection and bias

Run 2 - see the differences in bias between replicates

```{R run2}


```

## Run 3

## Alpha diversity metrics

```{r alpha div}
dir.create("output/alpha")
# Get richness measures
richness <- phyloseq::estimate_richness(ps2, measures=c("Chao1", "Shannon", "Simpson")) %>% #
  rownames_to_column("sample_name") %>%
  mutate(sample_name = str_replace(sample_name, "\\.", "-"))


#Set number of randomisations for calculating significance
# Calculate Faith's PD-index & Species richness - with Standard errors
sespd <- picante::ses.pd(as(phyloseq::otu_table(ps2), "matrix"),  phyloseq::phy_tree(ps2), null.model = "taxa.labels", include.root = F, runs = 9)

# Join together
div_table <- sespd %>%
  rownames_to_column("sample_name") %>%
  dplyr::select(sample_name, ntaxa, pd.obs) %>%
  dplyr::rename(pd = pd.obs, alpha = ntaxa) %>%
  left_join(richness, by="sample_name") %>%
  left_join(sample_data(ps2) %>% 
              as("data.frame") %>%
              filter(!duplicated(sample_name)) %>%
              dplyr::select(replicate, sample_name, type),
            by = "sample_name") 

# Summarise means
div_table %>%
  summarise(across(where(is.numeric), mean, na.rm=TRUE))

# Difference in alpha diversity between replicates
#report::report(aov(alpha ~replicate, data=div_table))
#report::report(aov(Shannon ~replicate, data=div_table))
#report::report(aov(pd ~replicate, data=div_table))
#
# Difference in alpha diversity between trap types
report::report(aov(alpha ~type, data=div_table))
report::report(aov(Shannon ~type, data=div_table))
report::report(aov(pd ~type, data=div_table))
```

## Beta diversity metrics

```{r Distances}
ps2_dist <- ps2
# Get OTU tables
otutab <- otu_table(ps2_dist)
#Impute zeroes for compositional distances
otutab_n0 <- as.matrix(zCompositions::cmultRepl(otutab, method="CZM", output="p-counts"))
#Root phylogenetic tree
phy_tree(ps2_dist) <- multi2di(phy_tree(ps2_dist))

#Calculate different distance metrics
metrics <- c("Bray", "Jaccard", "Aitchison", "Philr", "Unifrac", "WUnifrac")
distlist <- vector("list", length=length(metrics))
names(distlist) <- metrics

distlist$Jaccard <- as.matrix(vegdist(otutab, method="jac",binary = T))
distlist$Bray <- as.matrix(vegdist(otutab, method="bray"))
distlist$Aitchison <- as.matrix(vegdist(CoDaSeq::codaSeq.clr(otutab_n0), method="euclidean"))
distlist$Philr <- as.matrix(vegdist(philr::philr(otutab_n0, phy_tree(ps2),
                                                part.weights='enorm.x.gm.counts',
                                                ilr.weights='blw.sqrt'), method="euclidean"))
distlist$Unifrac <- as.matrix(phyloseq::UniFrac(ps2_dist, weighted=FALSE, parallel = TRUE))
distlist$WUnifrac <- as.matrix(phyloseq::UniFrac(ps2_dist, weighted=TRUE, parallel = TRUE))

```

# Adonis and betadisper
```{r betatest}
# Adonis test
metadata <- sample_data(ps2_dist) %>%
  as("data.frame")

# Test difference by community type
adonis_results <- distlist %>%
  purrr::map(function(x) {
    bind_rows(
    broom::tidy(adonis(x~type, method="euclidean", data=metadata)$aov.tab) %>% dplyr::slice(1)
    )
})  %>%
  bind_rows(.id="dist")

# Check homogeneity
betadisper_results <- distlist %>%
  purrr::map(function(x) {
    y <- as.dist(x[metadata$sample_name, metadata$sample_name])
  bind_rows(
    as.data.frame(permutest(vegan::betadisper(y, metadata$type))$tab) %>%
      dplyr::slice(1) %>% 
      mutate(term="type")
  )
})  %>%
  bind_rows(.id="dist")

dir.create("output/beta")
write_csv(adonis_results, "output/beta/adonis.csv")
write_csv(betadisper_results, "output/beta/adonis.csv")
```

# PCA plots

```{r pca plots}
phy_tree(ps2) <- multi2di(phy_tree(ps2))
phy_tree(ps2) <- makeNodeLabel(phy_tree(ps2), method="number", prefix='n')

# Get philr distance
ps2.philr <- philr::philr(otutab_n0, phy_tree(ps2),
                     part.weights='enorm.x.gm.counts', 
                     ilr.weights='blw.sqrt')
#PCA 
pca <- prcomp(ps2.philr)

#Name balances
pcnames <-  sapply(rownames(pca$rotation), function(x) name.balance(phy_tree(ps2), tax_table(ps2), x))
pcnames <- make.unique(pcnames, sep = ".")
rownames(pca$rotation) <- pcnames

# Get pca data
pca_data <- pca$x %>%
  as_tibble(rownames = "sample_name") %>%
  dplyr::select(1:6)%>%
  left_join(sample_data(ps_run1) %>%
              as("data.frame") %>%
    dplyr::select(sample_name, type, target_subfragment) %>%
    distinct()) %>%
  mutate(extract_id = sample_name %>%
           str_remove_all("BF1-BR1-|fwhF2-fwhR2n-|SauronS878-HexCOIR4-|fwhF2-HexCOIR4-"))

#Get PCA loadings
pca_loadings <- data.frame(OTU = rownames(pca$rotation), pca$rotation[, 1:2])
mult <- min(
    (max(pca_data$PC1) - min(pca_data$PC1)/(max(pca_loadings$PC1)-min(pca_loadings$PC1))),
    (max(pca_data$PC2) - min(pca_data$PC2)/(max(pca_loadings$PC2)-min(pca_loadings$PC2)))
    )
pca_loadings <- transform(pca_loadings,
        v1 = .7 * mult * (pca_loadings$PC1),
        v2 = .7 * mult * (pca_loadings$PC1)
        )

# calculate percent variance explained for the axis labels
pc1 <- round(pca$sdev[1]^2/sum(pca$sdev^2),2)
pc2 <- round(pca$sdev[2]^2/sum(pca$sdev^2),2)
pc_ylab <- paste("PC1: ", pc1, sep="")
pc_xlab <- paste("PC2: ", pc2, sep="")

# Plot PCA
gg.pca <- ggplot(data=pca_data, aes(x=PC2, y=PC3)) + 
  geom_point(aes(fill = extract_id),alpha=0.8, size=3,shape=21, colour="black") +
  scale_colour_brewer(palette="Paired") +
  geom_hline(yintercept = 0, linetype=2, alpha=0.5) +  
  geom_vline(xintercept = 0, linetype=2, alpha=0.5) +
  xlab(pc_xlab) + 
  ylab(pc_ylab) +
  #Add loadings
  geom_text(data=pca_loadings, aes(x=v1, y=v2, label=OTU), 
            size = 5, vjust=1,hjust=1, color="red", check_overlap = TRUE,
            alpha=0.5)+
  geom_segment(data=pca_loadings, aes(x=0, y=0, xend=v1, yend=v2),
               arrow=arrow(length=unit(0.2,"cm")), alpha=0.5, color="red") +
  base_theme +
coord_fixed(ratio=pc1/pc2) # Scale plot by variance explained

gg.pca

# Heirarchial clustering
dend <- hclust(vegdist(ps2.philr, method="euclidean"), method="average")

p3 <- ggtree(as.phylo(dend) ) + 
  theme_tree2()

colours_p3 <- p3$data %>%
  left_join(as_data_frame(sample_data(ps2)) %>%
              dplyr::select(sample_name, type) %>%
  dplyr::rename(label = sample_name)
    )

p3 <- p3 %<+% colours_p3  + 
  geom_tippoint(aes(colour=as.factor(type)))  + 
  geom_tiplab(aes(colour=as.factor(type)))+
  scale_colour_brewer(palette="Paired") +
    scale_x_continuous(expand=c(0, 30)) +
  theme(legend.position = "bottom")

# Plot together
p3 + gg.pca

tidied_pca <- broom::tidy(pca, matrix="rotation") %>%
  magrittr::set_colnames(c("term", "component", "value"))

library(tidytext)
tidied_pca %>%
  dplyr::filter(component < 5) %>%
  group_by(component) %>%
  top_n(6, abs(value)) %>%
  ungroup() %>%
  mutate(term = reorder_within(term, abs(value), component)) %>%
  dplyr::mutate(component = factor(paste0("PC",component))) %>%
  ggplot(aes(x=abs(value), y=term, fill = value > 0)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~component, scales = "free") +
  scale_y_reordered() +
    labs(
    x = "Absolute value of contribution",
    y = NULL, 
    fill = "Positive?"
  ) +
  theme_classic() 

# Scree plot
sdev <- pca$sdev
percent_variation <- sdev^2 / sum(sdev^2)

tibble(
  component = unique(tidied_pca$component),
  percent_var = percent_variation ## use cumsum() to find cumulative, if you prefer
) %>%
  dplyr::filter(component < 11) %>%
  mutate(component = factor(component)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(component, percent_var)) +
  geom_col() +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = NULL, y = "Percent variance explained by each PCA component") +
  theme_classic()
```

# Fit GLMnet

from philr tutorial https://bioconductor.org/packages/devel/bioc/vignettes/philr/inst/doc/philr-intro.html
```{r glmnet}
library(glmnet)

# Predict mock vs real
sample_data(ps2)$mock <- factor(get_variable(ps2, "type") %in% c("Mock", "POS"))

glmmod <- glmnet(ps2.philr, sample_data(ps2)$type, alpha=1, family="multinomial")

# Get coords usign tidy insteaed
tidied <- tidy(glmmod) %>% 
  filter(!term == "(Intercept)",
         !term == ""
         )%>%
  mutate(node = name.to.nn(phy_tree(ps2), term))

ggplot(tidied, aes(step, estimate, group = term)) +
  geom_line()

#tc.colors <- c('#a6cee3', '#1f78b4')
p <- ggtree(phy_tree(ps2), layout='fan') +
  geom_balance(node=2843, alpha=0.6) # get node number from the tidied dev.node
p <- annotate_balance(phy_tree(ps2), 'n16', p=p, labels = c('n16+', 'n16-'),
                 offset.text=0.15, bar=FALSE)
annotate_balance(tree, 'n730', p=p, labels = c('n730+', 'n730-'),
                 offset.text=0.15, bar=FALSE)
```


# Phylogeny of trap catches

```{r Phylogeny}

# For presentation
test <- ps2 %>% 
  phyloseq::subset_samples(sample_name == "HLVKYDMXX_T10SPD-ex1") %>%
    #filter_taxa( function(x) mean(x) > 0, TRUE) %>%
  tax_glom("Species")

tree <- phy_tree(test)

ggtree(tree, layout="circular") + coord_polar(theta='y')+ scale_x_reverse(limits=c(4, 0)) + geom_tippoint(color="steelblue", size=2, alpha=.8)

ggtree(tree) + geom_tippoint(color="steelblue", size=2, alpha=.8)


```



## Occupancy modelling

### eDNAoccupancy
```{r edna occupancy}

library(eDNAoccupancy)
data(fungusDetectionData)
data(fungusSurveyData)

# Make detection table
ps_qual <- ps %>%
  speedyseq::tax_glom(taxrank="Species") %>%
  transform_sample_counts(function (x) (x > 0) * 1) %>%
  #merge_samples(group = "ExtractID") %>%
  speedyseq::psmelt() %>%
  select(Sample, Abundance, Species) %>%
  separate(Sample, into=c("site", "rep"), sep="-rep") %>%
  mutate(rep=paste0("pcr",rep)) %>%
  separate(site, into=c("site", "sample"), sep="-ex") %>%
  pivot_wider(names_from=rep, values_from = Abundance, values_fill=list(Abundance = 0)) 

det_suzukii <- ps_qual %>%
  mutate(site = str_replace(site, "DM", "D100M")) %>%
  filter(Species=="Drosophila_suzukii") %>%
  filter(str_detect(site,"D100M|D250M|D500M|D1000M")) %>%
  select(site, sample, pcr1, pcr2, pcr3) %>%
  mutate(sample = as.integer(sample)) %>%
  arrange(sample) %>%
  as.data.frame()

suzukii_detections = occData(det_suzukii, siteColName = 'site',
                            sampleColName = 'sample')

#Make covariate tables

# Read in expected table
exp <- read_csv("sample_data/expected_quant_merged.csv") %>%
  gather(Species, Actual, -X1) %>%
  mutate(Species = str_replace(Species, pattern=" ",replacement="_")) %>%
  filter(str_detect(X1,"D100M|D250M|D500M|D1000M|DLarv")) %>%
  drop_na() %>%
  set_colnames(c("Sample","Species","Actual"))
# Add true presence

#Add community size covariate

commsize <- exp %>%
  group_by(Sample) %>%
  summarise(commsize = sum(Actual)) %>%
  mutate(Sample = str_replace_all(Sample, pattern="(-)(.*?)(?=$)", replacement=""))

survey_data <- samdf %>%
  remove_rownames() %>%
  mutate(Sample = str_replace_all(ExtractID, pattern="(-)(.*?)(?=$)", replacement="")) %>%
  select(Sample, geo_loc_name, material) %>%
  left_join(commsize, by="Sample") %>%
  rename(site = Sample) %>%
  filter(str_detect(site,"D100M|D250M|D500M|D1000M")) %>%
  unique()

# Add alpha diversity covariates

# Try using hill numbers for these https://github.com/anttonalberdi/hilldiv

#estimate richness
alpha_table <- phyloseq::estimate_richness(ps2)

# Calculate Faith's PD-index
pdtable <- picante::pd(as(phyloseq::otu_table(ps2), "matrix"), phyloseq::phy_tree(ps2), include.root = F)




 ## number of detections per sample
 head(suzukii_detections$y)
 ## number of PCR replicates per sample
 head(suzukii_detections$K)

#We fit a multi-scale occupancy model without covariates and print a summary of the parameter estimates using the following code.

 set.seed(69)
 fit = occModel(detectionMats=suzukii_detections, niter=11000,
                niterInterval=5000)
 posteriorSummary(fit, burnin=1000, mcError=TRUE)


## Center and scale numeric-valued covariate measurements
survey_data.sc = scaleData(survey_data)

set.seed(0157)
fit = occModel(formulaSite          = ~ 1,
               formulaSiteAndSample = ~ commsize,
               formulaReplicate     = ~ commsize,
               detectionMats        = suzukii_detections,
               siteData             = survey_data.sc,
               niter                = 6000,
               niterInterval        = 2000,
               siteColName = 'site'
               )
posteriorSummary(fit, burnin=1000, mcError=TRUE)


#If we want to assess whether the Markov chain used to compute these estimates appears to have converged, trace plots of the parameters may be created as follows (Fig.~\ref{fig:TracePlotFungusAnalysis}).
plotTrace(fit, c('beta.(Intercept)', 'alpha.(Intercept)', 'alpha.frogs',
            'delta.(Intercept)'),  burnin=1000)

#Autocorrelation plots of the parameters are created similarly
 plotACF(fit, c('beta.(Intercept)', 'alpha.(Intercept)', 'alpha.frogs',
             'delta.(Intercept)'),  burnin=1000)

#After inspection of these plots, suppose we decide that the MCMC algorithm needs to be run longer, either to eliminate the transient portion of the Markov chain or to reduce Monte Carlo errors in the parameter estimates.  We can resume the MCMC algorithm for the currently fitted model as follows.
 fit = updateOccModel(fit, niter=5000, niterInterval=2000)
 posteriorSummary(fit, burnin=1000,  mcError=TRUE)

 #These estimates of the parameters are computed using the updated Markov chain containing \rinline{fit$niterations} iterations.  The Monte Carlo errors in these parameter estimates are slightly lower, but the estimates are otherwise similar to those computed with only \rinline{fit$niterations-5000} iterations.

#In addition to estimating posterior summaries of the model's formal parameters, we also may be interested in estimating posterior summaries of derived parameters.  For example, in the second model fitted to the \emph{Bd} data, the probability of eDNA occurrence in ponds was assumed to be constant ($\psi$), the conditional probability of eDNA occurrence in samples was assumed to be a function of the frog density index \code{frogs}, and the conditional probability of eDNA detection was assumed to be constant ($p$).  The posterior medians of these derived parameters are estimated as follows.

psi = posteriorSummaryOfSiteOccupancy(fit, burnin=1000)
theta = posteriorSummaryOfSampleOccupancy(fit, burnin=1000)
p = posteriorSummaryOfDetection(fit, burnin=1000)

 ## output estimates of posterior medians
 cbind(psi=psi$median, theta=theta$median[,1], p=p$median[,1])

 frogs = fungusSurveyData[, 'frogs']
 plot(frogs, theta$median[,1], ylim=c(0,1), xlim=c(0,0.8), cex=2)
 segments(frogs, theta$lower[,1], frogs, theta$upper[,1], lwd=2)
 
#One way to assess the relative importance of such estimated relationships is to compare competing models using model-selection criteria.  For example, we compute the PPLC and WAIC criteria for the previously fitted model as follows.
 posteriorPredictiveLoss(fit, burnin=1000)
 WAIC(fit, burnin=1000)

```

###Seak occupancy

Seak occupancy modelling - The model is fitted within a Bayesian framework and any of the model parameters can be functions of covariates. The implemented algorithm performs Bayesian variable selection and the output includes posterior summaries of all parameters as well as posterior probabilities of inclusion (see examples for a more detailed description of how to interpret the output).

The model has been developed for single species qPCR data. The data are the number of positive qPCRs (eDNA score) for each water sample collected at surveyed sites. The model allows us to estimate the probability of species presence at each survey site, while accounting for the probabilities of a false positive and false negative error at stage 1 (field) and stage 2 (lab).



Occupancy modelling calculates the probability of detection from a number of replicates. ie - 6 replicates positive = 100% probaiblity , 5/6 = 85% probability

Nested levels = Replicated extractions, replicated PCRs .

Could fit a single specied


For model taking into accoutn false poositives and negatives: https://seak.shinyapps.io/eDNA/

This requires format

Columns = Sample (extraciton replicate ) so 2 columns
Rows = site (trap)
cell value = number of positive PCR replicates (out of 3)
Column 3 = True presence or absense 1 or 0
column 4,5,6 etc other covariates. Sequencing depth, community size, species richness,trap type, phylogenetic richness... etc



```{r occupancy}
#convert to presence/absense
ps_qual <- ps %>%
  speedyseq::tax_glom(taxrank="Species") %>%
  transform_sample_counts(function (x) (x > 0) * 1) %>%
  merge_samples(group = "Sample_Name") %>%
  speedyseq::psmelt() %>%
  dplyr::select(Sample, Abundance, Species) %>%
  mutate(Sample = str_remove(Sample, "^.*_")) %>%
  separate(Sample, into=c("Sample", "exrep"), sep="-ex") %>%
  pivot_wider(names_from=exrep, values_from = Abundance, values_fill=list(Abundance = 0)) %>%
  dplyr::select(Sample, Species, `1`, `2`,)

# Read in expected table
exp <- read_csv("sample_data/expected_quant_merged.csv") %>%
  gather(Species, Actual, -X1) %>%
  mutate(Species = str_replace(Species, pattern=" ",replacement="_")) %>%
  #filter(str_detect(X1,"D100M|D250M|D500M|D1000M|DLarv")) %>%
  drop_na() %>%
  set_colnames(c("Sample","Species","Actual"))
# Add true presence

true_pres <- exp %>%
  mutate(Sample = str_replace_all(Sample, pattern="(-)(.*?)(?=$)", replacement="")) %>%
  mutate(Actual = case_when(
    Actual > 0 ~ 1,
    Actual == 0 ~ 0
  )) %>%
  unique()
  
#Add community size covariate - need to estimate for others

commsize <- exp %>%
  group_by(Sample) %>%
  summarise(commsize = sum(Actual)) %>%
  mutate(Sample = str_replace_all(Sample, pattern="(-)(.*?)(?=$)", replacement=""))

# add seqdepth covariate

#filterdepth

#richness
richness <- ps_qual %>%
  mutate(Sample = str_replace(Sample, "DM", "D100M")) %>%
  ungroup() %>%
  mutate(total = `1`+`2`) %>%
  filter(total > 0) %>%
  group_by(Sample) %>%
  summarise(richness= n())  

# Species evenness

# Phylogenetic diversity


#trap_type
comm_type <- exp %>%
  mutate(Sample = str_replace_all(Sample, pattern="(-)(.*?)(?=$)", replacement="")) %>%
  mutate(comm_type = case_when(
    str_detect(Sample, "D100M|D250M|D500M|D1000M") ~ "Mock",
    str_detect(Sample, "DLarv") ~ "Larvae",
    str_detect(Sample, "ACV") ~ "ACV",
    str_detect(Sample, "FF") ~ "FF",
    str_detect(Sample, "SPD") ~ "SPD",
    str_detect(Sample, "DC") ~ "DC",
  )) %>%
  dplyr::select(Sample, comm_type) %>%
  unique()
  

# Get suzukii only
det_suzukii <- ps_qual %>%
  mutate(Sample = str_replace(Sample, "DM", "D100M")) %>%
  left_join(true_pres, by=c("Sample", "Species"))%>%
  left_join(commsize, by="Sample") %>%
  left_join(richness, by="Sample") %>%
  left_join(comm_type, by="Sample") %>%
  filter(Species == "Drosophila_suzukii") %>%
  dplyr::select(-Species) %>%
  unique() %>%
  mutate(Actual = replace_na(Actual, 0))  %>%
  filter(!is.na(commsize)) %>%
  mutate(commsize = scale(commsize, center = TRUE, scale = TRUE))  %>%
  #mutate(random = scale(rbinom(nrow(.), 100, 0.7), center = TRUE, scale=TRUE)) %>%
  #mutate(random2 = scale(rbinom(nrow(.), 100, 0.4), center = TRUE, scale=TRUE)) %>%
  mutate(richness = scale(richness, center = TRUE, scale = TRUE))  %>%
  filter(!str_detect(Sample, "DLarv"))# %>%
  #set_rownames(.$Sample) #%>%
  dplyr::select(-Sample)
  
write.csv(det_suzukii, "test_occupancy_suzukii.csv", row.names=FALSE)

```

For sequencing depth covariate could you just rarefy to certain depth, recalculate detection, then rbind a longer table together in a loop
Same with filtering threshold



these could be fit seperately for our 3 target species

Then we can look at how the detection probability changes across different filtering thresholds used to remove index switching?


To test if probability of detection differs as a function of sample water volume, we used the eDNAoccupancy R package (version 0.2.4; Dorazio & Erickson, 2017) to model probabilities of eDNA detection. This package fits Bayesian, multi‐scale occupancy models to our data, which included three, nested levels of sampling: stream location, replicated water samples collected from each stream, and subsamples (i.e., PCR technical replicates) of each water sample. 



https://onlinelibrary.wiley.com/doi/full/10.1002/edn3.23

https://besjournals.onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2011.00156.x

https://www.pnas.org/content/pnas/116/18/8931.full.pdf

Based on the overall model, a total of seven water samples was
required to achieve >95% detection probabilities of S. mansoni
eDNA at water sample level (θ = 0.35) [as calculated by using
the equation P = 1 − (1 − θ)
n (27)]. By using the same approach,
the model-based estimated number of qPCR replicates required
to achieve detection probabilities >95% ranged from three to
nine replicates between sites


## Check for concordance between mock and real


```{r PCA}
# Read in expected table
exp <- read_csv("sample_data/expected_quant_merged.csv") %>%
  gather(Species, Abundance, -X1) %>%
  mutate(Species = str_replace(Species, pattern=" ",replacement="_")) %>%
  filter(str_detect(X1,"D100M|D250M|D500M|D1000M|DLarv")) %>%
  drop_na() %>%
  set_colnames(c("Sample","Species","Actual"))

# Prepare observed table
sam <- ps.merged %>%
  speedyseq::tax_glom("Species") %>%
  transform_sample_counts(function (x) x/sum(x)) %>%
  speedyseq::psmelt() %>%
  mutate(Species = str_replace(Species, pattern="Drosophila_mauritiana/simulans", replacement= "Drosophila_simulans")) %>%
  mutate(Species = str_replace(Species, pattern="Drosophila_albomicans", replacement= "Drosophila_immigrans")) %>%
  filter(Sample %in% exp$Sample) %>%
  arrange(Abundance) %>%
  distinct() %>%
  select(Sample, Species, Abundance)

# Join tables
joint <- sam %>%
  filter(Species %in% exp$Species) %>%
  group_by(Species, Sample) %>% 
  summarise(Abundance = sum(Abundance)) %>%
  ungroup() %>%
  #mutate(Type = ifelse(Sample %in% controls, "Est", "Eval")) %>%
  bind_rows(exp %>%
              mutate(Actual = replace_na(Actual, 0)) %>%
              rename(Abundance = Actual) %>%
              filter(str_detect(Sample, pattern="-ex1"))  %>%
              mutate(Sample = str_replace_all(Sample, pattern="-ex1", replacement="-A")
            
            )) %>%
  group_by(Sample) %>%  
  mutate_at(vars(Abundance), ~ . / sum(.)) %>% # Convert to proportions
  #mutate(Abundance = Abundance + 0.0001) %>% # Add pseudocount
  #mutate(Abundance = clr(Abundance)) %>%
  ungroup()

# PCA
joint_pca <- joint %>%
  pivot_wider(
    names_from = Species, #  Switch this to transpose
    values_from = Abundance,
    values_fill = list(Abundance=0),
  ) %>%
  mutate(Extract = Sample %>% str_replace_all(pattern="(-)(.*?)(?=$)", replacement="")) %>%
  mutate(Mock = Sample %>% 
           str_replace_all(pattern="(-)(.*?)(?=$)", replacement="") %>%
           str_replace_all(pattern="(^)(.*?)(?<=M)", replacement="")) %>%
  nest(data = everything()) %>%
  mutate(pca = map(data, ~ prcomp(.x %>% select(-Sample, -Extract, -Mock), 
                                  center = TRUE, scale = TRUE)),
         pca_aug = map2(pca, data, ~augment(.x, data = .y))) 

joint_pca$pca %>%
  map(~tidy(.x, data = .y, "pcs")) %>%
  as.data.frame() %>%
  ggplot(aes(x = PC, y=percent)) +
  geom_bar(stat="identity") + labs(x="PC",y="Variance Explained")


library(RColorBrewer)
col <- colorRampPalette(brewer.pal(11, "Spectral"))(25)

joint_pca %>%
  mutate(
    pca_graph = map2(
      .x = pca,
      .y = data,
      ~ autoplot(.x, loadings = TRUE, loadings.label = TRUE,
                 loadings.label.repel = FALSE,
                 data = .y, label = TRUE,
                 label.label = "Sample",
                 label.repel = TRUE, 
                 colour='Extract') +
       #theme_bw() +
        labs(x = "Principal Component 1",
             y = "Principal Component 2",
             title = "First two principal components of PCA for expected and observed") +
        coord_fixed()#+
       # scale_colour_manual(values=col)
    )
  ) %>%
  pull(pca_graph)


## Heirarchial clustering


# Output drosophila summary
ps.merged %>% 
  subset_taxa(Family=="Drosophilidae") %>%
  microbiome::transform("compositional") %>%
  summarise_taxa("Species", "sample_id") %>%
  filter(!str_detect(sample_id, "NTC")) %>%
  #filter(str_detect(Species, "Drosophila|Scaptodrosophila")) %>%
  spread(key="sample_id", value="totalRA") %>%
  write.csv(file = "output/csv/unfiltered/drosophila_spp_sum.csv")

```


# Reproducability Receipt

```{details, echo = FALSE, details.summary = 'Reproducability receipt'}
# datetime
Sys.time()
#repository
git2r::repository()
sessioninfo::session_info()
```

