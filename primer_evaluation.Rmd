---
title: "primer_evaluation"
author: "Alexander Piper"
date: "09/08/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Introduction


## Load packages
```{r setup}
## Load Necessary packages
sapply(c("rentrez", "bold", "taxize","usethis", "tidyverse", "spider", "insect", "ape", "DECIPHER", "ggpubr", "RColorBrewer", "plotly", "ggforce", "seqinr", "shortread", "patchwork", "viridis","ggridges","UpSetR"), require, character.only = TRUE)


# install.packages("devtools")
#devtools::install_github("alexpiper/taxreturn")
library(taxreturn)

## Get an NCBI api key for taxize queries
# use_entrez()

# After generating your key set it as ENTREZ_KEY in .Renviron.
# ENTREZ_KEY='1c0a0c4afa28448650a1450662a22c68f208'
#usethis::edit_r_environ()
```

# Assemble pest list

* EPPO global database https://gd.eppo.int/ - DONE
* US APHIS - https://www.aphis.usda.gov/aphis/home/ - DONE
* QBank - https://qbank.eppo.int/arthropods/organisms - DONE
* Global invasive species database - http://www.iucngisd.org/gisd/search.php - DONE
* Global register of introduced or invasive species http://www.griis.org/ - DONE
* VectorBase: https://www.vectorbase.org/organisms - DONE
* DAWR top 40 - http://www.agriculture.gov.au/pests-diseases-weeds/plant - DONE
* PHA National biosecurity status report -  http://www.planthealthaustralia.com.au/national-programs/national-plant-biosecurity-status-report/ - DONE
* Ashfaq & Herbert 2016 - DNA barcodes for bio-surveillance: regulated and economically important arthropod plant pests - DONE
* CABI - https://t.co/LGjlFoOazd - DONE
* http://www.europe-aliens.org - DONE

```{r Curate pest lists}
dat <- list.files("primer_evaluation/pestlist/", pattern = ".csv", full.names = TRUE) %>%
  purrr::set_names() %>%
  map_dfr(read_csv, .id = "Source") %>%
  mutate(source = source %>%
           str_split_fixed(pattern="export_", n=2) %>%
           as.data.frame() %>%
           pull(V2) %>%
           str_replace(pattern=".csv", replacement = "")) %>%
  mutate(Species = Species %>%  #Resolve weird characters
           str_replace_all("Ã¿", "") %>%
           iconv(from = 'UTF-8', to = 'ASCII//TRANSLIT')%>% 
           str_replace_all("\\?", ""))

#Resolve taxonomic names 

library(taxreturn)
dat_resolved <- dat %>% 
  mutate(Species = resolve_taxonomy(dat$Species, subspecies=FALSE, quiet=FALSE, missing="ignore", higherrank=FALSE, fuzzy=TRUE)) %>%
  mutate(Species = trimws(Species, which="both")) %>%
  filter(str_detect(Species, " ")) # remove genus level only

backup <- dat_resolved

# Get higher taxonomic levels

#Query NCBI taxonomy database locally using taxizedb 
ncbi_search <- taxizedb::classification(unique(dat_resolved$Species), db='ncbi')

#Query GBIF using online search for those not in NCBI taxonomy
ncbi_failed <- names(ncbi_search)[which(is.na(ncbi_search))]
length(ncbi_failed)
gbif_search <- taxize::classification(ncbi_failed, db="gbif", ask=FALSE, verbose = FALSE)

#Merge all taxonomies and remove NA's
taxranks <- c(ncbi_search, gbif_search)
taxranks <- taxranks[which(!is.na(taxranks))]


lineage <- map(taxranks, mutate_all, as.character) %>%
  bind_rows( .id="Species") %>%
  filter(rank %in% c("class","order","family","genus")) %>%
  select(-id) %>%
  group_by(Species) %>%
  pivot_wider(names_from = rank, values_from=name) %>%
  rename_all(funs(str_to_sentence(.))) %>% 
  ungroup() %>%
  right_join(dat, by="Species") %>%
  filter(Class=="Insecta") %>%
  drop_na()

#Write out final list of pests 
write_csv(lineage, "primer_evaluation/pestlist.csv")

```

## Figure 1 - Summary of pestlist

```{r Figure 1}

lineage <- read_csv("primer_evaluation/pestlist.csv") 

# Fig 1a - Upset plot of species share between the different databases

sources <- as.character(unique(lineage$Source))
upsetlist <- list()
for (i in 1:length(sources)){
  upsetlist[[i]]= lineage$Species[which(lineage$Source==sources[i])] 
  names(upsetlist)[[i]] <- sources[i]
}

Fig1a <- upset(fromList(upsetlist),nsets=length(upsetlist), order.by = "freq")
print(Fig1a)

## Figure 1b - summary of families within the dataset 

library(RColorBrewer)
col <- colorRampPalette(brewer.pal(11, "Spectral"))(10)

Fig1b <- group_by(lineage, Order, Source) %>%
  summarise(Genus = n_distinct(Genus), Species = n_distinct(Species)) %>%
  ungroup() %>%
  mutate(Order = fct_reorder(Order, -Species)) %>% 
  ggplot(aes(x = Order, y = Species, fill = Source)) +
  geom_bar(stat = "identity")  +
  theme_pubr() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1,vjust=0)) +
  scale_fill_manual(values=col) +
  ylim(-500,2500) +
  theme_minimal() +
  theme(
    axis.text = element_blank(),
    axis.title = element_blank(),
    panel.grid = element_blank(),
    plot.margin = unit(rep(-1,4), "cm")      # Adjust the margin to make in sort labels are not truncated!
  ) +
  coord_polar(start=0) +
  geom_text(data = . %>%
              dplyr::select(Order, Species) %>%
              group_by(Order) %>%
              summarise(value = sum(Species)),
            aes(x=Order, y=value + 20, label=Order),
            color="black", fontface="bold", alpha=0.6, inherit.aes = FALSE)

```

## Figure 2a - COI Entropy

### Output pest families

Add Ns to alignment so they all match total length

```{r Subset to pests}
pestlist <- read_csv("primer_evaluation/pestlist.csv") %>%
  pull(Family) %>%
  unique()
seqs <- readFASTA("reference/merged_final.fa.gz")

dir.create("primer_evaluation/pestfamilies/")

pass <- data.frame(name=pestlist, pre=0, post=0, size=0)

for (i in 1:length(pestlist)){
  query <- pestlist[i]
  names <- names(seqs)  %>% 
    str_split_fixed(";", n = 8) %>% 
    as_tibble() %>% 
    filter(V6 == query) %>%
    unite(names,paste0("V",1:8),sep=";")
          
  subset <- seqs[names(seqs) %in% names$names]
  if (length(subset) > 0){
    #Get highest occuring length
    size <- as.data.frame(table(lengths(subset))) %>%
    arrange(desc(Freq))%>%
    slice(1) %>%
    pull(Var1) %>%
    as.character()
  
    lengthfilt <- subset[lengths(subset)==size]
    pass$pre[i] <- length(subset)
    pass$post[i] <- length(lengthfilt)
    pass$size[i] <- size
    print(paste0(length(lengthfilt), " sequences of ",size ," bp kept from ", length(subset), " total for ", pestlist[i]))
    
    ##Remove high-distance outliers - only for those where there are at least 10 species
    sppnames <- names(lengthfilt) %>% str_split_fixed(";", n = Inf) %>% as_tibble() %>%
      pull(paste0("V",(ncol(.) -1)))

    if (length(sppnames) > 10){ 
    dist <- DistanceMatrix(lengthfilt %>% as.character %>% lapply(.,paste0,collapse="") %>% unlist %>% DNAStringSet, verbose=FALSE)
    #Define outliers as 1.5* the dist from the 3rd quartile
    rem <- colnames(dist)[which(dist[,1] > (summary(dist[,1])[["3rd Qu."]] * 1.5))]
    
    lengthfilt <- lengthfilt[!names(lengthfilt) %in% rem]
    }
    if (length(lengthfilt) > 0){insect::writeFASTA(lengthfilt,file=paste0("primer_evaluation/pestfamilies/", pestlist[i],".fa.gz"), compress=TRUE)}
  }
}

## Might need to remove those with too low sequences to run the sliding window script. Need to also check the amount of pass vs fails, maybe do a plot?
##Plot pass vs fails

gg.pass <- pass %>%
  gather(type,value, -name, -size) %>%
  #arrange(desc(value)) %>%
  mutate(name = fct_reorder(name, -value))%>%
  ggplot(aes(x=name,y=value,fill=type))+
  geom_bar(stat="identity", position="dodge") +
  theme(axis.text.x = element_text(angle=90))

```

## Sliding window analysis


Could we do sliding window with a clustered database? use kmer package to cluster? - then select the longest sequence

Or is it worth doing a coarse entropy

```{bash slurmjobscript }
echo "Create individual R files for each fasta, and Sbatch job files"
loc=$(pwd)
TMPDIR=\$TMPDIR
host=\hostname
mkdir $loc/output/
  
  ls pestfamilies | sed -e '1p' -e '/.fa.gz/!d' | sort > test_ls_2
declare -i files
let files=$(grep -c ".fa.gz" test_ls_2)
echo "#qsub file to run all slurm files" > queue_all_jobs
###Make the header for the qsub files
echo "#!/bin/bash
#SBATCH --job-name r_slidingwin
#SBATCH --nodes=1
#SBATCH --ntasks=4
#SBATCH --mem=120GB 
#SBATCH --time=96:00:00
echo '$host'
echo $TMPDIR
cd $TMPDIR
mkdir job_dir
cd job_dir" > script_header
###Set variables & start while loop
declare -i x
x=1
##Start while loop
while [ $x -le $files ] 
do
##Make individual R script files	
read_file=$(sed -n "${x}p" test_ls_2)
sample=$(echo $read_file | awk -F . '{print $1}' )
echo "file = '$read_file'" > R_header
cat R_header base_sw.R > sw$sample.R
##Create Job submission files
echo "cp $loc/pests/$read_file .
	cp $loc/sw$sample.R .
#Load modules and run R scripts
module load R
Rscript sw$sample.R
 
cp *.rds $loc/output/. " > temp_slurm_file
###assembling components into queue all jobs file
cat script_header temp_slurm_file > QA_swscript_$sample.slurm
echo "sbatch QA_swscript_$sample.slurm" >> queue_all_jobs
echo "rm QA_swscript_$sample.slurm" >> queue_all_jobs
let x=x+1
done
#Cleanup
rm script_header
rm temp_slurm_file
rm test_ls_2
rm R_header
echo "Queue files made. Please run queue_all_jobs script"
```

###  R Sliding window 
```{r}
library("spider")
library("ape")
library("DECIPHER")
library("Biostrings")
library("tidyverse")
library("insect")
#files <- list.files(path="reference/pests/",pattern=".fa.gz",full.names = TRUE)
#file <- files[3]
name <- basename(file) %>%
  str_replace(".fa.gz","")
message(name)
seqs <- readFASTA(file)
seqs <- as.matrix(seqs)
# Genus and species names
aa <- Biostrings::strsplit(dimnames(seqs)[[1]], split = ";")
Genus <- sapply(aa, function(x) paste(x[7], sep = "_"))
Spp <- sapply(aa, function(x) paste(x[8], sep = "_")) %>%
  str_replace(pattern="\\ ", replacement="_")
slidelist <- list()
# summary statistics
sum <- as.data.frame(as.matrix(dataStat(Spp, Genus)))
rows <- rownames(sum)
sum <- rbind(sum, nrow(seqs))
rownames(sum) <- c(rows, "seqs")
colnames(sum) <- name
slidelist[[1]] <- sum
####################### Sliding window analyses to identify a mini-barcode region #######################
slidelist[[2]] <- slideAnalyses(seqs, Spp, width = 220, interval = 1, distMeasures = TRUE, treeMeasures = TRUE)
slidelist[[3]] <- slideAnalyses(seqs, Spp, width = 420, interval = 1, distMeasures = TRUE, treeMeasures = TRUE)
## Find conserved primer sites Using windows of 20, 25 and 30bp in length
slidelist[[5]] <- slideAnalyses(seqs, Spp, width = 21, interval = 1, distMeasures = TRUE, treeMeasures = TRUE)
saveRDS(slidelist, file = paste0(name, "_windowlist.rds"))
```

### Sliding window analysis

```{r Figure 1}
path <- "primer_evaluation/sliding_window/" # CHANGE ME to the directory containing all downloaded bold CSV files
vec <- sort(list.files(path, pattern = ".rds", full.names = TRUE)) # Read fasta filenames
length(vec)
rank220 <- vector("list",length=length(vec))
l <- 1
for (l in 1:length(vec)) {
  dat <- readRDS(vec[l])
  rank220[[l]] <- rankSlidWin(dat[[2]], criteria = "mean_distance", num = 100) %>%
    mutate(Family = basename(vec[l]) %>%
    str_replace("_windowlist.rds","")
           ) %>%
    remove_rownames() %>%
    #rownames_to_column("rank") %>%
    mutate(rank= nrow(.):1)
}

sw220 <- bind_rows(rank220) %>%
  mutate(winend = position + 220) %>%
  subset(select=c("Family","position","winend", "rank")) %>%
  rename(pos = position)

```



Is there anyway to do an entropy measurement, or consensus alignment or something across the entire family list to remove the problem of having different length sequences

## Get sequence entropy for orders

Here, information content is defined by the relative entropy of a column in the alignment (Yu et al., 2015), which is higher for conserved columns. The relative entropy is based on the background distribution of letter-frequencies in the alignment.

```{r entropy}
path <- "primer_evaluation/pestfamilies/"
vec <- sort(list.files(path, pattern = ".fa.gz", full.names = TRUE)) # Read fasta filenames
length(vec)

names <- vec %>%
  str_replace(".fa.gz","") %>%
  str_replace(".fa","") %>%
  str_split_fixed("/", n = 3) %>%
  as_tibble() %>%
  pull(V3)

i=1
dat <- vector("list",length=length(vec))

for (i in 1:length(vec)) {
  file <- vec[i]
  seqs <- readDNAStringSet(file)
  #frame <- median(taxreturn::get_reading_frame(seqs))
  #seqs <- Biostrings::translate(seqs, genetic.code =getGeneticCode("SGC4"), no.init.codon=TRUE )
  
  #if(max(width(seqs)) == 658){
  values <- as_tibble(cbind(names[i], MaskAlignment(seqs, type="values",windowSize=1))) %>%
    rename(Family = `names[i]`) %>%
    mutate(Family = as.character(Family)) %>%
    mutate(pos = rownames(.))
  dat[[i]] <- values
 # }
}

#Reorder by taxonomic order - collapse rare orders
pestlist <- read_csv("primer_evaluation/pestlist.csv") %>%
  select(Order, Family) %>%
  unique() 

#Set moving average function - Adjust smoothing (n=5?)
ma <- function(x,n=3){stats::filter(x,rep(1/n,n), sides=2)}


# need to adjust for aligment start length!
# MAke consensus sequence for each pest family and align to a reference coi (used for model)
# get ranges on left of model, put in a data frame
# left_join to ent, group by family, and add the buffer, then ungroup

ent <- bind_rows(dat) %>%
  dplyr::select(Family, entropy, pos) %>%
  mutate(pos = as.numeric(pos)) %>%
  filter(pos > 2) %>%
  mutate(ma = as.numeric(ma(entropy, n = 3)) %>%
          replace_na(0))  %>%
  mutate(annot = case_when(
    pos %in% seq(from=1, to=2, by=1) ~ "Loop 0",
    pos %in% seq(from=3, to=78, by=1) ~ "Helix 1",
    pos %in% seq(from=79, to=103, by=1)~ "Loop 1-2",
    pos %in% seq(from=104, to=211, by=1)~ "Helix 2",    
    pos %in% seq(from=212, to=235, by=1)~ "Loop 2-3",   
    pos %in% seq(from=213, to=304, by=1)~ "Helix 3", 
    pos %in% seq(from=305, to=373, by=1)~ "Loop 3-4", 
    pos %in% seq(from=374, to=466, by=1)~ "Helix 4", 
    pos %in% seq(from=467, to=499, by=1)~ "Loop 4-5", 
    pos %in% seq(from=500, to=598, by=1)~ "Helix 5", 
    pos %in% seq(from=599, to=634, by=1)~ "Loop 5-6", 
    pos %in% seq(from=635, to=658, by=1)~ "Helix 6", 
  )) %>%
  mutate(structure = case_when(
    str_detect(annot, "Helix") ~ "Helix",
    str_detect(annot, "Loop") ~ "Loop",
  )) %>%
  left_join(pestlist, by="Family") %>%
  left_join(sw220, by=c("Family", "pos")) %>%
  arrange(Family) 
```

## Get primer binding sites

```{r get primer binding sites}
#alignment was then manually curated in geneious primer
folmer_curated <-  ape::read.dna("reference/Folmer_insecta_fullength_withprime_curated.fa",format="fasta")
model <- aphid::derivePHMM(folmer_curated)


# Be worth validating how the score is calculated?
primers <- read_csv("primer_evaluation/primer_candidates.csv") %>%
  select(name, strand, seq, citation, issues) %>%
  left_join(.$seq %>% purrr::map(get_binding_position, model, tryrc = TRUE, minscore=8) %>%
  bind_rows() %>%
  rename(seq = primer), by="seq") %>%
  unique()

write_csv(primers, "primer_evaluation/primer_candidates.csv")

```


## Plotting Figure 2b

```{r Figure 2}
# Get primers
Fprimers <- read_csv("primer_evaluation/primer_candidates.csv") %>%
  filter(!str_detect(Name,"AgPest")) %>% 
  select(F.Start, F.Stop, F.Name) %>%
  unique() %>%
  mutate(Dir="Forward") %>%
  rename(Start = F.Start) %>%
  rename(Stop = F.Stop) %>%
  rename(Name = F.Name)

Rprimers <- read_csv("primer_evaluation/primer_candidates.csv") %>%
  filter(!str_detect(Name,"AgPest")) %>% 
  select(R.Start, R.Stop, R.Name) %>%
  unique() %>%
  mutate(Dir="Reverse") %>%
  rename(Start = R.Start) %>%
  rename(Stop = R.Stop) %>%
  rename(Name = R.Name)

primers <- bind_rows(Fprimers,Rprimers)

Fprimerpos <- seq(1,nrow(primers %>% filter(Dir=="Forward")),1)/1000
Rprimerpos <- seq(1,nrow(primers %>% filter(Dir=="Reverse")),1)/1000

# Test boxplot
library(ggthemes)
gg.box <- ggplot(ent %>% group_by(pos) %>% mutate(median = median(ma)), aes(x = pos, y=ma, group=pos, colour=structure)) + 
  geom_boxplot(outlier.shape = NA, alpha=0.8)+
  geom_line(aes(x = pos, y=median), colour="black",size=1, inherit.aes = FALSE) +
  #?geom_tufteboxplot(median.type = "point", whisker.type = "line", hoffset = 0) +
  theme_classic() +    
  theme(legend.position = "bottom") +
  ylab("Entropy") +
  xlab("Position within COI folmer region") +
  scale_color_manual(values=c("#ca0020", "#0571b0")) +
  scale_x_continuous(limits = c(min(primers$Start), max(primers$Stop)),breaks=seq(0,600,50),expand=c(0,0))  #+
 #geom_point(data=ent[ent$pos==1,], aes(x=jitter(position,factor=5), y=Order), size = 1,color="white",alpha=0.5)

## Primer & SW density plot
gg.primers <- ggplot(data=ent[ent$pos==1,], aes(x = as.numeric(pos))) +
  geom_segment(data = primers %>% filter(Dir=="Forward"),
               aes(x = Start, xend = Stop,
                   y = Fprimerpos, yend = Fprimerpos,
                   colour=Dir), size = 1, arrow = arrow(length = unit(0.3,"cm")),
               show.legend = FALSE) +
  geom_text(data = primers %>% filter(Dir=="Forward"),
            aes(x = Start, y = Fprimerpos,
                label = Name , colour=Dir),
            hjust = 1, show.legend = FALSE) +
  geom_segment(data = primers %>% filter(Dir=="Reverse"),
               aes(x = Stop, xend = Start,
                   y = Rprimerpos, yend = Rprimerpos,
                   colour=Dir), size = 1,
               arrow = arrow(length = unit(0.3,"cm")),
               show.legend = FALSE) +
  geom_text(data = primers %>% filter(Dir=="Reverse"),
            aes(x = Stop, y = Rprimerpos,
                label = Name, colour=Dir),
            hjust = 0, show.legend = FALSE) +
  scale_x_continuous(limits = c(min(primers$Start), max(primers$Stop)),breaks=seq(0,600,50),expand=c(0,0))  +
  #scale_y_continuous(trans = "reverse") +
  theme_classic()  +
  theme(legend.position = "none",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())

## GGDensity


gg.density <-  ent %>%
 mutate(rank= case_when(
   rank > 0 ~ as.numeric(rank),
   is.na(rank) ~ 0,
   )) %>%
  group_by(pos, Order) %>%
  summarise(rank =  sum(rank)) %>%
  left_join(
    ent %>%
    mutate(rank= as.numeric(rank)) %>%
    filter(!is.na(rank)) %>%
    group_by(Order) %>%
    summarise(total =  n())
  ) %>%
  mutate(rank = rank / total ) %>%
  mutate(Order = case_when(
    Order %in% c("Coleoptera", "Diptera", "Hemiptera", "Hymenoptera", "Lepidoptera") ~ Order,
    !Order %in% c("Coleoptera", "Diptera", "Hemiptera", "Hymenoptera", "Lepidoptera") ~ "Other"
    )) %>%
  ggplot(aes(x =pos, y=1)) +
    geom_tile(aes(fill=rank*100))+ 
    scale_fill_viridis_c(option="plasma") + 
  facet_wrap(~Order, ncol=1, strip.position ="right")+
  scale_x_continuous(limits = c(min(primers$Start), max(primers$Stop)),breaks=seq(0,600,50),expand=c(0,0))  +
  theme_void() +
  theme(legend.position = "bottom",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank())
  
Fig2 <- gg.box / gg.density / gg.primers #+ plot_layout(heights=c(2,4, 1))
```


# Figure 2b - identificaiton sucess

In order to evaluate the taxonomic resolution of different barcode regions, alignments were trimmed to primer regions using the in silico PCR function from the insect package and  the identificaiton sucess functions from the SPIDER r package were used


Modified from SPIDER package tutorial http://spider.r-forge.r-project.org/tutorial/tutorial.pdf and Elodie Modave, Anna J MacDonald, Stephen D Sarre; A single mini-barcode test to screen for Australian mammalian predators from environmental samples, GigaScience, Volume 6, Issue 8, 1 August 2017, gix052, https://doi.org/10.1093/gigascience/gix052


Pairwise genetic distance was calculated for each pair of sequences using the ârawâ model. We conducted bioinformatic analyses using the nearNeighbour, BestCloseMatch, and ThreshID functions to identify the taxa most likely to be misidentified or ambiguously identified using our primers

The nearNeighbour function determines, for each sequence in the reference database, whether the most closely related sequence originates from a conspecific, with 2 outcomes possible: âtrueâ or âfalse.â This has problems with singletons however, as the nearest neighbour will always be another species,

BestCloseMatch and ThreshID functions use a genetic distance threshold to account for intra-specific variation. We estimated the most appropriate genetic thresholds to use for the âUNIQUEâ and âFULLâ databases to be 3.5% and 1%, respectively, based on the thresholds with the lowest cumulative error. The BestCloseMatch analysis identified the most closely related sequence, within the specified genetic distance threshold, and its species of origin for each query sequence. The ThreshID analysis extended this to consider species of origin for all sequences within the genetic distance threshold. These analyses had 4 possible outcomes: âcorrect,â âincorrect,â âambiguous,â and âno identificationâ [47]. The âFULLâ database was also analysed, with a 3.5% genetic threshold to allow for comparison with the results of the âUNIQUEâ database


```{r identification sucess}
primers <- read_csv("primer_evaluation/primer_candidates.csv")
Alignments <- sort(list.files("primer_evaluation/pestfamilies/", pattern = ".fa.gz", full.names = TRUE)) # Read fasta filenames

names <- basename(Alignments) %>%
  str_replace(".fa.gz","")

# Filter to only those within alignment size & HiSeq sized
dat.passed <- primers %>%
  filter(F.Start > 0 & R.Stop < 661) %>%
  filter(amplicon < 240) %>% 
  mutate(F.seq = str_replace_all(F.seq, "I","N"))%>% #Replace Inosines with N
  mutate(R.seq = str_replace_all(R.seq, "I","N"))

p <- 1
i <- 1
dat <- vector("list", length=nrow(dat.passed))
prime <- vector("list", length=nrow(dat.passed))
dir.create("primer_evaluation/amplicons")


for (i in 1:length(Alignments)) {
  
  name <- names[i]
  seqs <- readFASTA(Alignments[i])
  for (p in 1:nrow(dat.passed)) {
    
    amplicon <- virtualPCR(seqs, up = dat.passed$F.seq[p], dat.passed$R.seq[p], rcdown = TRUE, trimprimers = TRUE, quiet = TRUE)
    if (length(amplicon) > 3) {
      
      #Filter to median - Some amplicons have primer slippage?
      seqLength <- sapply(amplicon, length)
      
      # Get most frequent value
      uniqx <- unique(na.omit(seqLength))
      if (length(uniqx) > 1 ) {message(dat.passed$F.Name[p]," and ",  dat.passed$R.Name[p], " have primer slippage for ", name)}
      freqlen <- uniqx[which.max(tabulate(match(seqLength, uniqx)))]
      
      amplicon <- as.matrix(amplicon[which(seqLength == freqlen)])
      
      # Genus and species names
      aa <- Biostrings::strsplit(dimnames(amplicon)[[1]], split = ";")
      Genus <- sapply(aa, function(x) paste(x[7], sep = "_"))
      Spp <- sapply(aa, function(x) paste(x[8], sep = "_"))
      
      Dist <- dist.dna(amplicon, pairwise.deletion = TRUE)
      
      if (any(Dist > 0)){
        closematch <- tibble(
          query = labels(amplicon),
          Spp = Spp,
          result = bestCloseMatch(Dist, Spp))  %>% 
          left_join(enframe(bestCloseMatch(Dist, Spp, names = TRUE)) %>%
                    set_colnames(c("query", "names"))%>% 
                    mutate(names = map(names, ~set_names(., paste0("closematch_",seq_along(.))))) ,
                    by="query") %>%
          unnest_wider(col=names)
        
        if (length(unique(Spp)) > 3) {
          Tr <- nj(Dist)
          maxInt <- max(Tr$edge.length[Tr$edge[, 2] > length(Tr$tip.label)])
          nodeRoot <- Tr$edge[which(Tr$edge.length == maxInt), 2]
          TrRoot <- root(Tr, node = nodeRoot, resolve.root = TRUE)
          TrRoot$tip.label <- Spp
          mono <- monophyly(TrRoot, Spp, singletonsMono = TRUE)
          
          prime[[p]] <-  tibble(
            primer = dat.passed$Name[p],
            Spp = Spp,
            query = dimnames(amplicon)[[1]],
            nn = nearNeighbour(Dist, Spp),
            nn_spp = nearNeighbour(Dist, Spp, names = TRUE),
            mono=mono[match(Spp, unique(Spp))]
          ) %>%
            left_join(closematch, by=c("query", "Spp"))
          
        } else if (length(unique(Spp)) <3) {
           prime[[p]] <- tibble(
            primer = dat.passed$Name[p],
            Spp = Spp,
            query = dimnames(amplicon)[[1]],
            nn = nearNeighbour(Dist, Spp),
            nn_spp = nearNeighbour(Dist, Spp, names = TRUE)
          ) %>%
            left_join(closematch, by=c("query", "Spp"))
        } 
      } 
    } else next()
  }
  out <- bind_rows(prime)
  write_csv(out, paste0("primer_evaluation/amplicons/",name,".csv"))
  
  dat[[i]] <- out
}
# Some sequences are lost with the in silico PCR, will need to put another column for unsucessfully amplified
```

## Plotting figure 2b

```{r }
#Read back in data:
vec <- sort(list.files("primer_evaluation/amplicons/", pattern = ".csv", full.names = TRUE)) # Read fasta filenames


id_summary <- vec %>%
  purrr::set_names() %>%
  purrr::map_dfr(read_csv, .id = "Source")
  
pestlist <- read_csv("primer_evaluation/pestlist.csv") %>%
  mutate(Species = str_replace_all(Species, " ", "_"))

#summarise for all taxa 

# Could probably left_join to the lineage data, and then summarise by genus/ family etc
all_sum <- id_summary %>%
  dplyr::group_by(primer) %>%
  dplyr::summarise(amplified=n(), 
                   nn_true = sum(nn==TRUE),
                   nn_false = sum(nn==FALSE),
                   cm_ambiguous=sum(result=="ambiguous"),
                   cm_incorrect=sum(result=="incorrect"),
                   cm_correct=sum(result=="correct"),      
                   cm_noid=sum(result=="no id"),
                   mono_true=sum(mono==TRUE),
                   mono_false=sum(mono==FALSE))%>% 
  gather(key="measure", value="value", -primer) %>%
  mutate(dataset="all")



pest_sum <- id_summary %>%
  filter(Spp %in% str_replace_all(read_csv("primer_evaluation/pestlist.csv")$Species, " ", "_")) %>%
  rename(Species = Spp) %>%
  left_join(read_csv("primer_evaluation/pestlist.csv") %>%
              dplyr::select(-Source) %>%
              mutate(Species = str_replace_all(Species, " ", "_")),
            by="Species") #%>%
  group_by(Class, Order, Family, Genus, primer) %>%
  dplyr::summarise(amplified = n(),
                   nn = sum(nn==TRUE),
                   mono = sum(mono==TRUE),
                   cm = sum(result=="correct") + sum(result=="no id")) %>%
  dplyr::mutate(
    nn = nn / amplified,
    mono = mono / amplified,
    cm = cm / amplified
  ) #%>%
  select(-amplified) %>%
  ungroup() %>%
  pivot_longer(cols=nn:cm,
               names_to="measure",
               values_to="value")
  
  
#Get taxonomic lineage and convert to tree

library(ggtree)

test <- as_tibble(tree) %>%
  full_join(pest_sum  %>%
    rename(label = Genus)) 

p <- ggtree(tidytree::as.treedata(test)) +
  geom_nodelab(geom='label') + # + geom_tiplab(align=TRUE) 
  theme_tree2() #+
  scale_colour_gradient(low = "darkgreen", high = "red",  oob = scales::squish) + 
  theme(legend.position = "none") +
      scale_y_continuous(expand=c(0,0))
  

  
  
gg.ident <- pest_sum %>%
  left_join(p$data %>%
  filter(isTip) %>%
    select(c(label, y)) %>%
    rename(Genus = label)) %>%
  filter(!is.na(y)) %>%
  ggplot(aes(x = primer , y = factor(.$Genus, levels=unique(.$Genus[order(.$y)])) , fill = value)) +
  geom_tile() +
  #scale_fill_viridis_c(option="magma",limits = c(0, 200))+
  scale_fill_gradient(low = "red", high = "darkgreen", na.value = "grey", limits = c(0, 1), oob = scales::squish) +
  facet_grid(~measure) +
  theme_classic() + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.y = element_blank(),
    strip.text.y = element_text(angle = 0)
  ) 

p + gg.ident  
  

#Join datasets

p1 <- ggplot(all_sum[which(all_sum$measure == "cm_ambiguous" | all_sum$measure == "cm_correct" | all_sum$measure == "cm_incorrect" |  all_sum$measure == "cm_noid" ),])+
  geom_bar(aes(x=primer,y=value,fill=measure),stat="identity", position="stack") +
  facet_wrap(~dataset,scales="free_y")+ 
  theme(axis.text.x = element_text(angle=90,hjust=1,vjust=0.5))+
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank())

p2 <- ggplot(all_sum[which(all_sum$measure == "mono_true" | all_sum$measure == "mono_false"),])+
  geom_bar(aes(x=primer,y=value,fill=measure),stat="identity", position="stack") +
  facet_wrap(~dataset,scales="free_y") + 
  theme(axis.text.x = element_text(angle=90,hjust=1,vjust=0.5))+
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank())

p3 <- ggplot(all_sum[which(all_sum$measure == "nn_true" | all_sum$measure == "nn_false"),])+
  geom_bar(aes(x=primer,y=value,fill=measure),stat="identity", position="stack") +
  facet_wrap(~dataset,scales="free_y") + 
  theme(axis.text.x = element_text(angle=90,hjust=1,vjust=0.5))

Fig3a <- p1 / p2 / p3 


#failed 

pest_fail <- pests[which(pests$primer =="fwhF2-fwhR2n" & pests$mono.match.Spp..unique.Spp... == "FALSE" | pests$nearNeighbour.Dist..Spp. == "FALSE" | pests$primer =="fwhF2-fwhR2n" & pests$V1 == "incorrect"),]
length(unique(pest_fail$Spp))

#All taxa which failed 
all_fail <- id_summary[which(id_summary$primer =="fwhF2-fwhR2n" & id_summary$mono.match.Spp..unique.Spp... == "FALSE" | id_summary$nearNeighbour.Dist..Spp. == "FALSE" | id_summary$primer =="fwhF2-fwhR2n" & id_summary$V1 == "incorrect"),]
length(unique(all_fail$Spp))

# Failed pest taxa were manually inspected, many of these were incorrectly annotated taxonomy, or synonyms
#The groups that are unlikely to work with any of these primers include:

```


# Figure 3 - Primer mismatch
PROBLEM - lost the folmer F and R binding regions when cleaning, so am restricting to primers within the binding region. It would be nice to have them all so i will need to do download and cleaning again. Need to write automated script for this, or see code from below study

Code modified from: Bylemans J, Gleeson DM, Hardy CM, Furlan E. Toward an ecoregion scale evaluation of eDNA metabarcoding primers: A case study for the freshwater fish biodiversity of the Murray-Darling Basin (Australia). Ecol Evol. 2018;8697â712. 

## PROBLEM - going to need to add the N's to make all the alignments the correct sizE!
Either add the N's, or generate a consensus, do an alignment to the consensus, get the ranges of the alignment, use those as the stop and start position - This might be a better way to do it

```{r Primerminer, message=FALSE}
library(PrimerMiner)

primers <- read_csv("primer_evaluation/primer_candidates.csv")
Alignments <- sort(list.files("primer_evaluation/pestfamilies/", pattern = ".fa.gz", full.names = TRUE)) # Read fasta filenames

names <- Alignments %>%
  str_replace(".fa.gz","") %>%
  str_replace(".fa","") %>%
  str_split_fixed("/", n = 3) %>%
  as_tibble() %>%
  pull(V3)

# Filter to only those within alignment size & HiSeq sized
dat.passed <- primers %>%
  filter(F.Start > 0 & R.Stop < 661) %>%
  filter(amplicon < 240) %>% 
  mutate(F.seq = str_replace_all(F.seq, "I","N"))%>% #Replace Inosines with N
  mutate(R.seq = str_replace_all(R.seq, "I","N"))


dir.create("primer_evaluation/PrimerMiner")

for (i in 1:nrow(dat.passed)) {
    dir.create(paste0("primer_evaluation/PrimerMiner/", dat.passed$F.Name[i]))
    dir.create(paste0("primer_evaluation/PrimerMiner/", dat.passed$R.Name[i]))
    
    for (j in 1:length(Alignments)) {
        seqs <- readDNAStringSet(Alignments[j])
        if(length(seqs) >1){
          
          #Problem, crashing on ionisine

          str_detect(dat.passed$R.seq[i], "I")
          
          Fprimer <-  matchPattern(DNAString(dat.passed$F.seq[i]),seqs[[1]],max.mismatch = 3,fixed=FALSE)
          Rprimer <-  matchPattern(reverseComplement(DNAString(dat.passed$R.seq[i])),seqs[[1]],max.mismatch = 3,fixed=FALSE)
          
          Fstart <- Fprimer@ranges@start
          Fstop <- Fprimer@ranges@start + Fprimer@ranges@width - 1
          Rstart <- Rprimer@ranges@start
          Rstop <- Rprimer@ranges@start + Rprimer@ranges@width - 1
          
        #Forward
        if(length(Fprimer@ranges@start) >0 && Fstart > 0){
        evaluate_primer(Alignments[j],
          as.character(dat.passed$F.seq[i]), Fstart, Fstop,
          forward = T, gap_NA = T,
          mm_position = "Position_v1", mm_type = "Type_v1", adjacent = 2,
          save = paste0("primer_evaluation/PrimerMiner/", dat.passed$F.Name[i], "/", names[j], ".csv")
        )
        }
        
        #Reverse
        #check length of target - does it suit reverse primer?
        if(length(Rprimer@ranges@start) >0 && Rstop < length(seqs[[1]])){
        evaluate_primer(Alignments[j],
          as.character(dat.passed$R.seq[i]), Rstart, Rstop,
          forward = F, gap_NA = T,
          mm_position = "Position_v1", mm_type = "Type_v1", adjacent = 2,
          save = paste0("primer_evaluation/PrimerMiner/", dat.passed$R.Name[i], "/", names[j], ".csv")
        )
        }
        
        }
    }    
}

```

## Plotting figure 3

```{r plot figure 2}
#Read in all files
files <- sort(list.files(list.dirs("primer_evaluation/PrimerMiner/"), pattern = ".csv", full.names = TRUE))

dat <- files %>% 
  purrr::set_names() %>%
  map_dfr(read_csv, col_types= cols_only(Template=col_character(),
                                       sequ=col_character(),
                                       sum=col_double()),.id = "source", progress=TRUE) %>%
  separate(col=Template, into=c("Acc","Kingdom","Phylum","Class","Order","Family","Genus","Species"), sep=";") %>%
  rename(Sequence = sequ) %>%
  mutate(Primer = source %>%
           str_replace("primer_evaluation/PrimerMiner//","") %>%
           str_replace("\\/(.*?)$", ""))

summaries <- dat %>% 
  filter(Species %in% str_replace_all(read_csv("primer_evaluation/pestlist.csv")$Species, " ", "_")) %>%
  group_by(Kingdom, Phylum, Class, Order, Family, Genus, Species, Primer) %>%
  summarise(sum = mean(sum)) %>% # Summarise mean of species with multiple sequences
  ungroup()  %>%
  mutate(dir = case_when(
    Primer %in% unique(dat.passed$F.Name) ~ "Forward",
    Primer %in% unique(dat.passed$R.Name) ~ "Reverse"
    ))  %>%
  mutate(Primer = paste0(substr(dir,1,1)," ",Primer))

#Get taxonomic lineage and convert to tree
  lineage <- summaries %>%
     group_by(Kingdom, Phylum, Class, Order, Family, Genus, Primer) %>%
  summarise(sum = mean(sum)) %>% # Summarise mean of species with multiple sequences
    tidyr::unite(col=pathString, Kingdom, Phylum, Class, Order, Family, Genus, sep="/") %>%
    dplyr::mutate(pathString = paste0("Root/", pathString)) %>%
    data.tree::as.Node(.)


tree <- ape::read.tree(textConnection(data.tree::ToNewick(lineage, heightAttribute = NULL)))

library(ggtree)

test <- as_tibble(tree) %>%
  full_join(summaries %>%
  group_by(Kingdom, Phylum, Class, Order, Family, Genus) %>%
  summarise(mismatch = mean(sum)) %>%
    rename(label = Genus)) 

p <- ggtree(tidytree::as.treedata(test), aes(color=mismatch)) +
  geom_nodelab(geom='label') + # + geom_tiplab(align=TRUE) 
  theme_tree2()+
  scale_colour_gradient(low = "darkgreen", high = "red", limits = c(0, 200), oob = scales::squish) + 
  theme(legend.position = "none") +
      scale_y_continuous(expand=c(0,0))

gg.sum <- summaries %>%
  group_by(Kingdom, Phylum, Class, Order, Family, Genus, Primer, dir) %>%
  summarise(sum = mean(sum) ) %>% # Summarise mean of species with multiple sequences
  ungroup() %>%
  left_join(p$data %>%
  filter(isTip) %>%
    select(c(label, y)) %>%
    rename(Genus = label)) %>%
  filter(!is.na(y)) %>%
  ggplot(aes(x = Primer , y = factor(.$Genus, levels=unique(.$Genus[order(.$y)])) , fill = sum)) +
  geom_tile() +
  #scale_fill_viridis_c(option="magma",limits = c(0, 200))+
  scale_fill_gradient(low = "darkgreen", high = "red", na.value = "grey", limits = c(0, 200), oob = scales::squish) +
  facet_grid(~dir, scales="free", space="free", drop=TRUE) +
  theme_classic() + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.y = element_blank(),
    strip.text.y = element_text(angle = 0)
  ) 

p + gg.sum

```

# LCA Stats


# Evaluate LCA stats

```{r evaluate LCA}
taxreturn::lca_probs(x, sim=seq(0.5,1,0.1))

pestlist <- read_csv("primer_evaluation/pestlist.csv") %>%
  pull(Family) %>%
  unique()
seqs <- readFASTA("reference/merged_final.fa.gz")

out <- taxreturn::lca_probs(seqs, sim=seq(0.8,1,0.01))
write_csv(out, path="primer_evaluation/LCA_probabilities.csv")
out <- read_csv("primer_evaluation/LCA_probabilities.csv") %>% 
  pivot_longer(
    cols = kingdom:species,
    names_to="rank",
    values_to = "prob")


gg.lca  <-  ggplot(out, aes(x=sim, y=prob, group=rank, fill=rank, colour=rank)) + 
  geom_line(size=1) +
  geom_vline(xintercept=0.97, linetype="dotted") +
  scale_x_reverse(breaks=seq(.8,1,0.01)) + 
  scale_color_brewer(palette = "Spectral")  +
  theme_classic()  +
  theme(legend.position = "bottom") +
  xlab("% Sequence Identity") +
  ylab("P(LCR)") + 
  ggtitle("Probability of sequence sharing LCR with reference")



## Split by family?

# Splitting the fastas doesnt work, will have to split the way it returns them using grouping
problist <- vector("list", length=length(pestlist))
for (i in 1:length(pestlist)){
  query <- pestlist[i]
  names <- names(seqs)  %>% 
    str_split_fixed(";", n = 8) %>% 
    as_tibble() %>% 
    filter(V6 == query) %>%
    unite(names,paste0("V",1:8),sep=";")
          
  subset <- seqs[names(seqs) %in% names$names]
  if (length(subset) > 0){
  problist[[i]] <- taxreturn::lca_probs(subset, sim=seq(0.5,1,0.1)) %>%
    mutate(Family = pestlist[i])
  print(problist[[i]])
  }
  
}

## Might need to remove those with too low sequences to run the sliding window script. Need to also check the amount of pass vs fails, maybe do a plot?
##Plot pass vs fails

gg.pass <- pass %>%
  gather(type,value, -name, -size) %>%
  #arrange(desc(value)) %>%
  mutate(name = fct_reorder(name, -value))%>%
  ggplot(aes(x=name,y=value,fill=type))+
  geom_bar(stat="identity", position="dodge") +
  theme(axis.text.x = element_text(angle=90))
```


# Evaluate off target identifications

Using the trimmed datasets, conduct a pirmerblast using primertree, and plot reuslts, highlighting the non-arthropoda nodes that were produced

modified from: Bylemans J, Gleeson DM, Hardy CM, Furlan E. Toward an ecoregion scale evaluation of eDNA metabarcoding primers: A case study for the freshwater fish biodiversity of the Murray-Darling Basin (Australia). Ecol Evol. 2018;8697â712. 

To reduce the number of primer pairs for further analyses perform an initial screening of primers using PrimerTree

Note: Detailed information about installing and running PrimerTree can be found at https://github.com/jimhester/primerTree

```{r }
primers <- read_csv("primer_candidates.csv")
library(primerTree)
# 3.1. - Query each primer pair against the NCBI database and construct a primertree object.
#dat.I <- primers[which(primers$Final=="TRUE"), ]
dat.I <- dat.passed

dir.create("PrimerTree")
#for (i in 1:nrow(dat.I)) {
  assign(paste("PT", dat.I$Name[i], sep = "."), search_primer_pair(name = dat.I$Name[i], dat.I$F.seq[i], dat.I$R.seq[i], num_permutations = 50, num_aligns = 1000))
  saveRDS(paste("PT", dat.I$Name[i], sep = "."),paste0("PrimerTree/PT.",dat.I$Name[i],".rds"))
}
#, clustal_options = c(exec='clustal-omega-1.2.2-win64/clustalo.exe')

# 3.2. - Inspect the sequence length distribution for each primer pair and remove any sequence records with a length deviating from the
#        majority of the sequences.

#Below code requires clustal files in R install directory

seq_lengths(`PT.AgPestF1-AgPestR1a`) # No obvious outliers
`PT.AgPestF1-AgPestR1a` <- filter_seqs(`PT.AgPestF1-AgPestR1a`, min_length = 200)

seq_lengths(`PT.AgPestF2-AgPestR2`) # No obvious outliers
`PT.AgPestF2-AgPestR2` <- filter_seqs(`PT.AgPestF2-AgPestR2`, min_length = 200)

seq_lengths(`PT.fwhF2-fwhR2n`) # No obvious outliers
`PT.fwhF2-fwhR2n` <- filter_seqs(`PT.fwhF2-fwhR2n`, min_length = 200)

seq_lengths(`PT.SauronS878-BR1`) # No obvious outliers
`PT.SauronS878-BR1` <- filter_seqs(`PT.SauronS878-BR1`, min_length = 200)

#Plot trees
t1 <- plot(`PT.AgPestF1-AgPestR1a`, ranks='class', main='PT.AgPestF1-AgPestR1a', rotate=45, size=1)
t2 <- plot(`PT.AgPestF2-AgPestR2`, ranks='class', main='PT.AgPestF2-AgPestR2', rotate=45, size=1)
t3 <- plot(`PT.fwhF2-fwhR2n`, ranks='class', main='PT.fwhF2-fwhR2n', rotate=45, size=1)
t4 <- plot(`PT.SauronS878-BR1`, ranks='class', main='PT.SauronS878-BR1', rotate=45, size=1)

Fig3 <- t1+t2+t3+t4
#on this plot we can see: 
#Off target amplifications
#Longer branch length = higher resolution


# 3.3. - Evaluate the taxonomic coverage and the specificity of the primers within the Actinopterygii class (i.e. Actinopteri class based
#        on the NCBI nomenclature). Also evaluate the taxonomic resolution of the primers at the genus level and correct for length of the
#        barcode to allow for comparisons between primers. Add additional columns to the input file for all calculated statistics.

dat.I$PT.Specificity <- rep("", nrow(dat.I))
dat.I$PT.PWDistance <- rep("", nrow(dat.I))
dat.I$PT.Length <- rep("", nrow(dat.I))
dat.I$PT.Resolution <- rep("", nrow(dat.I))
dat.I$PT.Order <- rep("", nrow(dat.I))
dat.I$PT.Family <- rep("", nrow(dat.I))
dat.I$PT.Genus <- rep("", nrow(dat.I))

for (i in 1:nrow(dat.I)) {
  tmp1 <- paste("PT", dat.I$Name[i], sep = ".")
  TAXID.All <- length(unique(as.data.frame(get(tmp1)$taxonomy)$taxId))
  TAXID.Act <- length(unique(subset(as.data.frame(get(tmp1)$taxonomy), subset = class == "Insecta")$taxId))
  dat.I$PT.Specificity[i] <- round((TAXID.Act / TAXID.All) * 100, digits = 2)
  dat.I$PT.PWDistance[i] <- as.numeric(calc_rank_dist_ave(get(tmp1), ranks = c("genus")))
  dat.I$PT.Length[i] <- as.integer(mean(get(tmp1)$BLAST_result$product_length))
  dat.I$PT.Resolution[i] <- as.numeric(dat.I$PT.PWDistance[i]) / as.numeric(dat.I$PT.Length[i])
  dat.I$PT.Order[i] <- length(unique(subset(as.data.frame(get(tmp1)$taxonomy), subset = class == "Insecta")$order))
  dat.I$PT.Family[i] <- length(unique(subset(as.data.frame(get(tmp1)$taxonomy), subset = class == "Insecta")$family))
  dat.I$PT.Genus[i] <- length(unique(subset(as.data.frame(get(tmp1)$taxonomy), subset = class == "Insecta")$genus))
}

#   B. Primer specificity (i.e. the percentage of unique Actinopterygii species out of the total number of unique species recovered)

gg.specificity <- ggplot(dat.I, aes(x = factor(Name, levels = Name), y = as.numeric(PT.Specificity))) +
  geom_bar(stat = "identity", fill = "gray50") +
  geom_hline(aes(yintercept = 90), linetype = "dashed", colour = "red3") +
  coord_cartesian(ylim = c(30, 100)) +
  ggtitle("B") +
  ylab("% of unique Actinopterygii species") +
  theme_classic() +
  theme(
    plot.title = element_text(size = 8, colour = "black", face = "bold"),
    axis.title.x = element_blank(),
    axis.title.y = element_text(size = 7, colour = "black"),
    axis.text.x = element_text(size = 7, colour = "black", angle = 90, hjust = 1, vjust = 0.5),
    axis.text.y = element_text(size = 7, colour = "black"),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_line(size = 0.25, colour = "black"),
    axis.ticks.length = unit(0.1, "cm")
  )
gg.specificity

#   C. Taxonomic coverage (i.e. no. of Actinopterygii orders for which sequences were obtained)

gg.coverage <- ggplot(dat.I, aes(x = factor(Name, levels = Name), y = as.numeric(PT.Order))) +
  geom_bar(stat = "identity", fill = "gray50") +
  geom_hline(aes(yintercept = 30), linetype = "dashed", colour = "red3") +
  coord_cartesian(ylim = c(0, 40)) +
  ggtitle("C") +
  ylab("No. of Actinopterygii orders") +
  theme_classic() +
  theme(
    plot.title = element_text(size = 8, colour = "black", face = "bold"),
    axis.title.x = element_blank(),
    axis.title.y = element_text(size = 7, colour = "black"),
    axis.text.x = element_text(size = 7, colour = "black", angle = 90, hjust = 1, vjust = 0.5),
    axis.text.y = element_text(size = 7, colour = "black"),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_line(size = 0.25, colour = "black"),
    axis.ticks.length = unit(0.1, "cm")
  )
gg.coverage

```

## Evaluate cleanseqs

```{r cleanseqs eval}

#Filtered was then aligned in MAFFT - mafft folmer_insecta_fullength.fa > folmer_insecta_fullength_aligned.fa
#alignment was then manually curated in geneious primer
folmer_curated <-  ape::read.dna("folmer_insecta_fullength_aligned_curated.fa",format="fasta")
model <- aphid::derivePHMM(folmer_curated)

seqs <- readDNAStringSet("test.fasta")

eval <- seq(50,500,50)

result_list <- vector("list", length(eval))

for (i in 1:length(eval)){

#remove non-homologous sequences

#model <- data("model", package="taxreturn")
load("C:/Users/ap0y/Dropbox/R/taxreturn/data/model.rda")
result_list[[i]] <- clean_seqs(seqs, model,minscore = i, cores=2, shave=TRUE,maxNs = 0)
print(eval[i])
print(result_list[[i]])

}

out <- clean_seqs(seqs, model,minscore = 600, cores=1, shave=TRUE,maxNs = 0)

```

## Try fill in gaps in Ridgeplot
```{r}

i=1
dat <- vector("list",length=length(vec))
con_list <- vector("list",length=length(vec))
if(file.exists("Sequences/consensus.fa.gz"))(file.remove("Sequences/consensus.fa.gz"))
for (i in 1:length(vec)) {
  file <- vec[i]
  seqs <- readDNAStringSet(file)
  
  values <- as_tibble(cbind(names[i], MaskAlignment(seqs, type="values",windowSize=1))) %>%
    rename(Family = `names[i]`) %>%
    mutate(Family = as.character(Family)) %>%
    mutate(pos = rownames(.))
  dat[[i]] <- values
  
  #Get consensus only for those with >100 sequences
  
  if(length(seqs) > 2){
  names(con) <- names[i]
  writeXStringSet(con, filepath="Sequences/consensus.fa.gz",append=TRUE, compress=TRUE, )
  }
}



  

#Try align to model
folmer_curated <-  ape::read.dna("folmer_insecta_fullength_aligned_curated.fa",format="fasta")
model <- aphid::derivePHMM(folmer_curated)
con_seqs <- readFASTA("Sequences/consensus.fa.gz")

aligned <- aphid::align(con_seqs, model=model)

test <- aligned %>% as.list %>% as.character %>% lapply(.,paste0,collapse="") %>% unlist %>% DNAStringSet()

test2 <- as.matrix(test)

det <- str_detect(as.character(test2[1,]), pattern="-")
dimnames(test2)[which %in% det]
match("-", as.character(test2[1,]))

ranges <- MaskAlignment(seqs, type="ranges", threshold=0, maxFractionGaps = 0.2, showPlot = TRUE) # Mask columns with majority gaps - caused 
seqs <- replaceAt(seqs, ranges) # remove the masked columns


browse <-  aligned %>% as.list %>% as.character %>% lapply(.,paste0,collapse="") %>% unlist %>% DNAStringSet()
BrowseSeqs(browse)

```


```{r sessioninfo}
sessionInfo(package = NULL)
```
