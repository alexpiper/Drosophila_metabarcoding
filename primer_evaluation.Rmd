---
title: "primer_evaluation"
author: "Alexander Piper"
date: "09/08/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Introduction


## Load packages
```{r setup}
#Set required packages
.cran_packages <- c("usethis",
                    "tidyverse",
                    "spider", 
                    "insect",
                    "ape",
                    "RColorBrewer",
                    "seqinr",
                    "patchwork",
                    "ShortRead",
                    "foreach",
                    "doParallel")

.bioc_packages <- c("DECIPHER",
                    "ggtree",
                    "Biostrings")

.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install(.bioc_packages[!.inst], ask = F)
}

#Load all packages
sapply(c(.cran_packages,.bioc_packages), require, character.only = TRUE)

# Github packages
devtools::install_github("alexpiper/taxreturn")
library(taxreturn)

# SOurce internal functions
source("R/helper_functions.R")

```

# Assemble pest list

* EPPO global database https://gd.eppo.int/ - DONE
* US APHIS - https://www.aphis.usda.gov/aphis/home/ - DONE
* QBank - https://qbank.eppo.int/arthropods/organisms - DONE
* Global invasive species database - http://www.iucngisd.org/gisd/search.php - DONE
* Global register of introduced or invasive species http://www.griis.org/ - DONE
* VectorBase: https://www.vectorbase.org/organisms - DONE
* DAWR top 40 - http://www.agriculture.gov.au/pests-diseases-weeds/plant - DONE
* PHA National biosecurity status report -  http://www.planthealthaustralia.com.au/national-programs/national-plant-biosecurity-status-report/ - DONE
* Ashfaq & Herbert 2016 - DNA barcodes for bio-surveillance: regulated and economically important arthropod plant pests - DONE
* CABI - https://t.co/LGjlFoOazd - DONE
* http://www.europe-aliens.org - DONE

```{r Curate pest lists}
dat <- list.files("primer_evaluation/pestlist/", pattern = ".csv", full.names = TRUE) %>%
  purrr::set_names() %>%
  map_dfr(read_csv, .id = "Source", col_types = cols("Species" = col_character())) %>%
  mutate(Source = str_remove(basename(Source), pattern="\\.csv")) %>%
  mutate(Species = Species %>%  
           str_remove_all("ÿ") %>% #Resolve weird characters
           iconv(from = 'UTF-8', to = 'ASCII//TRANSLIT')%>% 
           str_remove_all("\\?") %>%
           str_remove_all("\\((.*?)\\)") %>% # remove things between brackets ie: Hygromia (Hygromia) cinctella
           str_squish() # remove excess whitespace
         ) %>%
  filter(str_count(Species, " ") > 0 ) %>% #Remove non-binomial 
  separate(Species, into=c("Genus", "Species"), sep=" ", extra="merge") %>% # Fix duplicated genus names
  mutate(Species = str_remove(Species, pattern=Genus) %>% str_squish()) %>%
  unite(col=Species, Genus, Species, sep = " ") %>%
  unique()

# Map to OTT taxonomy ids
taxreturn::download_ott_taxonomy()
dat_resolved <- dat %>% mutate(Species = map_to_ott(Species, dir="ott3.2", from="ncbi", resolve_synonyms=TRUE, filter_bads=TRUE, remove_na = TRUE, quiet=FALSE)) %>%
  filter(!is.na(Species))

lineage <- get_ott_lineage(dat_resolved$Species, dir="ott3.2")  %>%
  bind_cols(dat_resolved) %>% 
  select(-Species)%>%
  rename_all(funs(str_to_sentence(.))) %>%
  filter(Class=="Insecta") %>%
  drop_na()

#Write out final list of pests 
write_csv(lineage, "primer_evaluation/pestlist.csv")
```

## Figure 1

```{r Figure 1}
lineage <- read_csv(
  "primer_evaluation/pestlist.csv",
  col_types  = cols(
  Acc = col_character(),
  Kingdom = col_character(),
  Phylum = col_character(),
  Class = col_character(),
  Order = col_character(),
  Family = col_character(),
  Genus = col_character(),
  Species = col_character(),
  Source = col_character()
)) %>%
  unique()

# Fig 1a - Upset plot of species share between the different databases

sources <- as.character(unique(lineage$Source))
upsetlist <- list()
for (i in 1:length(sources)){
  upsetlist[[i]]= lineage$Species[which(lineage$Source==sources[i])] 
  names(upsetlist)[[i]] <- sources[i]
}

Fig1a <- upset(fromList(upsetlist),nsets=length(upsetlist), order.by = "freq")
print(Fig1a)

## Figure 1b - summary of families within the dataset 

library(RColorBrewer)
col <- colorRampPalette(brewer.pal(11, "Spectral"))(10)

Fig1b <- group_by(lineage, Order, Source) %>%
  summarise(Genus = n_distinct(Genus), Species = n_distinct(Species)) %>%
  ungroup() %>%
  mutate(Order = fct_reorder(Order, -Species)) %>% 
  ggplot(aes(x = Order, y = Species, fill = Source)) +
  geom_bar(stat = "identity")  +
  theme_pubr() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1,vjust=0)) +
  scale_fill_manual(values=col) +
  ylim(-500,2500) +
  theme_minimal() +
  theme(
    axis.text = element_blank(),
    axis.title = element_blank(),
    panel.grid = element_blank(),
    plot.margin = unit(rep(-1,4), "cm")      # Adjust the margin to make in sort labels are not truncated!
  ) +
  coord_polar(start=0) +
  geom_text(data = . %>%
              dplyr::select(Order, Species) %>%
              group_by(Order) %>%
              summarise(value = sum(Species)),
            aes(x=Order, y=value + 20, label=Order),
            color="black", fontface="bold", alpha=0.6, inherit.aes = FALSE)

# Summaries for article text

# Unique taxa
lineage %>% 
  #select(-Source, Acc) %>%
  summarise(Species = n_distinct(Species),
            Genus = n_distinct(Genus),
            Family = n_distinct(Family),
            Order = n_distinct(Order),
            )

# Sum of reference DB's
lineage %>% 
  group_by(Source) %>%
  summarise(Species = n_distinct(Species)) %>%
  arrange(Species)

# Proportion of sequences unique
lineage %>%
  add_count(Source, name = "DB_total") %>%
  group_by(Species) %>%
  add_tally(name = "n_occurances") %>%
  ungroup() %>%
  filter(n_occurances==1) %>%
  group_by(Source, DB_total)%>%
  summarise(n = n_distinct(Species)) %>%
  mutate(freq = n / DB_total)%>%
  arrange(freq)
```

# Primer info

## Binding sites

```{r get primer binding sites}
#alignment was then manually curated in geneious primer
folmer_curated <-  ape::read.dna("reference/Folmer_insecta_fullength_withprime_curated.fa",format="fasta")
model <- aphid::derivePHMM(folmer_curated)


# Be worth validating how the score is calculated?
primers <- read_csv("primer_evaluation/primer_candidates.csv") %>%
  select(name, strand, seq, citation, issues) %>%
  left_join(.$seq %>% purrr::map(get_binding_position, model, tryrc = TRUE, minscore=8) %>%
  bind_rows() %>%
  rename(seq = primer), by="seq") %>%
  unique()

write_csv(primers, "primer_evaluation/primer_candidates.csv")

```

## Constraints

GC clamp
GC ratio
Tm Deviation
Tm Range
Repeats
Runs
Length

```{R }
#GC Ratio
test <- DNAString(primers$seq[1] %>% str_replace("I", "N"))
as.data.frame(alphabetFrequency(test, baseOnly=F, as.prob=T))


check_gc <- function(primer, ambiguous = TRUE){
  if(ambiguous){
    query <- unlist(DECIPHER::Disambiguate(DNAStringSet(primer)))
  } else {
    query <- DNAString(primer)
  }
   df <- as.data.frame(
     prop.table(
       colSums(
         letterFrequency(query,letters="ACGT", OR=0
                         )))) %>%
    rownames_to_column("Base") %>%
     set_colnames(c("Base", "Proportion"))
   df$primer <- primer
  return(df)
}

check_gc(primers$seq[1])



#TMCalc using nearest neighbour methods of Santalucia N E W J . Nearest-neighbor thermodynamics of deoxyinosine pairs in DNA duplexes[J].Nucleic Acids Research, 2005, 33(19):6258-67
library(TmCalculator)
primer <- primers$seq[1]
TmCalculator::Tm_NN(primer, ambiguous = TRUE)

# Can correct for salt content etc

#homopolymers

## Homopolymers check
test <- as.character(unlist(DECIPHER::Disambiguate(DNAStringSet(primer))))

check_homopolymers <- function(primer, ambiguous = TRUE){
  
  if(ambiguous){
    query <- as.character(unlist(DECIPHER::Disambiguate(DNAStringSet(primer))))
  } else {
    query <- primer
  }
  df <- data.frame(
      primer = primer,
    `A` = query %>% purrr::map_chr(longestConsecutive, "A") %>% max(),
    `T` = query %>% purrr::map_chr(longestConsecutive, "T") %>% max(),
    `G` = query %>% purrr::map_chr(longestConsecutive, "G") %>% max(),
    `C` = query %>% purrr::map_chr(longestConsecutive, "C") %>% max(),
    stringsAsFactors = FALSE
  )
  return(df)
}
 

```


## Presence in seqs

vcountpattern with maxmismatch changing?

with indels turns it to lehvenstein
```{r check pres}
primerHits <- function(primer, fn, max.mismatch=0, with.indels=FALSE) {
      if(stringr::str_detect(primer, "I")) {
        message(paste0("Warning: Inosine (I) bases detected in primer ", primer," these will be converted to N!"))
        primer <- primer %>% str_replace_all("I", "N")
        }
    # Counts number of sequences in which the primer is found
    nhits <- vcountPattern(primer, sread(readFasta(fn)), max.mismatch=max.mismatch, fixed = FALSE, with.indels = with.indels)
    return(sum(nhits > 0))
}

primers <- read_csv("primer_evaluation/primer_candidates.csv") 

fn="reference/merged_final.fa.gz"

out <- vector("list", length=nrow(primers))
for (i in 1:nrow(primers)){
  
  if(primers$strand[i] == "F"){
    query <- primers$seq[i]
    
  } else  if(primers$strand[i] == "R"){
    query <- rc(primers$seq[i])
  }
  print(i)
  df <- tibble(
    name = primers$name[i],
    primer = query,
    strand = primers$strand[i],
    #Hamming distance (no indels in COI)
    h0 = primerHits(query, fn, max.mismatch=0, with.indels=FALSE),
    h1 = primerHits(query, fn, max.mismatch=1, with.indels=FALSE),
    h2 = primerHits(query, fn, max.mismatch=2, with.indels=FALSE),
  )
  out[[i]] <- df
}

names(out) <- primers$seq
out <- bind_rows(out)
write_csv(out, "primer_evaluation/primer_presence.csv")

# Plotting
out <- read_csv("primer_evaluation/primer_presence.csv")

gg.primerpresF <- out %>% 
  pivot_longer(cols=starts_with(c("h", "l")),
               names_to = "measure",
               values_to = "seqs"
               ) %>%
  left_join(primers) %>%
  filter(strand=="F", measure=="h2") %>%
  mutate(name = fct_reorder(name, start, .desc = TRUE)) %>%
  ggplot(aes(x=name, y=seqs)) + 
  geom_bar(stat="identity", position="dodge") +
  coord_flip() + 
  xlab("Forward Primers")

gg.primerpresR <- out %>% 
  pivot_longer(cols=starts_with(c("h", "l")),
               names_to = "measure",
               values_to = "seqs"
               ) %>%
  left_join(primers) %>%
  filter(strand=="R", measure=="h2") %>%
  mutate(name = fct_reorder(name, start, .desc = TRUE)) %>%
  ggplot(aes(x=name, y=seqs)) + 
  geom_bar(stat="identity", position="dodge") +
  coord_flip() + 
  xlab("Reverse Primers")



gg.primerpresF / gg.primerpresR
```

# Primer placement

## Create alignment
```{r Align}
model <- readRDS("reference/folmer_fullength_model.rds")

seqs <- insect::readFASTA("reference/merged_final.fa.gz")
lengthfilt <- taxreturn::map_to_model(seqs, model, minscore = 400, shave= TRUE, pad=TRUE, check_indels=TRUE, maxNs=Inf, cores=47, quiet=FALSE)

#write out results
insect::writeFASTA(lengthfilt, "reference/merged_final_aligned.fa.gz", compress=TRUE)

## NOTE - need to double check why there are different lenght seqs. How is it handling big deletions
table(lengths(seqs))
test <- seqs[lengths(seqs)==692]
writeFASTA(test, "cicadelidae_deletion_seqs.fa")

# Get whole alignment entropy
lengthfilt <- insect::readFASTA("reference/merged_final_aligned.fa.gz")

ent <- taxreturn::alignment_entropy(lengthfilt, maskgaps=1, countgaps=FALSE, method="ML", unit="log")
values <- as.data.frame(ent, stringsAsFactors=FALSE) %>%
  rownames_to_column("pos") %>%
  magrittr::set_colnames(c("pos", "value"))

write_csv(values, "primer_evaluation/whole_alignment_entropy.csv")
```

## Entropy & SW by order

```{r subsetting}
## Read in aligned & Subset to only fullength
seqs <- insect::readFASTA("reference/merged_final_aligned.fa.gz")
seqs <- seqs[lengths(seqs)==712]

## TESTING
seqs <- seqs[1:1000]

# querylevel
queryrank <- "order"

# Get unique querieranks
queries <- names(seqs)  %>% 
  str_split_fixed(";", n = 8) %>% 
  as_tibble() %>% 
  magrittr::set_colnames(c("acc", "kingdom", "phylum",
                           "class", "order", "family", 
                           "genus", "species")) %>%
  filter(class=="Insecta") %>%
  pull(queryrank) %>%
  unique

#Make lists to store everything
entlist <- vector("list", length=length(queries))
names(entlist) <- queries
sw220 <- vector("list", length=length(queries))
names(sw220) <- queries
sw420 <- vector("list", length=length(queries))
names(sw420) <- queries

#Make folder to output files
dir.create(paste0("primer_evaluation/", queryrank))

for (i in 1:length(queries)){
  print(i)
  query <- queries[i]
 print(query)
  names <- names(seqs)  %>% 
  str_split_fixed(";", n = 8) %>% 
  as_tibble() %>% 
  magrittr::set_colnames(c("acc", "kingdom", "phylum",
                           "class", "order", "family", 
                           "genus", "species")) %>%
    filter_at(vars(queryrank), any_vars(.== query)) %>%
    unite(names,everything(),sep=";")
  
  subset <- seqs[names(seqs) %in% names$names]
  if (length(subset) > 0){
    #Transform to matrix
    subset <- as.matrix(subset)   
    nseqs <- nrow(subset)
    message(nseqs, " sequences for ", query)

    # Get entropies - Need to make this more robust to matrices! - as DNAbin list?
    ent <- taxreturn::alignment_entropy(as.list(subset), maskgaps=1, countgaps=FALSE, 
                                        method="ML", unit="log")
    entlist[[i]] <- as.data.frame(ent, stringsAsFactors=FALSE) %>%
      rownames_to_column("pos") %>%
      magrittr::set_colnames(c("pos", "value")) %>%
      mutate(nseqs = nseqs)
      
     # Conduct sliding window analysis
    aa <- Biostrings::strsplit(dimnames(subset)[[1]], split = ";")
    Genus <- sapply(aa, function(x) paste(x[7], sep = "_"))
    Spp <- sapply(aa, function(x) paste(x[8], sep = "_")) %>%
      str_replace(pattern="\\ ", replacement="_")
    
    #220 bp sw (Novaseq)
    nd <- slideNucDiag_para(subset, Spp, width = 220, interval = 3, cores=3)
    sw220[[i]] <- data.frame(pos=seq(1, dim(subset)[2] - 220, by = 3), nd=colSums(nd)) %>%
      mutate(nseqs = nseqs) %>%
      mutate(nspp = length(unique(Spp)))
    
    #420 bp sw (Miseq)
    nd <- slideNucDiag_para(subset, Spp, width = 420, interval = 3, cores=3)
    sw420[[i]] <- data.frame(pos=seq(1, dim(subset)[2] - 420, by = 3), nd=colSums(nd)) %>%
      mutate(nseqs = nseqs) %>%
      mutate(nspp = length(unique(Spp)))
    
    insect::writeFASTA(subset, file=paste0("primer_evaluation/", queryrank,"/", queries[i],".fa.gz"), compress=TRUE)
      }
}

ent_out <- bind_rows(entlist, .id="names")
write_csv(ent_out,paste0("primer_evaluation/",queryrank,"_ent_out.csv"))

sw220_out <- bind_rows(sw220, .id="names")
write_csv(sw220_out, paste0("primer_evaluation/",queryrank,"_sw220_out.csv"))

sw420_out <- bind_rows(sw420, .id="names")
write_csv(sw420_out, paste0("primer_evaluation/",queryrank,"_sw420_out.csv"))

```


## Figure 2
```{r entropy and sliding window}
# filter to just insecta (forgot to do this for first run)
orders <- get_ncbi_lineage() %>% 
  filter(class=="Insecta") %>% 
  pull(order) %>%
  unique()

# need to record number of seqs
orders <- orders[!orders %in% c("Grylloblattodea","Mantophasmatodea", "Zoraptera" )]
orders <- orders[!is.na(orders)] #Where are the NA's coming from?

values <- read_csv("primer_evaluation/order_ent_out.csv") %>%
  filter(names %in% orders)


#Set moving average function - Adjust smoothing (n=5?)
ma <- function(x,n=3){stats::filter(x,rep(1/n,n), sides=2)}

ent <- values %>%
  mutate(value = value %>% 
           na_if("") %>%
           replace_na(0)) %>%
  mutate(ma = ma(value, n = 3)) %>%
  mutate(annot = case_when(
    pos %in% seq(from=1, to=2, by=1) ~ "Loop 0",
    pos %in% seq(from=3, to=78, by=1) ~ "Helix 1",
    pos %in% seq(from=79, to=103, by=1)~ "Loop 1-2",
    pos %in% seq(from=104, to=211, by=1)~ "Helix 2",    
    pos %in% seq(from=212, to=235, by=1)~ "Loop 2-3",   
    pos %in% seq(from=213, to=304, by=1)~ "Helix 3", 
    pos %in% seq(from=305, to=373, by=1)~ "Loop 3-4", 
    pos %in% seq(from=374, to=466, by=1)~ "Helix 4", 
    pos %in% seq(from=467, to=499, by=1)~ "Loop 4-5", 
    pos %in% seq(from=500, to=598, by=1)~ "Helix 5", 
    pos %in% seq(from=599, to=634, by=1)~ "Loop 5-6", 
    pos %in% seq(from=635, to=712, by=1)~ "Helix 6", 
  )) %>%
  mutate(structure = case_when(
    str_detect(annot, "Helix") ~ "Helix",
    str_detect(annot, "Loop") ~ "Loop",
  ))  

## plot line by order to check (remove this)
gg.line <- ent %>%
  group_by(pos) %>%
  mutate(median = median(ma)) %>%
  ggplot(aes(x = pos, y=ma, colour=names)) + 
  geom_line(aes(x = pos, y=ma),size=1, inherit.aes = FALSE) +
  facet_wrap(~names)


# Plot entropy of COI
gg.box <- ent %>%
  group_by(pos) %>%
  mutate(median = median(ma)) %>%
  ggplot(aes(x = pos, y=ma, group=pos, colour=structure)) + 
  geom_boxplot(outlier.shape = NA, alpha=0.8) +
  geom_line(aes(x = pos, y=median),size=1, inherit.aes = FALSE) + #, colour="black"
  #?geom_tufteboxplot(median.type = "point", whisker.type = "line", hoffset = 0) +
  theme_classic() +    
  theme(legend.position = "bottom") +
  ylab("Entropy") +
  xlab("Position within COI folmer region") +
  scale_color_manual(values=c("#ca0020", "#0571b0")) +
  scale_x_continuous(limits = c(0, 712), breaks=seq(0,700,50), expand=c(0,0)) 

# Sliding window plots - Can i double facet by window size and order
sw220 <- read_csv("primer_evaluation/order_sw220_out.csv") %>%
  filter(names %in% orders) %>%
  mutate(windowsize = 220)

sw420 <- read_csv("primer_evaluation/order_sw420_out.csv") %>%
  filter(names %in% orders) %>%
  mutate(windowsize = 420)

sw <- bind_rows(sw220, sw420)

gg.sw <- sw %>%
  ggplot(aes(x = pos, y=nd, colour=names)) + 
  geom_line() +
  facet_grid(windowsize~names)

gg.density <-  sw220 %>%
  dplyr::rename(Order = names) %>%
  mutate(Order = case_when(
     Order %in% c("Coleoptera", "Diptera", "Hemiptera", "Hymenoptera", "Lepidoptera") ~ Order,
    !Order %in% c("Coleoptera", "Diptera", "Hemiptera", "Hymenoptera", "Lepidoptera") ~ "Other"
    )) %>%
  ggplot(aes(x =pos, y=1)) +
    geom_tile(aes(fill=nd))+
    scale_fill_viridis_c(option="plasma") + 
  facet_wrap(~Order, ncol=1, strip.position ="right") +
  scale_x_continuous(limits = c(0, 712), breaks=seq(0,700,50), expand=c(0,0))  +
  theme_void() +
  theme(legend.position = "bottom",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank())


## Primers
primers <- read_csv("primer_evaluation/primer_candidates.csv")

Fprimerpos <- seq(1,nrow(primers %>% filter(strand=="F")),1)/1000
Rprimerpos <- seq(1,nrow(primers %>% filter(strand=="R")),1)/1000

gg.primers <- ggplot(data=values[values$pos==1,], aes(x = as.numeric(pos))) +
  geom_segment(data = primers %>% filter(strand=="F"),
               aes(x = start, xend = end,
                   y = Fprimerpos, yend = Fprimerpos,
                   colour=strand), size = 1, arrow = arrow(length = unit(0.3,"cm")),
               show.legend = FALSE) +
  geom_text(data = primers %>% filter(strand=="F"),
            aes(x = start, y = Fprimerpos,
                label = name , colour=strand),
            hjust = 1, show.legend = FALSE) +
  geom_segment(data = primers %>% filter(strand=="R"),
               aes(x = end, xend = start,
                   y = Rprimerpos, yend = Rprimerpos,
                   colour=strand), size = 1,
               arrow = arrow(length = unit(0.3,"cm")),
               show.legend = FALSE) +
  geom_text(data = primers %>% filter(strand=="R"),
            aes(x = end, y = Rprimerpos,
                label = name, colour=strand),
            hjust = 0, show.legend = FALSE)  +
  scale_x_continuous(limits = c(0, 712), breaks=seq(0,700,50), expand=c(0,0)) +
  theme_classic()  +
  theme(legend.position = "none",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())

Fig2 <- gg.box / gg.density / gg.primers 

```

# Identificaiton sucess

In order to evaluate the taxonomic resolution of different barcode regions, alignments were trimmed to primer regions using the in silico PCR function from the insect package and  the identificaiton sucess functions from the SPIDER r package were used


Pairwise genetic distance was calculated for each pair of sequences using the “raw” model. We conducted bioinformatic analyses using the nearNeighbour, BestCloseMatch, and ThreshID functions to identify the taxa most likely to be misidentified or ambiguously identified using our primers

The nearNeighbour function determines, for each sequence in the reference database, whether the most closely related sequence originates from a conspecific, with 2 outcomes possible: “true” or “false.” This has problems with singletons however, as the nearest neighbour will always be another species,

BestCloseMatch and ThreshID functions use a genetic distance threshold to account for intra-specific variation. We estimated the most appropriate genetic thresholds to use for the “UNIQUE” and “FULL” databases to be 3.5% and 1%, respectively, based on the thresholds with the lowest cumulative error. The BestCloseMatch analysis identified the most closely related sequence, within the specified genetic distance threshold, and its species of origin for each query sequence. The ThreshID analysis extended this to consider species of origin for all sequences within the genetic distance threshold. These analyses had 4 possible outcomes: “correct,” “incorrect,” “ambiguous,” and “no identification” [47]. The “FULL” database was also analysed, with a 3.5% genetic threshold to allow for comparison with the results of the “UNIQUE” database


```{r identification sucess}
primers <- read_csv("primer_evaluation/primer_candidates.csv") %>%
  mutate(seq = str_replace_all(seq, "I","N")) %>% 
  select(-score, -issues)

# Get all possible primer combinations
combos <- expand_grid(primers %>% filter(strand=="F") %>% pull(seq),
                      primers %>% filter(strand=="R") %>% pull(seq)
                      ) %>%
  mutate_if(is.factor, as.character)%>%
  unique() %>%
  magrittr::set_colnames(c("Fseq", "Rseq")) %>%
  left_join(primers %>% filter(strand=="F") %>% rename_all(. %>% paste0("F",.)), by="Fseq") %>%
  left_join(primers %>% filter(strand=="R") %>% rename_all(. %>% paste0("R",.)), by="Rseq") %>%
  mutate(amplicon = Rstart - Fend) %>%
  filter( amplicon > 100)

## Load seqs - Cant operate with gaps
seqs <- insect::readFASTA("reference/merged_final.fa.gz")

seqs <- seqs[1:1000]
#seqs <- as.matrix(seqs)
#seqs <- aphid::unalign(seqs) # Cant operate on matrix
dir.create("primer_evaluation/amplicons")

for (p in 1:nrow(combos)) {
  
  amplicon <- virtualPCR(seqs, up = combos$Fseq[p],
                           combos$Rseq[p], rcdown = TRUE,
                             trimprimers = TRUE, quiet = FALSE, partialbind =FALSE, cores=2)
  
  primernames <- paste0(combos$Fname[p], "_",  combos$Rname[p])
    insect::writeFASTA(amplicon, file=paste0("primer_evaluation/amplicons/", primernames,".fa.gz"), compress=TRUE)  
  
}

#Metric 1 - 
### Number of shared mixed clusters for each primer
amplicon <- readFASTA("primer_evaluation/amplicons/fwhF2_fwhR2n.fa.gz")


db <- taxreturn::get_ott_taxonomy(dir="ott3.2")

seqs <- amplicon[1:1000]

thresholds <- rev(seq(0.9, 1, 0.01))
threshlist <- vector("list", length=length(thresholds))

for (i in 1:length(thresholds)){
  threshlist[[i]] <- taxreturn::get_mixed_clusters(
    x = seqs, db=db,
    rank = c("species","genus","family"),
    threshold = thresholds[i],
    confidence=0, quiet = FALSE) 
}
names(threshlist) <- thresholds 
mixed_clusters <- dplyr::bind_rows(threshlist)

# SUmmarise number of mixed clusters that contain pests at %

#Subset above results

#Metric 2 - ID SUCCESS WITH SPIDER
# Could also do mixed clusters at different distance levels, using get_mixed_clusters equvialent

#Metric 3 - Leave one out

#Metric 4- P(LCR) for each? 

## Should be able to evaluate these with the RDP clasifier and blast

  if (length(amplicon) > 3) {
    
    #Filter to median - Probem is the ones with deletions
    #Could i extract subalignments of the ones of different size then pad them?
    seqLength <- lengths(amplicon)
    
    # Get most frequent value
    uniqx <- unique(na.omit(seqLength))
    freqlen <- uniqx[which.max(tabulate(match(seqLength, uniqx)))]
    amplicon <- as.matrix(amplicon[which(seqLength == freqlen)])
    
    # Genus and species names
    aa <- Biostrings::strsplit(dimnames(amplicon)[[1]], split = ";")
    Genus <- sapply(aa, function(x) paste(x[7], sep = "_"))
    Spp <- sapply(aa, function(x) paste(x[8], sep = "_"))
    
    # Could i speed this up using kmer::mbed
    dist <- kmer::kdistance(amplicon)
    
    Dist <- dist.dna(amplicon, pairwise.deletion = TRUE)
    
    
    if (any(Dist > 0)){
      closematch <- tibble(
        query = labels(amplicon),
        Spp = Spp,
        result = bestCloseMatch(Dist, Spp))  %>% 
        left_join(enframe(bestCloseMatch(Dist, Spp, names = TRUE)) %>%
                  set_colnames(c("query", "names"))%>% 
                  mutate(names = map(names, ~set_names(., paste0("closematch_",seq_along(.))))) ,
                  by="query") %>%
        unnest_wider(col=names)
      
      if (length(unique(Spp)) > 3) {
        Tr <- nj(Dist)
        maxInt <- max(Tr$edge.length[Tr$edge[, 2] > length(Tr$tip.label)])
        nodeRoot <- Tr$edge[which(Tr$edge.length == maxInt), 2]
        TrRoot <- root(Tr, node = nodeRoot, resolve.root = TRUE)
        TrRoot$tip.label <- Spp
        mono <- monophyly(TrRoot, Spp, singletonsMono = TRUE)
        
        prime[[p]] <-  tibble(
          primer = dat.passed$Name[p],
          Spp = Spp,
          query = dimnames(amplicon)[[1]],
          nn = nearNeighbour(Dist, Spp),
          nn_spp = nearNeighbour(Dist, Spp, names = TRUE),
          mono=mono[match(Spp, unique(Spp))]
        ) %>%
          left_join(closematch, by=c("query", "Spp"))
        
      } else if (length(unique(Spp)) <3) {
         prime[[p]] <- tibble(
          primer = dat.passed$Name[p],
          Spp = Spp,
          query = dimnames(amplicon)[[1]],
          nn = nearNeighbour(Dist, Spp),
          nn_spp = nearNeighbour(Dist, Spp, names = TRUE)
        ) %>%
          left_join(closematch, by=c("query", "Spp"))
      } 
    } 
}


# Some sequences are lost with the in silico PCR, will need to put another column for unsucessfully amplified

# Would be good to display this as amplification sucess by length as well
```

## Figure 3

```{r figure 3}
#Read back in data:
vec <- sort(list.files("primer_evaluation/amplicons/", pattern = ".csv", full.names = TRUE)) # Read fasta filenames


id_summary <- vec %>%
  purrr::set_names() %>%
  purrr::map_dfr(read_csv, .id = "Source")
  
pestlist <- read_csv("primer_evaluation/pestlist.csv") %>%
  mutate(Species = str_replace_all(Species, " ", "_"))

#summarise for all taxa 

# Could probably left_join to the lineage data, and then summarise by genus/ family etc
all_sum <- id_summary %>%
  dplyr::group_by(primer) %>%
  dplyr::summarise(amplified=n(), 
                   nn_true = sum(nn==TRUE),
                   nn_false = sum(nn==FALSE),
                   cm_ambiguous=sum(result=="ambiguous"),
                   cm_incorrect=sum(result=="incorrect"),
                   cm_correct=sum(result=="correct"),      
                   cm_noid=sum(result=="no id"),
                   mono_true=sum(mono==TRUE),
                   mono_false=sum(mono==FALSE))%>% 
  gather(key="measure", value="value", -primer) %>%
  mutate(dataset="all")



pest_sum <- id_summary %>%
  filter(Spp %in% str_replace_all(read_csv("primer_evaluation/pestlist.csv")$Species, " ", "_")) %>%
  rename(Species = Spp) %>%
  left_join(read_csv("primer_evaluation/pestlist.csv") %>%
              dplyr::select(-Source) %>%
              mutate(Species = str_replace_all(Species, " ", "_")),
            by="Species") #%>%
  group_by(Class, Order, Family, Genus, primer) %>%
  dplyr::summarise(amplified = n(),
                   nn = sum(nn==TRUE),
                   mono = sum(mono==TRUE),
                   cm = sum(result=="correct") + sum(result=="no id")) %>%
  dplyr::mutate(
    nn = nn / amplified,
    mono = mono / amplified,
    cm = cm / amplified
  ) #%>%
  select(-amplified) %>%
  ungroup() %>%
  pivot_longer(cols=nn:cm,
               names_to="measure",
               values_to="value")
  
  
#Get taxonomic lineage and convert to tree

library(ggtree)

test <- as_tibble(tree) %>%
  full_join(pest_sum  %>%
    rename(label = Genus)) 

p <- ggtree(tidytree::as.treedata(test)) +
  geom_nodelab(geom='label') + # + geom_tiplab(align=TRUE) 
  theme_tree2() #+
  scale_colour_gradient(low = "darkgreen", high = "red",  oob = scales::squish) + 
  theme(legend.position = "none") +
      scale_y_continuous(expand=c(0,0))
  

  
  
gg.ident <- pest_sum %>%
  left_join(p$data %>%
  filter(isTip) %>%
    select(c(label, y)) %>%
    rename(Genus = label)) %>%
  filter(!is.na(y)) %>%
  ggplot(aes(x = primer , y = factor(.$Genus, levels=unique(.$Genus[order(.$y)])) , fill = value)) +
  geom_tile() +
  #scale_fill_viridis_c(option="magma",limits = c(0, 200))+
  scale_fill_gradient(low = "red", high = "darkgreen", na.value = "grey", limits = c(0, 1), oob = scales::squish) +
  facet_grid(~measure) +
  theme_classic() + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.y = element_blank(),
    strip.text.y = element_text(angle = 0)
  ) 

p + gg.ident  
  

#Join datasets

p1 <- ggplot(all_sum[which(all_sum$measure == "cm_ambiguous" | all_sum$measure == "cm_correct" | all_sum$measure == "cm_incorrect" |  all_sum$measure == "cm_noid" ),])+
  geom_bar(aes(x=primer,y=value,fill=measure),stat="identity", position="stack") +
  facet_wrap(~dataset,scales="free_y")+ 
  theme(axis.text.x = element_text(angle=90,hjust=1,vjust=0.5))+
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank())

p2 <- ggplot(all_sum[which(all_sum$measure == "mono_true" | all_sum$measure == "mono_false"),])+
  geom_bar(aes(x=primer,y=value,fill=measure),stat="identity", position="stack") +
  facet_wrap(~dataset,scales="free_y") + 
  theme(axis.text.x = element_text(angle=90,hjust=1,vjust=0.5))+
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank())

p3 <- ggplot(all_sum[which(all_sum$measure == "nn_true" | all_sum$measure == "nn_false"),])+
  geom_bar(aes(x=primer,y=value,fill=measure),stat="identity", position="stack") +
  facet_wrap(~dataset,scales="free_y") + 
  theme(axis.text.x = element_text(angle=90,hjust=1,vjust=0.5))

Fig3a <- p1 / p2 / p3 


#failed 

pest_fail <- pests[which(pests$primer =="fwhF2-fwhR2n" & pests$mono.match.Spp..unique.Spp... == "FALSE" | pests$nearNeighbour.Dist..Spp. == "FALSE" | pests$primer =="fwhF2-fwhR2n" & pests$V1 == "incorrect"),]
length(unique(pest_fail$Spp))

#All taxa which failed 
all_fail <- id_summary[which(id_summary$primer =="fwhF2-fwhR2n" & id_summary$mono.match.Spp..unique.Spp... == "FALSE" | id_summary$nearNeighbour.Dist..Spp. == "FALSE" | id_summary$primer =="fwhF2-fwhR2n" & id_summary$V1 == "incorrect"),]
length(unique(all_fail$Spp))

# Failed pest taxa were manually inspected, many of these were incorrectly annotated taxonomy, or synonyms
#The groups that are unlikely to work with any of these primers include:

```


# Primer mismatch
Need to load the aligned Database so the N's are there

Code modified from: Bylemans J, Gleeson DM, Hardy CM, Furlan E. Toward an ecoregion scale evaluation of eDNA metabarcoding primers: A case study for the freshwater fish biodiversity of the Murray-Darling Basin (Australia). Ecol Evol. 2018;8697–712. 

```{r Primerminer, message=FALSE}
library(PrimerMiner)

primers <- read_csv("primer_evaluation/primer_candidates.csv")
Alignments <- sort(list.files("primer_evaluation/pestfamilies/", pattern = ".fa.gz", full.names = TRUE)) # Read fasta filenames

names <- Alignments %>%
  str_replace(".fa.gz","") %>%
  str_replace(".fa","") %>%
  str_split_fixed("/", n = 3) %>%
  as_tibble() %>%
  pull(V3)

# Filter to only those within alignment size & HiSeq sized
dat.passed <- primers %>%
  filter(F.Start > 0 & R.Stop < 661) %>%
  filter(amplicon < 240) %>% 
  mutate(F.seq = str_replace_all(F.seq, "I","N"))%>% #Replace Inosines with N
  mutate(R.seq = str_replace_all(R.seq, "I","N"))


dir.create("primer_evaluation/PrimerMiner")

for (i in 1:nrow(dat.passed)) {
    dir.create(paste0("primer_evaluation/PrimerMiner/", dat.passed$F.Name[i]))
    dir.create(paste0("primer_evaluation/PrimerMiner/", dat.passed$R.Name[i]))
    
    for (j in 1:length(Alignments)) {
        seqs <- readDNAStringSet(Alignments[j])
        if(length(seqs) >1){
          
          #Problem, crashing on ionisine

          str_detect(dat.passed$R.seq[i], "I")
          
          Fprimer <-  matchPattern(DNAString(dat.passed$F.seq[i]),seqs[[1]],max.mismatch = 3,fixed=FALSE)
          Rprimer <-  matchPattern(reverseComplement(DNAString(dat.passed$R.seq[i])),seqs[[1]],max.mismatch = 3,fixed=FALSE)
          
          Fstart <- Fprimer@ranges@start
          Fstop <- Fprimer@ranges@start + Fprimer@ranges@width - 1
          Rstart <- Rprimer@ranges@start
          Rstop <- Rprimer@ranges@start + Rprimer@ranges@width - 1
          
        #Forward
        if(length(Fprimer@ranges@start) >0 && Fstart > 0){
        evaluate_primer(Alignments[j],
          as.character(dat.passed$F.seq[i]), Fstart, Fstop,
          forward = T, gap_NA = T,
          mm_position = "Position_v1", mm_type = "Type_v1", adjacent = 2,
          save = paste0("primer_evaluation/PrimerMiner/", dat.passed$F.Name[i], "/", names[j], ".csv")
        )
        }
        
        #Reverse
        #check length of target - does it suit reverse primer?
        if(length(Rprimer@ranges@start) >0 && Rstop < length(seqs[[1]])){
        evaluate_primer(Alignments[j],
          as.character(dat.passed$R.seq[i]), Rstart, Rstop,
          forward = F, gap_NA = T,
          mm_position = "Position_v1", mm_type = "Type_v1", adjacent = 2,
          save = paste0("primer_evaluation/PrimerMiner/", dat.passed$R.Name[i], "/", names[j], ".csv")
        )
        }
        
        }
    }    
}

```

## Figure 4

```{r figure 4}
#Read in all files
files <- sort(list.files(list.dirs("primer_evaluation/PrimerMiner/"), pattern = ".csv", full.names = TRUE))

dat <- files %>% 
  purrr::set_names() %>%
  map_dfr(read_csv, col_types= cols_only(Template=col_character(),
                                       sequ=col_character(),
                                       sum=col_double()),.id = "source", progress=TRUE) %>%
  separate(col=Template, into=c("Acc","Kingdom","Phylum","Class","Order","Family","Genus","Species"), sep=";") %>%
  rename(Sequence = sequ) %>%
  mutate(Primer = source %>%
           str_replace("primer_evaluation/PrimerMiner//","") %>%
           str_replace("\\/(.*?)$", ""))

summaries <- dat %>% 
  filter(Species %in% str_replace_all(read_csv("primer_evaluation/pestlist.csv")$Species, " ", "_")) %>%
  group_by(Kingdom, Phylum, Class, Order, Family, Genus, Species, Primer) %>%
  summarise(sum = mean(sum)) %>% # Summarise mean of species with multiple sequences
  ungroup()  %>%
  mutate(dir = case_when(
    Primer %in% unique(dat.passed$F.Name) ~ "Forward",
    Primer %in% unique(dat.passed$R.Name) ~ "Reverse"
    ))  %>%
  mutate(Primer = paste0(substr(dir,1,1)," ",Primer))

#Get taxonomic lineage and convert to tree
  lineage <- summaries %>%
     group_by(Kingdom, Phylum, Class, Order, Family, Genus, Primer) %>%
  summarise(sum = mean(sum)) %>% # Summarise mean of species with multiple sequences
    tidyr::unite(col=pathString, Kingdom, Phylum, Class, Order, Family, Genus, sep="/") %>%
    dplyr::mutate(pathString = paste0("Root/", pathString)) %>%
    data.tree::as.Node(.)


tree <- ape::read.tree(textConnection(data.tree::ToNewick(lineage, heightAttribute = NULL)))

library(ggtree)

test <- as_tibble(tree) %>%
  full_join(summaries %>%
  group_by(Kingdom, Phylum, Class, Order, Family, Genus) %>%
  summarise(mismatch = mean(sum)) %>%
    rename(label = Genus)) 

p <- ggtree(tidytree::as.treedata(test), aes(color=mismatch)) +
  geom_nodelab(geom='label') + # + geom_tiplab(align=TRUE) 
  theme_tree2()+
  scale_colour_gradient(low = "darkgreen", high = "red", limits = c(0, 200), oob = scales::squish) + 
  theme(legend.position = "none") +
      scale_y_continuous(expand=c(0,0))

gg.sum <- summaries %>%
  group_by(Kingdom, Phylum, Class, Order, Family, Genus, Primer, dir) %>%
  summarise(sum = mean(sum) ) %>% # Summarise mean of species with multiple sequences
  ungroup() %>%
  left_join(p$data %>%
  filter(isTip) %>%
    select(c(label, y)) %>%
    rename(Genus = label)) %>%
  filter(!is.na(y)) %>%
  ggplot(aes(x = Primer , y = factor(.$Genus, levels=unique(.$Genus[order(.$y)])) , fill = sum)) +
  geom_tile() +
  #scale_fill_viridis_c(option="magma",limits = c(0, 200))+
  scale_fill_gradient(low = "darkgreen", high = "red", na.value = "grey", limits = c(0, 200), oob = scales::squish) +
  facet_grid(~dir, scales="free", space="free", drop=TRUE) +
  theme_classic() + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.y = element_blank(),
    strip.text.y = element_text(angle = 0)
  ) 

p + gg.sum

```

# Off-target amplification

Using the trimmed datasets, conduct a pirmerblast using primertree, and plot reuslts, highlighting the non-arthropoda nodes that were produced

modified from: Bylemans J, Gleeson DM, Hardy CM, Furlan E. Toward an ecoregion scale evaluation of eDNA metabarcoding primers: A case study for the freshwater fish biodiversity of the Murray-Darling Basin (Australia). Ecol Evol. 2018;8697–712. 

To reduce the number of primer pairs for further analyses perform an initial screening of primers using PrimerTree

Note: Detailed information about installing and running PrimerTree can be found at https://github.com/jimhester/primerTree

```{r off target}
primers <- read_csv("primer_evaluation/primer_candidates.csv")
library(primerTree)

forward <- "GGDRCWGGWTGAACWGTWTAYCCNCC"
rev <- "TATDGTRATDGCHCCNGC"

test3 <- search_primer_pair(
  forward,
  rev
)
ranks = c("kingdom", "phylum", "class", 
    "order", "family", "genus", "species")

lineage <- test[["taxonomy"]] %>%
  select(all_of(ranks))%>% 
  tidyr::unite(col = pathString, 
  !!ranks, sep = "/") %>%
  dplyr::mutate(pathString = paste0("Root/", pathString)) %>%
  data.tree::as.Node(.)

tree <- ape::read.tree(textConnection(data.tree::ToNewick(lineage, heightAttribute = NULL)))

library(ggtree)

ggtree(tree)


dir.create("PrimerTree")
#for (i in 1:nrow(dat.I)) {
  assign(paste("PT", dat.I$Name[i], sep = "."), search_primer_pair(name = dat.I$Name[i], dat.I$F.seq[i], dat.I$R.seq[i], num_permutations = 50, num_aligns = 1000))
  saveRDS(paste("PT", dat.I$Name[i], sep = "."),paste0("PrimerTree/PT.",dat.I$Name[i],".rds"))
}
#, clustal_options = c(exec='clustal-omega-1.2.2-win64/clustalo.exe')

# 3.2. - Inspect the sequence length distribution for each primer pair and remove any sequence records with a length deviating from the
#        majority of the sequences.

#Below code requires clustal files in R install directory

seq_lengths(`PT.AgPestF1-AgPestR1a`) # No obvious outliers
`PT.AgPestF1-AgPestR1a` <- filter_seqs(`PT.AgPestF1-AgPestR1a`, min_length = 200)

seq_lengths(`PT.AgPestF2-AgPestR2`) # No obvious outliers
`PT.AgPestF2-AgPestR2` <- filter_seqs(`PT.AgPestF2-AgPestR2`, min_length = 200)

seq_lengths(`PT.fwhF2-fwhR2n`) # No obvious outliers
`PT.fwhF2-fwhR2n` <- filter_seqs(`PT.fwhF2-fwhR2n`, min_length = 200)

seq_lengths(`PT.SauronS878-BR1`) # No obvious outliers
`PT.SauronS878-BR1` <- filter_seqs(`PT.SauronS878-BR1`, min_length = 200)

#Plot trees
t1 <- plot(`PT.AgPestF1-AgPestR1a`, ranks='class', main='PT.AgPestF1-AgPestR1a', rotate=45, size=1)
t2 <- plot(`PT.AgPestF2-AgPestR2`, ranks='class', main='PT.AgPestF2-AgPestR2', rotate=45, size=1)
t3 <- plot(`PT.fwhF2-fwhR2n`, ranks='class', main='PT.fwhF2-fwhR2n', rotate=45, size=1)
t4 <- plot(`PT.SauronS878-BR1`, ranks='class', main='PT.SauronS878-BR1', rotate=45, size=1)

Fig3 <- t1+t2+t3+t4
#on this plot we can see: 
#Off target amplifications
#Longer branch length = higher resolution


# 3.3. - Evaluate the taxonomic coverage and the specificity of the primers within the Actinopterygii class (i.e. Actinopteri class based
#        on the NCBI nomenclature). Also evaluate the taxonomic resolution of the primers at the genus level and correct for length of the
#        barcode to allow for comparisons between primers. Add additional columns to the input file for all calculated statistics.

dat.I$PT.Specificity <- rep("", nrow(dat.I))
dat.I$PT.PWDistance <- rep("", nrow(dat.I))
dat.I$PT.Length <- rep("", nrow(dat.I))
dat.I$PT.Resolution <- rep("", nrow(dat.I))
dat.I$PT.Order <- rep("", nrow(dat.I))
dat.I$PT.Family <- rep("", nrow(dat.I))
dat.I$PT.Genus <- rep("", nrow(dat.I))

for (i in 1:nrow(dat.I)) {
  tmp1 <- paste("PT", dat.I$Name[i], sep = ".")
  TAXID.All <- length(unique(as.data.frame(get(tmp1)$taxonomy)$taxId))
  TAXID.Act <- length(unique(subset(as.data.frame(get(tmp1)$taxonomy), subset = class == "Insecta")$taxId))
  dat.I$PT.Specificity[i] <- round((TAXID.Act / TAXID.All) * 100, digits = 2)
  dat.I$PT.PWDistance[i] <- as.numeric(calc_rank_dist_ave(get(tmp1), ranks = c("genus")))
  dat.I$PT.Length[i] <- as.integer(mean(get(tmp1)$BLAST_result$product_length))
  dat.I$PT.Resolution[i] <- as.numeric(dat.I$PT.PWDistance[i]) / as.numeric(dat.I$PT.Length[i])
  dat.I$PT.Order[i] <- length(unique(subset(as.data.frame(get(tmp1)$taxonomy), subset = class == "Insecta")$order))
  dat.I$PT.Family[i] <- length(unique(subset(as.data.frame(get(tmp1)$taxonomy), subset = class == "Insecta")$family))
  dat.I$PT.Genus[i] <- length(unique(subset(as.data.frame(get(tmp1)$taxonomy), subset = class == "Insecta")$genus))
}

#   B. Primer specificity (i.e. the percentage of unique Actinopterygii species out of the total number of unique species recovered)

gg.specificity <- ggplot(dat.I, aes(x = factor(Name, levels = Name), y = as.numeric(PT.Specificity))) +
  geom_bar(stat = "identity", fill = "gray50") +
  geom_hline(aes(yintercept = 90), linetype = "dashed", colour = "red3") +
  coord_cartesian(ylim = c(30, 100)) +
  ggtitle("B") +
  ylab("% of unique Actinopterygii species") +
  theme_classic() +
  theme(
    plot.title = element_text(size = 8, colour = "black", face = "bold"),
    axis.title.x = element_blank(),
    axis.title.y = element_text(size = 7, colour = "black"),
    axis.text.x = element_text(size = 7, colour = "black", angle = 90, hjust = 1, vjust = 0.5),
    axis.text.y = element_text(size = 7, colour = "black"),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_line(size = 0.25, colour = "black"),
    axis.ticks.length = unit(0.1, "cm")
  )
gg.specificity

#   C. Taxonomic coverage (i.e. no. of Actinopterygii orders for which sequences were obtained)

gg.coverage <- ggplot(dat.I, aes(x = factor(Name, levels = Name), y = as.numeric(PT.Order))) +
  geom_bar(stat = "identity", fill = "gray50") +
  geom_hline(aes(yintercept = 30), linetype = "dashed", colour = "red3") +
  coord_cartesian(ylim = c(0, 40)) +
  ggtitle("C") +
  ylab("No. of Actinopterygii orders") +
  theme_classic() +
  theme(
    plot.title = element_text(size = 8, colour = "black", face = "bold"),
    axis.title.x = element_blank(),
    axis.title.y = element_text(size = 7, colour = "black"),
    axis.text.x = element_text(size = 7, colour = "black", angle = 90, hjust = 1, vjust = 0.5),
    axis.text.y = element_text(size = 7, colour = "black"),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_line(size = 0.25, colour = "black"),
    axis.ticks.length = unit(0.1, "cm")
  )
gg.coverage

```


```{r sessioninfo}
sessionInfo(package = NULL)
```
