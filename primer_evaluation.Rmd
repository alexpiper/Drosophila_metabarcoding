---
title: "primer_evaluation"
author: "Alexander Piper"
date: "09/08/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Introduction


## Load packages
```{r setup}
#Set required packages
.cran_packages <- c("usethis",
                    "tidyverse",
                    "spider", 
                    "insect",
                    "ape",
                    "RColorBrewer",
                    "seqinr",
                    "patchwork",
                    "ShortRead",
                    "foreach",
                    "doParallel",
                    "PrimerTree",
                    "TmCalculator")

.bioc_packages <- c("DECIPHER",
                    "ggtree",
                    "Biostrings")

.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install(.bioc_packages[!.inst], ask = F)
}

#Load all packages
sapply(c(.cran_packages,.bioc_packages), require, character.only = TRUE)

# Github packages
devtools::install_github("alexpiper/taxreturn")
library(taxreturn)
library(PrimerMiner)

# SOurce internal functions
source("R/helper_functions.R")

```

# Assemble pest list

* EPPO global database https://gd.eppo.int/ - DONE
* US APHIS - https://www.aphis.usda.gov/aphis/home/ - DONE
* QBank - https://qbank.eppo.int/arthropods/organisms - DONE
* Global invasive species database - http://www.iucngisd.org/gisd/search.php - DONE
* Global register of introduced or invasive species http://www.griis.org/ - DONE
* VectorBase: https://www.vectorbase.org/organisms - DONE
* DAWR top 40 - http://www.agriculture.gov.au/pests-diseases-weeds/plant - DONE
* PHA National biosecurity status report -  http://www.planthealthaustralia.com.au/national-programs/national-plant-biosecurity-status-report/ - DONE
* Ashfaq & Herbert 2016 - DNA barcodes for bio-surveillance: regulated and economically important arthropod plant pests - DONE
* CABI - https://t.co/LGjlFoOazd - DONE
* http://www.europe-aliens.org - DONE

```{r Curate pest lists}
dat <- list.files("primer_evaluation/pestlist/", pattern = ".csv", full.names = TRUE) %>%
  purrr::set_names() %>%
  map_dfr(read_csv, .id = "Source", col_types = cols("Species" = col_character())) %>%
  mutate(Source = str_remove(basename(Source), pattern="\\.csv")) %>%
  mutate(Species = Species %>%  
           str_remove_all("Ã¿") %>% #Resolve weird characters
           iconv(from = 'UTF-8', to = 'ASCII//TRANSLIT')%>% 
           str_remove_all("\\?") %>%
           str_remove_all("\\((.*?)\\)") %>% # remove things between brackets ie: Hygromia (Hygromia) cinctella
           str_squish() # remove excess whitespace
         ) %>%
  filter(str_count(Species, " ") > 0 ) %>% #Remove non-binomial 
  separate(Species, into=c("Genus", "Species"), sep=" ", extra="merge") %>% # Fix duplicated genus names
  mutate(Species = str_remove(Species, pattern=Genus) %>% str_squish()) %>%
  unite(col=Species, Genus, Species, sep = " ") %>%
  unique()

# Map to OTT taxonomy ids
taxreturn::download_ott_taxonomy()
dat_resolved <- dat %>% mutate(Species = map_to_ott(Species, dir="ott3.2", from="ncbi", resolve_synonyms=TRUE, filter_bads=TRUE, remove_na = TRUE, quiet=FALSE)) %>%
  filter(!is.na(Species))

lineage <- get_ott_lineage(dat_resolved$Species, dir="ott3.2")  %>%
  bind_cols(dat_resolved) %>% 
  select(-Species)%>%
  rename_all(funs(str_to_sentence(.))) %>%
  filter(Class=="Insecta") %>%
  drop_na()

#Write out final list of pests 
write_csv(lineage, "primer_evaluation/pestlist.csv")
```

## Figure 1

```{r Figure 1}
lineage <- read_csv(
  "primer_evaluation/pestlist.csv",
  col_types  = cols(
  Acc = col_character(),
  Kingdom = col_character(),
  Phylum = col_character(),
  Class = col_character(),
  Order = col_character(),
  Family = col_character(),
  Genus = col_character(),
  Species = col_character(),
  Source = col_character()
)) %>%
  unique()

# Fig 1a - Upset plot of species share between the different databases

sources <- as.character(unique(lineage$Source))
upsetlist <- list()
for (i in 1:length(sources)){
  upsetlist[[i]]= lineage$Species[which(lineage$Source==sources[i])] 
  names(upsetlist)[[i]] <- sources[i]
}

Fig1a <- upset(fromList(upsetlist),nsets=length(upsetlist), order.by = "freq")
print(Fig1a)

## Figure 1b - summary of families within the dataset 

library(RColorBrewer)
col <- colorRampPalette(brewer.pal(11, "Spectral"))(10)

Fig1b <- group_by(lineage, Order, Source) %>%
  summarise(Genus = n_distinct(Genus), Species = n_distinct(Species)) %>%
  ungroup() %>%
  mutate(Order = fct_reorder(Order, -Species)) %>% 
  ggplot(aes(x = Order, y = Species, fill = Source)) +
  geom_bar(stat = "identity")  +
  theme_pubr() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1,vjust=0)) +
  scale_fill_manual(values=col) +
  ylim(-500,2500) +
  theme_minimal() +
  theme(
    axis.text = element_blank(),
    axis.title = element_blank(),
    panel.grid = element_blank(),
    plot.margin = unit(rep(-1,4), "cm")      # Adjust the margin to make in sort labels are not truncated!
  ) +
  coord_polar(start=0) +
  geom_text(data = . %>%
              dplyr::select(Order, Species) %>%
              group_by(Order) %>%
              summarise(value = sum(Species)),
            aes(x=Order, y=value + 20, label=Order),
            color="black", fontface="bold", alpha=0.6, inherit.aes = FALSE)

# Summaries for article text

# Unique taxa
lineage %>% 
  #select(-Source, Acc) %>%
  summarise(Species = n_distinct(Species),
            Genus = n_distinct(Genus),
            Family = n_distinct(Family),
            Order = n_distinct(Order),
            )

# Sum of reference DB's
lineage %>% 
  group_by(Source) %>%
  summarise(Species = n_distinct(Species)) %>%
  arrange(Species)

# Proportion of sequences unique
lineage %>%
  add_count(Source, name = "DB_total") %>%
  group_by(Species) %>%
  add_tally(name = "n_occurances") %>%
  ungroup() %>%
  filter(n_occurances==1) %>%
  group_by(Source, DB_total)%>%
  summarise(n = n_distinct(Species)) %>%
  mutate(freq = n / DB_total)%>%
  arrange(freq)
```

# Primer info

```{r primer binding and constraints}
#alignment was then manually curated in geneious primer
folmer_curated <-  ape::read.dna("reference/Folmer_insecta_fullength_withprime_curated.fa",format="fasta")
model <- aphid::derivePHMM(folmer_curated)

# Be worth validating how the score is calculated?
primers <- read_csv("primer_evaluation/primer_candidates.csv") %>%
  select(name, strand, seq, citation, issues) %>%
  left_join(.$seq %>% purrr::map(get_binding_position, model, tryrc = TRUE, minscore=8) %>%
  bind_rows() %>%
  rename(seq = primer), by="seq") %>%
  unique()

primers <- primers %>%
  left_join(.$seq %>%
  purrr::map_df(get_primer_statistics, metrics="all", disambiguate=TRUE))

write_csv(primers, "primer_evaluation/primer_candidates.csv")
```

## Primer Presence in seqs

```{r check pres}
primerHits <- function(primer, fn, max.mismatch=0, with.indels=FALSE) {
      if(stringr::str_detect(primer, "I")) {
        message(paste0("Warning: Inosine (I) bases detected in primer ", primer," these will be converted to N!"))
        primer <- primer %>% str_replace_all("I", "N")
        }
    # Counts number of sequences in which the primer is found
    nhits <- vcountPattern(primer, sread(readFasta(fn)), max.mismatch=max.mismatch, fixed = FALSE, with.indels = with.indels)
    return(sum(nhits > 0))
}

primers <- read_csv("primer_evaluation/primer_candidates.csv") 

fn="reference/merged_final.fa.gz"

out <- vector("list", length=nrow(primers))
for (i in 1:nrow(primers)){
  
  if(primers$strand[i] == "F"){
    query <- primers$seq[i]
    
  } else  if(primers$strand[i] == "R"){
    query <- rc(primers$seq[i])
  }
  print(i)
  df <- tibble(
    name = primers$name[i],
    primer = query,
    strand = primers$strand[i],
    #Hamming distance (no indels in COI)
    h0 = primerHits(query, fn, max.mismatch=0, with.indels=FALSE),
    h1 = primerHits(query, fn, max.mismatch=1, with.indels=FALSE),
    h2 = primerHits(query, fn, max.mismatch=2, with.indels=FALSE),
  )
  out[[i]] <- df
}

names(out) <- primers$seq
out <- bind_rows(out)
write_csv(out, "primer_evaluation/primer_presence.csv")

# Plotting
out <- read_csv("primer_evaluation/primer_presence.csv")

gg.primerpresF <- out %>% 
  pivot_longer(cols=starts_with(c("h", "l")),
               names_to = "measure",
               values_to = "seqs"
               ) %>%
  left_join(primers) %>%
  filter(strand=="F", measure=="h2") %>%
  mutate(name = fct_reorder(name, start, .desc = TRUE)) %>%
  ggplot(aes(x=name, y=seqs)) + 
  geom_bar(stat="identity", position="dodge") +
  coord_flip() + 
  xlab("Forward Primers")

gg.primerpresR <- out %>% 
  pivot_longer(cols=starts_with(c("h", "l")),
               names_to = "measure",
               values_to = "seqs"
               ) %>%
  left_join(primers) %>%
  filter(strand=="R", measure=="h2") %>%
  mutate(name = fct_reorder(name, start, .desc = TRUE)) %>%
  ggplot(aes(x=name, y=seqs)) + 
  geom_bar(stat="identity", position="dodge") +
  coord_flip() + 
  xlab("Reverse Primers")

gg.primerpresF / gg.primerpresR
```

# Primer placement

## Create alignment
```{r Align}
model <- readRDS("reference/folmer_fullength_model.rds")

seqs <- insect::readFASTA("reference/merged_final.fa.gz")
lengthfilt <- taxreturn::map_to_model(seqs, model, minscore = 400, shave= TRUE, pad=TRUE, check_indels=TRUE, maxNs=Inf, cores=47, quiet=FALSE)

#write out results
insect::writeFASTA(lengthfilt, "reference/merged_final_aligned.fa.gz", compress=TRUE)

## NOTE - need to double check why there are different lenght seqs. How is it handling big deletions
table(lengths(seqs))
test <- seqs[lengths(seqs)==692]
writeFASTA(test, "cicadelidae_deletion_seqs.fa")

# Get whole alignment entropy
lengthfilt <- insect::readFASTA("reference/merged_final_aligned.fa.gz")

ent <- taxreturn::alignment_entropy(lengthfilt, maskgaps=1, countgaps=FALSE, method="ML", unit="log")
values <- as.data.frame(ent, stringsAsFactors=FALSE) %>%
  rownames_to_column("pos") %>%
  magrittr::set_colnames(c("pos", "value"))

write_csv(values, "primer_evaluation/whole_alignment_entropy.csv")
```

## Entropy by order
```{r subsetting}
## Read in aligned & Subset to only fullength
seqs <- insect::readFASTA("reference/merged_final_aligned.fa.gz")
seqs <- seqs[lengths(seqs)==712]

# querylevel
queryrank <- "order"

# Get unique querieranks
queries <- names(seqs)  %>% 
  str_split_fixed(";", n = 8) %>% 
  as_tibble() %>% 
  magrittr::set_colnames(c("acc", "kingdom", "phylum",
                           "class", "order", "family", 
                           "genus", "species")) %>%
  filter(class=="Insecta") %>%
  pull(queryrank) %>%
  unique()

#Make lists to store everything
entlist <- vector("list", length=length(queries))
names(entlist) <- queries

for (i in 1:length(queries)){
  print(i)
  query <- queries[i]
 print(query)
  names <- names(seqs)  %>% 
  str_split_fixed(";", n = 8) %>% 
  as_tibble() %>% 
  magrittr::set_colnames(c("acc", "kingdom", "phylum",
                           "class", "order", "family", 
                           "genus", "species")) %>%
    filter_at(vars(queryrank), any_vars(.== query)) %>%
    unite(names,everything(),sep=";")
  
  subset <- seqs[names(seqs) %in% names$names]
  if (length(subset) > 0){
    nseqs <- length(subset)
    message(nseqs, " sequences for ", query)
    
    # Get entropies
    ent <- taxreturn::alignment_entropy(as.list(subset), maskgaps=1, countgaps=FALSE, 
                                        method="ML", unit="log")
    entlist[[i]] <- as.data.frame(ent, stringsAsFactors=FALSE) %>%
      rownames_to_column("pos") %>%
      magrittr::set_colnames(c("pos", "value")) %>%
      mutate(nseqs = nseqs)
      }
}

ent_out <- bind_rows(entlist, .id="names")
write_csv(ent_out,paste0("primer_evaluation/", queryrank,"_ent_out.csv"))

```

## Figure 2
```{r entropy}
# Read in results
values <- read_csv("primer_evaluation/order_ent_out.csv") %>% 
  filter(nseqs > 20) # Filter to only those above 20 seqs

#Set moving average function - Adjust smoothing (n=5?)
ma <- function(x, n=3){stats::filter(x, rep(1/n, n), sides=2)}

ent <- values %>%
  mutate(value = value %>% 
           na_if("") %>%
           replace_na(0)) %>%
  mutate(ma = ma(value, n = 3)) %>%
  mutate(annot = case_when(
    pos %in% seq(from=1, to=2, by=1) ~ "Loop 0",
    pos %in% seq(from=3, to=78, by=1) ~ "Helix 1",
    pos %in% seq(from=79, to=103, by=1)~ "Loop 1-2",
    pos %in% seq(from=104, to=211, by=1)~ "Helix 2",    
    pos %in% seq(from=212, to=235, by=1)~ "Loop 2-3",   
    pos %in% seq(from=213, to=304, by=1)~ "Helix 3", 
    pos %in% seq(from=305, to=373, by=1)~ "Loop 3-4", 
    pos %in% seq(from=374, to=466, by=1)~ "Helix 4", 
    pos %in% seq(from=467, to=499, by=1)~ "Loop 4-5", 
    pos %in% seq(from=500, to=598, by=1)~ "Helix 5", 
    pos %in% seq(from=599, to=634, by=1)~ "Loop 5-6", 
    pos %in% seq(from=635, to=712, by=1)~ "Helix 6", 
  )) %>%
  mutate(structure = case_when(
    str_detect(annot, "Helix") ~ "Helix",
    str_detect(annot, "Loop") ~ "Loop",
  ))  

## plot entropy by order
gg.line <- ent %>%
  group_by(pos) %>%
  mutate(median = median(ma)) %>%
  ggplot(aes(x = pos, y=ma, colour=names)) + 
  geom_line(aes(x = pos, y=ma),size=1, inherit.aes = FALSE) +
  facet_wrap(~names)

# Plot entropy of COI Gene
gg.box <- ent %>%
  group_by(pos) %>%
  mutate(median = median(ma)) %>%
  ggplot(aes(x = pos, y=ma, group=pos, colour=structure)) + 
  geom_boxplot(outlier.shape = NA, alpha=0.8) +
  geom_line(aes(x = pos, y=median),size=1, inherit.aes = FALSE) + #, colour="black"
  #?geom_tufteboxplot(median.type = "point", whisker.type = "line", hoffset = 0) +
  theme_classic() +    
  theme(legend.position = "bottom") +
  ylab("Entropy") +
  xlab("Position within COI folmer region") +
  scale_color_manual(values=c("#ca0020", "#0571b0")) +
  scale_x_continuous(limits = c(0, 712), breaks=seq(0,700,50), expand=c(0,0)) 

# Sliding window of entropy
sw <- function(x, width, interval = 1){
  win <- seq(1,  length(x) - width, by = interval) #Get all possible windows
  out <- vector("numeric", length=length(x))
  for(i in 1:length(win)){
  out[[i]] <- sum(x[win[i]:(win[i] + width)])
  }
  out[out==0] <- NA
  return(out)
}

ent_sw <- values %>%
  group_by(names) %>%
  mutate(sw220 = sw(value, width=220, interval = 1)/220) %>%
  mutate(sw420 = sw(value, width=420, interval = 1)/420) %>%
  mutate(sw20 = sw(value, width=20, interval = 1)/20) %>% #For primers
  ungroup()%>%
  pivot_longer(starts_with("sw"),
               names_to = "windowsize",
               values_to = "sw") 

gg.density <-  ent_sw %>%
  dplyr::rename(Order = names) %>%
  mutate(Order = case_when(
     Order %in% c("Coleoptera", "Diptera", "Hemiptera", "Hymenoptera", "Lepidoptera") ~ Order,
    !Order %in% c("Coleoptera", "Diptera", "Hemiptera", "Hymenoptera", "Lepidoptera") ~ "Other"
    )) %>%
  ggplot(aes(x = pos, y=1)) +
    geom_tile(aes(fill=sw))+
    scale_fill_viridis_c(option="plasma") + 
  facet_wrap(windowsize~Order, ncol=1, strip.position ="right") +
  scale_x_continuous(limits = c(0, 712), breaks=seq(0,700,50), expand=c(0,0))  +
  theme_void() +
  theme(legend.position = "bottom",
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank())


## Primers
primers <- read_csv("primer_evaluation/primer_candidates.csv")

Fprimerpos <- seq(1,nrow(primers %>% filter(strand=="F")),1)/1000
Rprimerpos <- seq(1,nrow(primers %>% filter(strand=="R")),1)/1000

gg.primers <- ggplot(data=values[values$pos==1,], aes(x = as.numeric(pos))) +
  geom_segment(data = primers %>% filter(strand=="F"),
               aes(x = start, xend = end,
                   y = Fprimerpos, yend = Fprimerpos,
                   colour=strand), size = 1, arrow = arrow(length = unit(0.3,"cm")),
               show.legend = FALSE) +
  geom_text(data = primers %>% filter(strand=="F"),
            aes(x = start, y = Fprimerpos,
                label = name , colour=strand),
            hjust = 1, show.legend = FALSE) +
  geom_segment(data = primers %>% filter(strand=="R"),
               aes(x = end, xend = start,
                   y = Rprimerpos, yend = Rprimerpos,
                   colour=strand), size = 1,
               arrow = arrow(length = unit(0.3,"cm")),
               show.legend = FALSE) +
  geom_text(data = primers %>% filter(strand=="R"),
            aes(x = end, y = Rprimerpos,
                label = name, colour=strand),
            hjust = 0, show.legend = FALSE)  +
  scale_x_continuous(limits = c(0, 712), breaks=seq(0,700,50), expand=c(0,0)) +
  theme_classic()  +
  theme(legend.position = "none",
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank())

Fig2 <- gg.box / gg.density / gg.primers 
```

## Predicted mismatch
Need to load the aligned Database so the N's are there

Code modified from: Bylemans J, Gleeson DM, Hardy CM, Furlan E. Toward an ecoregion scale evaluation of eDNA metabarcoding primers: A case study for the freshwater fish biodiversity of the Murray-Darling Basin (Australia). Ecol Evol. 2018;8697â712. 

```{r Primerminer, message=FALSE}
library(PrimerMiner)
## Target sequences to test against
target <- "reference/merged_final_aligned.fa.gz"

# Load primers
primers <- read_csv("primer_evaluation/primer_candidates.csv") %>%
  mutate(seq = str_replace_all(seq, "I","N")) %>% 
  select(-score, -issues)

dir.create("primer_evaluation/PrimerMiner")

for (i in 1:nrow(primers)) {
  if(primers$strand[i]=="F"){
  evaluate_primer(target,
   as.character(primers$seq[i]), primers$start[i], primers$end[i],
   forward = TRUE, gap_NA = TRUE, N_NA=TRUE,
   mm_position = "Position_v1", mm_type = "Type_v1", adjacent = 2,
   save = paste0("primer_evaluation/PrimerMiner/", primers$name[i],".csv")
  )
  } else if(primers$strand[i]=="R"){
  evaluate_primer(target,
   as.character(primers$seq[i]), primers$start[i], primers$end[i],
   forward = FALSE, gap_NA = TRUE, N_NA=TRUE,
   mm_position = "Position_v1", mm_type = "Type_v1", adjacent = 2,
   save = paste0("primer_evaluation/PrimerMiner/", primers$name[i],".csv")
  )
 }
}

```

## Figure 3

```{r figure 4}
#Read in all files
files <- sort(list.files(list.dirs("primer_evaluation/PrimerMiner/"), pattern = ".csv", full.names = TRUE))

dat <- files %>% 
  purrr::set_names() %>%
  map_dfr(read_csv, col_types= cols_only(Template=col_character(),
                                       sequ=col_character(),
                                       sum=col_double()),.id = "source", progress=TRUE) %>%
  separate(col=Template, into=c("Acc","Kingdom","Phylum","Class","Order","Family","Genus","Species"), sep=";") %>%
  rename(Sequence = sequ) %>%
  mutate(Primer = source %>%
           str_replace("primer_evaluation/PrimerMiner//","") %>%
           str_replace("\\/(.*?)$", ""))

summaries <- dat %>% 
  filter(Species %in% str_replace_all(read_csv("primer_evaluation/pestlist.csv")$Species, " ", "_")) %>%
  group_by(Kingdom, Phylum, Class, Order, Family, Genus, Species, Primer) %>%
  summarise(sum = mean(sum)) %>% # Summarise mean of species with multiple sequences
  ungroup()  %>%
  mutate(dir = case_when(
    Primer %in% unique(dat.passed$F.Name) ~ "Forward",
    Primer %in% unique(dat.passed$R.Name) ~ "Reverse"
    ))  %>%
  mutate(Primer = paste0(substr(dir,1,1)," ",Primer))

#Get taxonomic lineage and convert to tree
  lineage <- summaries %>%
     group_by(Kingdom, Phylum, Class, Order, Family, Genus, Primer) %>%
  summarise(sum = mean(sum)) %>% # Summarise mean of species with multiple sequences
    tidyr::unite(col=pathString, Kingdom, Phylum, Class, Order, Family, Genus, sep="/") %>%
    dplyr::mutate(pathString = paste0("Root/", pathString)) %>%
    data.tree::as.Node(.)


tree <- ape::read.tree(textConnection(data.tree::ToNewick(lineage, heightAttribute = NULL)))

library(ggtree)

test <- as_tibble(tree) %>%
  full_join(summaries %>%
  group_by(Kingdom, Phylum, Class, Order, Family, Genus) %>%
  summarise(mismatch = mean(sum)) %>%
    rename(label = Genus)) 

p <- ggtree(tidytree::as.treedata(test), aes(color=mismatch)) +
  geom_nodelab(geom='label') + # + geom_tiplab(align=TRUE) 
  theme_tree2()+
  scale_colour_gradient(low = "darkgreen", high = "red", limits = c(0, 200), oob = scales::squish) + 
  theme(legend.position = "none") +
      scale_y_continuous(expand=c(0,0))

gg.sum <- summaries %>%
  group_by(Kingdom, Phylum, Class, Order, Family, Genus, Primer, dir) %>%
  summarise(sum = mean(sum) ) %>% # Summarise mean of species with multiple sequences
  ungroup() %>%
  left_join(p$data %>%
  filter(isTip) %>%
    select(c(label, y)) %>%
    rename(Genus = label)) %>%
  filter(!is.na(y)) %>%
  ggplot(aes(x = Primer , y = factor(.$Genus, levels=unique(.$Genus[order(.$y)])) , fill = sum)) +
  geom_tile() +
  #scale_fill_viridis_c(option="magma",limits = c(0, 200))+
  scale_fill_gradient(low = "darkgreen", high = "red", na.value = "grey", limits = c(0, 200), oob = scales::squish) +
  facet_grid(~dir, scales="free", space="free", drop=TRUE) +
  theme_classic() + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.y = element_blank(),
    strip.text.y = element_text(angle = 0)
  ) 

p + gg.sum

```



# Identification sucess

In order to evaluate the taxonomic resolution of different barcode regions, alignments were trimmed to primer regions using the in silico PCR function from the insect package and  the identificaiton sucess functions from the SPIDER r package were used

Metrics to evaluate primers on:
 *  OTU clustering of each primer at different ranks, see drop off
 *  OTU clustering, subset to pests only (ie fraction of pests in their own cluster)
 *  Datasets subset to pest genera (or families), evaluated with spider nearNeighbour, BestCloseMatch, ThreshID, Monophyly
 * Leave one out BLAST/RDP?
 * P(LCR) for each primer?
 
 
## Virtual PCR
 
```{r Virtual PCR}
# Load seqs
seqs <- insect::readFASTA("reference/merged_final.fa.gz")

# Load primers
primers <- read_csv("primer_evaluation/primer_candidates.csv") %>%
  mutate(seq = str_replace_all(seq, "I","N")) %>% 
  select(-score, -issues)

# Get all possible primer combinations
combos <- expand_grid(primers %>% filter(strand=="F") %>% pull(seq),
                      primers %>% filter(strand=="R") %>% pull(seq)
                      ) %>%
  mutate_if(is.factor, as.character)%>%
  unique() %>%
  magrittr::set_colnames(c("Fseq", "Rseq")) %>%
  left_join(primers %>% filter(strand=="F") %>% rename_all(. %>% paste0("F",.)), by="Fseq") %>%
  left_join(primers %>% filter(strand=="R") %>% rename_all(. %>% paste0("R",.)), by="Rseq") %>%
  mutate(amplicon = Rstart - Fend) %>%
  filter( amplicon > 100)

dir.create("primer_evaluation/amplicons")
lengthlist <- vector("list", length=nrow(combos)) 

#TESTING!
seqs <- seqs[1:1000]
combos <- combos %>% dplyr::slice(1:3)

for (p in 1:nrow(combos)) {
  #get primer names
  primernames <- paste0(combos$Fname[p], "_",  combos$Rname[p])
  
  #Conduct virtualPCR
  amplicon <- virtualPCR(seqs, up = combos$Fseq[p],
                           combos$Rseq[p], rcdown = TRUE,
                             trimprimers = TRUE, partialbind =FALSE, 
                         minamplen = (combos$amplicon[p] - 9), maxamplen = (combos$amplicon[p] + 9), 
                         quiet = FALSE, cores=2)
  
  # write out sequences
  insect::writeFASTA(amplicon, file=paste0("primer_evaluation/amplicons/", primernames,".fa.gz"), compress=TRUE)  
  
  #write out sequence lengths
  lengthlist[[p]] <- as.data.frame(table(lengths(amplicon)), stringsAsFactors=FALSE) %>%
    magrittr::set_colnames(c("length", "freq"))

}
names(lengthlist) <- paste0(combos$Fname, "_",  combos$Rname)
lengthlist %>%
bind_rows(lengthlist,.id="names") %>%
  write_csv("primer_evaluation/amplicons/lengthlist.csv")
```
 
## Clustering ID Success
```{r clustering.R}
# load packages ---------------------------------------------------
.cran_packages <- c("tidyverse", "spider", "insect", "ape",
                    "seqinr", "ShortRead", "foreach", "doParallel")

.bioc_packages <- c("DECIPHER", "Biostrings")

#Load all packages
sapply(c(.cran_packages,.bioc_packages), require, character.only = TRUE)

# Github packages
library(taxreturn)


# get job name ---------------------------------------------------
args = commandArgs(trailingOnly=TRUE)

if (length(args)==0) {
  stop("At least one argument must be supplied (input file).n", call.=FALSE)
}
print(args)
file <- args[1]
job_name <- basename(file) %>% str_remove("\\..*$")
message("file = ", file)
message("job_name = ", job_name)

# Run code ---------------------------------------------------

#Get db
db <- taxreturn::get_ott_taxonomy(dir="ott3.2")

## TESTING
 file <- "primer_evaluation/amplicons/fwhF2_fwhR2n.fa.gz"
amplicon <- insect::readFASTA(file)
print(amplicon)
amplicon <- amplicon[1:1000]

## Get distance clustering statistic
thresholds <- rev(seq(0.99, 1, 0.01)) #Chagne to 90
threshlist <- vector("list", length=length(thresholds))

for (i in 1:length(thresholds)){
threshlist[[i]] <- taxreturn::get_mixed_clusters( 
 x = amplicon, db=db,
 rank = "species",
 threshold = thresholds[i],
 return = "all",
 confidence=0, quiet = FALSE) 
}
names(threshlist) <- thresholds 
dplyr::bind_rows(threshlist) %>%
  write_csv(paste0(job_name,"_clustering.csv"))
```

## get the good from clustering

```{r}
test <- get_mixed_clusters( 
  x = amplicon, db=db,
  rank = "species",
  threshold = 0.95,
  return = "all",
  confidence=0, quiet = FALSE) 

#Still would be better to create a table with out, with the columns:
# Cluster, #Accession, # Taxon

```


## Spider ID Sucess
```{r Spider}
# install and load packages ---------------------------------------------------
.cran_packages <- c("tidyverse", "spider", "insect", "ape",
                    "seqinr", "ShortRead", "foreach", "doParallel")

.bioc_packages <- c("DECIPHER", "Biostrings")

.inst <- .cran_packages %in% installed.packages()
if(any(!.inst)) {
   install.packages(.cran_packages[!.inst])
}
.inst <- .bioc_packages %in% installed.packages()
if(any(!.inst)) {
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install(.bioc_packages[!.inst], ask = F)
}

#Load all packages
sapply(c(.cran_packages,.bioc_packages), require, character.only = TRUE)

# Github packages
devtools::install_github("alexpiper/taxreturn")
library(taxreturn)


# get job name ---------------------------------------------------
args = commandArgs(trailingOnly=TRUE)

if (length(args)==0) {
  stop("At least one argument must be supplied (input file).n", call.=FALSE)
}
print(args)
file <- args[1]
job_name <- basename(file) %>% str_remove("\\..*$")
message("file = ", file)
message("job_name = ", job_name)

# Run code ---------------------------------------------------

# Load resources
model <- readRDS("folmer_fullength_model.rds")
pestlist <- read_csv("primer_evaluation/pestlist.csv")

## Read in seqs
seqs <- insect::readFASTA(file)

#Filter to pest genera and remove singletons
names <- names(seqs)  %>% 
  str_split_fixed(";", n = 8) %>% 
  as_tibble() %>% 
  magrittr::set_colnames(c("acc", "kingdom", "phylum",
                          "class", "order", "family", 
                          "genus", "species")) %>%
  filter(genus %in% pestlist$Genus)%>%
  group_by(species) %>%
  add_tally %>%
  filter(n > 1) %>%
  select(-n) %>%
 unite(names,everything(),sep=";") #%>%
  
subset <- seqs[names(seqs) %in% names$names]
print(subset)

# Testing
subset <- subset[1:1000]

# Map to model
lengthfilt <- taxreturn::map_to_model(subset, model, minscore = 100, shave= TRUE, pad=TRUE, check_indels=TRUE, maxNs=Inf, cores=2, quiet=FALSE)

# All should be same length, if not -warn and subset to most frequent value
seqLength <- lengths(lengthfilt)
uniqx <- unique(na.omit(seqLength))
if(length(uniqx) > 1) {message("Warning, more than one length in lengthfilt")}
freqlen <- uniqx[which.max(tabulate(match(seqLength, uniqx)))]
lengthfilt <- as.matrix(lengthfilt[which(seqLength == freqlen)])

# Genus and species names
aa <- Biostrings::strsplit(dimnames(lengthfilt)[[1]], split = ";")
Genus <- sapply(aa, function(x) paste(x[7], sep = "_"))
Spp <- sapply(aa, function(x) paste(x[8], sep = "_"))

# Create distance matrix
Dist <- dist.dna(lengthfilt, pairwise.deletion = TRUE)

# Nearest neighbour metric
nn <- tibble(
  query = labels(lengthfilt),
  Spp = Spp,
  result = nearNeighbour(Dist, Spp),
  nn_spp = enframe(nearNeighbour(Dist, Spp, names = TRUE)) %>% pull(value))
  
# Closematch metric
cm <- tibble(
  query = labels(lengthfilt),
  Spp = Spp,
  result99 = bestCloseMatch(Dist, Spp, threshold = 0.01),
  result98 = bestCloseMatch(Dist, Spp, threshold = 0.02),
  result97 = bestCloseMatch(Dist, Spp, threshold = 0.03),
  result96 = bestCloseMatch(Dist, Spp, threshold = 0.04),
  result95 = bestCloseMatch(Dist, Spp, threshold = 0.05))

cm_names <- tibble(
  query = labels(lengthfilt),
  Spp = Spp,
  names99 = bestCloseMatch(Dist, Spp, names = TRUE, threshold = 0.01),
  names98 = bestCloseMatch(Dist, Spp, names = TRUE, threshold = 0.02),
  names97 = bestCloseMatch(Dist, Spp, names = TRUE, threshold = 0.03),
  names96 = bestCloseMatch(Dist, Spp, names = TRUE, threshold = 0.04),
  names95 = bestCloseMatch(Dist, Spp, names = TRUE, threshold = 0.05)) 

cm_names <- cm_names %>%
  mutate(names99 = map(names99, ~set_names(., paste0("closematch99_",seq_along(.))))) %>%
  mutate(names98 = map(names98, ~set_names(., paste0("closematch98_",seq_along(.))))) %>%
  mutate(names97 = map(names97, ~set_names(., paste0("closematch97_",seq_along(.))))) %>%
  mutate(names96 = map(names96, ~set_names(., paste0("closematch96_",seq_along(.))))) %>%
  mutate(names95 = map(names95, ~set_names(., paste0("closematch95_",seq_along(.))))) %>%     
  unnest_wider(names99) %>%     
  unnest_wider(names98) %>%     
  unnest_wider(names97) %>%     
  unnest_wider(names96) %>%     
  unnest_wider(names95)

closematch <- dplyr::left_join(cm, cm_names, by=c("query", "Spp"))

# Monophyly metric
Tr <- nj(Dist)
maxInt <- max(Tr$edge.length[Tr$edge[, 2] > length(Tr$tip.label)])
nodeRoot <- Tr$edge[which(Tr$edge.length == maxInt), 2]
TrRoot <- root(Tr, node = nodeRoot, resolve.root = TRUE)
TrRoot$tip.label <- Spp
mono <- monophyly(TrRoot, Spp, singletonsMono = TRUE)

out <-  tibble(
  primer = job_name,
  Spp = Spp,
  query = dimnames(lengthfilt)[[1]],
  mono=mono[match(Spp, unique(Spp))]
) %>%
  left_join(nn, by=c("query", "Spp")) %>%
  left_join(closematch, by=c("query", "Spp")) 

out %>% 
  write_csv(paste0(job_name,"_spider.csv"))
```

## SLURM job submit

Index jobs
```{bash generate job index}
#!/bin/bash
/usr/bin/ls -d $PWD/* | sed -e '1p' -e '/.fa.gz/!d' | sort > sequence_index.txt
```

Submit array

njobs=$(cat sequence_index.txt | wc -l)
sbatch --array=1-808 submit_clustering.slurm
```{bash job script}
#!/bin/bash
#SBATCH --job-name=id_metrics       
#SBATCH --ntasks=1 
#SBATCH --cpus-per-task=8
#SBATCH --mem=80GB
#SBATCH --time=100:00:00
#SBATCH --mail-user=alexander.piper@agriculture.vic.gov.au
#SBATCH --account=pathogens
#SBATCH --export=none

#Check if job is launched as array
if [ -z "$SLURM_ARRAY_TASK_COUNT" ]; then 
  echo SLURM_ARRAY_TASK_COUNT unset; 
  echo You must launch this job as an array
  echo see https://slurm.schedmd.com/job_array.html
  echo for info on how to run arrays
  exit 1
fi

Index=sequence_index.txt

# Make sure that sequence index file is there before we do anything
if [[ ! -f "${Index}" ]]; then
  echo "Error sequence index file ${Index} does not exist"
  exit 1
fi

#Gather info on our samples
FullSampleName=$(sed -n ${SLURM_ARRAY_TASK_ID}p ${Index})
SequencePath=$(dirname ${FullSampleName})
Sample=$(basename ${FullSampleName} .fa.gz)

# Double check that array index is valid
if [[ ! -f "${FullSampleName}" ]]; then
  echo "Error array index doesnt match up with index file"
  echo "Array index is  ${SLURM_ARRAY_TASK_ID}"
  exit 1
fi

# Goto tmp to do our working out
cd $TMPDIR

#Copy data files, database and decompress all
cp ${SequencePath}/${FullSampleName}* .
cp ${SequencePath}/clustering.R .
cp ${SequencePath}/spider.R .
cp -r ${SequencePath}/ott3.2 .
cp ${SequencePath}/folmer_fullength_model.rds .
cp ${SequencePath}/pestlist.csv .

#Decompress all
pigz -p8 -d ./*.gz

#Load modules
module purge
module load R

#Run clustering R script and send sample name to it
Rscript clustering.R $FullSampleName

#Run spider R script and send sample name to it
Rscript spider.R $FullSampleName

# Output useful job stats
/usr/local/bin/showJobStats.scr | gzip > ${Sample}-jobstats.gz

#Make an output directory
mkdir output
cp ./*_clustering.csv output
cp ./*_spider.csv output
cp ./*-jobstats.gz output

# put all output files back where we started
cp -r output ${SLURM_SUBMIT_DIR}
```
 
 
 # Clustering - need to write out results as RDS, or can i do it in a way that doesnt require masses of NA's
 Actually all the mixed should be in the cluster ID anyway?
 # Write out summaries as CSV?
  
  Only go from 1 to 0.95 as well?
  
  This function requires a bit of a rewrite before running again
  Need an option to just return all mixed clusters, pivoting longer?
  
  Options: return = suggested, or return=all

## Figure 4

```{r figure 3}
mixed_clusters <- vroom::vroom("primer_evaluation/amplicons/output/fwhF2_C_LepFolR_clustering.csv", delim=",")


#summarise overall numbers at each value
mixed_clusters %>% group_by(threshold) %>% summarise(n=n())

# SUmmarise number of mixed clusters that contain pests at %
pestlist <- read_csv("primer_evaluation/pestlist.csv") 

mixed_clusters %>% filter(listed %in% pestlist$Species) %>% group_by(threshold) %>% summarise(n=n())

#Read back in data:
vec <- sort(list.files("primer_evaluation/amplicons/", pattern = ".csv", full.names = TRUE)) # Read fasta filenames


id_summary <- vec %>%
  purrr::set_names() %>%
  purrr::map_dfr(read_csv, .id = "Source")
  
pestlist <- read_csv("primer_evaluation/pestlist.csv") %>%
  mutate(Species = str_replace_all(Species, " ", "_"))

#summarise for all taxa 

# Could probably left_join to the lineage data, and then summarise by genus/ family etc
all_sum <- id_summary %>%
  dplyr::group_by(primer) %>%
  dplyr::summarise(amplified=n(), 
                   nn_true = sum(nn==TRUE),
                   nn_false = sum(nn==FALSE),
                   cm_ambiguous=sum(result=="ambiguous"),
                   cm_incorrect=sum(result=="incorrect"),
                   cm_correct=sum(result=="correct"),      
                   cm_noid=sum(result=="no id"),
                   mono_true=sum(mono==TRUE),
                   mono_false=sum(mono==FALSE))%>% 
  gather(key="measure", value="value", -primer) %>%
  mutate(dataset="all")



pest_sum <- id_summary %>%
  filter(Spp %in% str_replace_all(read_csv("primer_evaluation/pestlist.csv")$Species, " ", "_")) %>%
  rename(Species = Spp) %>%
  left_join(read_csv("primer_evaluation/pestlist.csv") %>%
              dplyr::select(-Source) %>%
              mutate(Species = str_replace_all(Species, " ", "_")),
            by="Species") #%>%
  group_by(Class, Order, Family, Genus, primer) %>%
  dplyr::summarise(amplified = n(),
                   nn = sum(nn==TRUE),
                   mono = sum(mono==TRUE),
                   cm = sum(result=="correct") + sum(result=="no id")) %>%
  dplyr::mutate(
    nn = nn / amplified,
    mono = mono / amplified,
    cm = cm / amplified
  ) #%>%
  select(-amplified) %>%
  ungroup() %>%
  pivot_longer(cols=nn:cm,
               names_to="measure",
               values_to="value")
  
  
#Get taxonomic lineage and convert to tree

library(ggtree)

test <- as_tibble(tree) %>%
  full_join(pest_sum  %>%
    rename(label = Genus)) 

p <- ggtree(tidytree::as.treedata(test)) +
  geom_nodelab(geom='label') + # + geom_tiplab(align=TRUE) 
  theme_tree2() #+
  scale_colour_gradient(low = "darkgreen", high = "red",  oob = scales::squish) + 
  theme(legend.position = "none") +
      scale_y_continuous(expand=c(0,0))
  

  
  
gg.ident <- pest_sum %>%
  left_join(p$data %>%
  filter(isTip) %>%
    select(c(label, y)) %>%
    rename(Genus = label)) %>%
  filter(!is.na(y)) %>%
  ggplot(aes(x = primer , y = factor(.$Genus, levels=unique(.$Genus[order(.$y)])) , fill = value)) +
  geom_tile() +
  #scale_fill_viridis_c(option="magma",limits = c(0, 200))+
  scale_fill_gradient(low = "red", high = "darkgreen", na.value = "grey", limits = c(0, 1), oob = scales::squish) +
  facet_grid(~measure) +
  theme_classic() + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.title.y = element_blank(),
    strip.text.y = element_text(angle = 0)
  ) 

p + gg.ident  
  

#Join datasets

p1 <- ggplot(all_sum[which(all_sum$measure == "cm_ambiguous" | all_sum$measure == "cm_correct" | all_sum$measure == "cm_incorrect" |  all_sum$measure == "cm_noid" ),])+
  geom_bar(aes(x=primer,y=value,fill=measure),stat="identity", position="stack") +
  facet_wrap(~dataset,scales="free_y")+ 
  theme(axis.text.x = element_text(angle=90,hjust=1,vjust=0.5))+
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank())

p2 <- ggplot(all_sum[which(all_sum$measure == "mono_true" | all_sum$measure == "mono_false"),])+
  geom_bar(aes(x=primer,y=value,fill=measure),stat="identity", position="stack") +
  facet_wrap(~dataset,scales="free_y") + 
  theme(axis.text.x = element_text(angle=90,hjust=1,vjust=0.5))+
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank())

p3 <- ggplot(all_sum[which(all_sum$measure == "nn_true" | all_sum$measure == "nn_false"),])+
  geom_bar(aes(x=primer,y=value,fill=measure),stat="identity", position="stack") +
  facet_wrap(~dataset,scales="free_y") + 
  theme(axis.text.x = element_text(angle=90,hjust=1,vjust=0.5))

Fig3a <- p1 / p2 / p3 


#failed 

pest_fail <- pests[which(pests$primer =="fwhF2-fwhR2n" & pests$mono.match.Spp..unique.Spp... == "FALSE" | pests$nearNeighbour.Dist..Spp. == "FALSE" | pests$primer =="fwhF2-fwhR2n" & pests$V1 == "incorrect"),]
length(unique(pest_fail$Spp))

#All taxa which failed 
all_fail <- id_summary[which(id_summary$primer =="fwhF2-fwhR2n" & id_summary$mono.match.Spp..unique.Spp... == "FALSE" | id_summary$nearNeighbour.Dist..Spp. == "FALSE" | id_summary$primer =="fwhF2-fwhR2n" & id_summary$V1 == "incorrect"),]
length(unique(all_fail$Spp))

# Failed pest taxa were manually inspected, many of these were incorrectly annotated taxonomy, or synonyms
#The groups that are unlikely to work with any of these primers include:

```


# Off-target amplification
First identify all sequences that have homology to both forward and reverse primers, with the hit sequences placed so that they can actually form a PCR product. 
First perform a blast search for each primer individually against NT database (or can you do a kmer search with BBDUK?)
Get accession numbers, get taxonomy for accession numbers
then compare the lists for forward and reverse primers.
Any accession number that occurs in both lists needs to be investigated as a potential cross-reacting sequence
Get taxonomy for all cross reactign sequences, filter to those that are not insecta
Retrieve all sequences for cross reacting, make new database from those
Then do in-silico PCR with insect and count how many successfully amplify

```{r off target}
dir.create("primer_evaluation/off_target")
# Load primers
primers <- read_csv("primer_evaluation/primer_candidates.csv") %>%
  mutate(seq = str_replace_all(seq, "I","N")) %>% 
  mutate(seq =case_when(
    strand=="F" ~ seq,
    strand=="R" ~ rc(seq) #Works without RC but RC seems faster
  )) 

# Disambiguate primers and write out individuals
seqs <- DECIPHER::Disambiguate(DNAStringSet(primers$seq))
names(seqs) <- primers$name

for (i in 1:length(seqs)){
  out <- unlist(seqs[i])
  names(out) <- make.unique(names(out), sep="_")
  writeXStringSet(out, paste0("primer_evaluation/off_target/",names(out[1]),".fa"))
}


# Get all possible primer combinations
combos <- expand_grid(primers %>% filter(strand=="F") %>% pull(seq),
                      primers %>% filter(strand=="R") %>% pull(seq)
                      ) %>%
  mutate_if(is.factor, as.character)%>%
  unique() %>%
  magrittr::set_colnames(c("Fseq", "Rseq")) %>%
  left_join(primers %>% filter(strand=="F") %>% rename_all(. %>% paste0("F",.)), by="Fseq") %>%
  left_join(primers %>% filter(strand=="R") %>% rename_all(. %>% paste0("R",.)), by="Rseq") %>%
  mutate(amplicon = Rstart - Fend) %>%
  filter( amplicon > 100) %>%
  mutate(synthetic = paste0(Fseq,"-", rc(Rseq) )) 

# Write out all combos - takes a while due to extremely high degeneracy!
for(i in 1:nrow(combos)){
  print(i)
  out <- DECIPHER::Disambiguate(DNAStringSet(combos$synthetic[i]))
  names(out) <- paste0(combos$Fname[i], "_",  combos$Rname[i])
  out <- unlist(out)
  # Pad with 20 N's
  out <- DNAStringSet(sapply(out, str_replace_all, pattern= "-", replacement="NNNNNNNNNNNNNNNNNNNN"))
  
  names(out) <- make.unique(names(out), sep="_")
  writeXStringSet(out, paste0("primer_evaluation/off_target/", names(out[1]),".fa"))
}

# For the combos should i just take a random sample of 1000? as this is pretty ridiculous

```

See primerblast paper:

To evaluate specificity, artificial search sequences were generated by concatenating both primer sequences with a 20 base spacer. This ensures that each primer will be treated separately in the BLAST search and thus achieves the equivalent effect of performing a separate BLAST search for each primer. To create a database of potential non-target sequence ampliciations These artificial sequences as well as just the forward and reverse primers were searched against the local NCBI nr database using BLASTn

From primerserver code : https://github.com/billzt/PrimerServer/blob/master/script/_run_specificity_check.pl
blastn -task blastn-short -query $query_file -db $db_file -evalue 30000 "
                    ." -word_size 7 -perc_identity60 -dust no -ungapped -reward 1 -penalty -1 "
                    ." -max_hsps 500 -outfmt '6 qseqid qstart qend sseqid sstart send sstrand' "
                    ." -out $query_file.$db_name.out -num_threads $run_cpu";


Index jobs
```{bash generate job index}
#!/bin/bash
/usr/bin/ls -d $PWD/*.fa | sort > sequence_index.txt
```

Submit array

njobs=$(cat sequence_index.txt | wc -l)
sbatch --array=1-1 primerblast.slurm

## BLAST
```{bash blast}
#!/bin/bash
#SBATCH --job-name=BLASTn       
#SBATCH --ntasks=1 
#SBATCH --cpus-per-task=8
#SBATCH --mem=50GB
#SBATCH --time=240:00:00
#SBATCH --mail-user=alexander.piper@agriculture.vic.gov.au
#SBATCH --account=pathogens
#SBATCH --export=none

#Check if job is launched as array
if [ -z "$SLURM_ARRAY_TASK_COUNT" ]; then 
  echo SLURM_ARRAY_TASK_COUNT unset; 
  echo You must launch this job as an array
  echo see https://slurm.schedmd.com/job_array.html
  echo for info on how to run arrays
  exit 1
fi
Index=sequence_index.txt

# Make sure that sequence index file is there before we do anything
if [[ ! -f "${Index}" ]]; then
  echo "Error sequence index file ${Index} does not exist"
  exit 1
fi

#Gather info on our samples
BlastDB=/group/blastdb/nt
FullSampleName=$(sed -n ${SLURM_ARRAY_TASK_ID}p ${Index})
SequencePath=$(dirname ${FullSampleName})
Sample=$(basename ${FullSampleName} .fa)

# Double check that array index is valid
if [[ ! -f "${FullSampleName}" ]]; then
  echo "Error array index doesnt match up with index file"
  echo "Array index is  ${SLURM_ARRAY_TASK_ID}"
  exit 1
fi

# Goto tmp to do our working out
cd $TMPDIR

#Copy data files, database and decompress all
cp ${SequencePath}/${Sample}.fa .
#pigz -p8 -d ./*.gz

#Load modules
module purge
module load BLAST+

###START###

echo ${BlastDB}
echo ${Sample}
date

blastn -task blastn-short \
-query ${Sample}.fa \
-db  ${BlastDB} \
-out ${Sample}.out \
-evalue 30000 \
-perc_identity 60 \
-word_size 7 \
-dust no \
-ungapped \
-reward 1 \
-penalty -3 \ #Watch this
-max_hsps 100000 \
-outfmt '6 qseqid qstart qend sseqid staxid sstart send sstrand' \
-num_threads 8

# Output useful job stats
/usr/local/bin/showJobStats.scr | gzip > ${Sample}-jobstats.gz

#Make a directory call ${Sample} and cp all output files into that directory
mkdir ${Sample}_output
cp ./*.out ${Sample}_output
cp ./*-jobstats.gz ${Sample}_output

date

# put all output files back where we started
cp -r ${Sample}_output ${SLURM_SUBMIT_DIR}
```


Note: Detailed information about installing and running PrimerTree can be found at https://github.com/jimhester/primerTree

Could use a slurm array to submit each seperately with all combinatons. 
Also worth having a function to count degeneracy for the constraints section
```{r off target}
primers <- read_csv("primer_evaluation/primer_candidates.csv")
library(primerTree)



forward <- "GGDRCWGGWTGAACWGTWTAYCCNCC"
rev <- "TATDGTRATDGCHCCNGC"

test <- search_primer_pair(
  forward,
  rev,
  api_key ="1c0a0c4afa28448650a1450662a22c68f208",
  num_permutations = 20
)
ranks = c("kingdom", "phylum", "class", 
    "order", "family", "genus", "species")

lineage <- test3[["taxonomy"]] %>%
  select(all_of(ranks))%>% 
  tidyr::unite(col = pathString, 
  !!ranks, sep = "/") %>%
  dplyr::mutate(pathString = paste0("Root/", pathString)) %>%
  data.tree::as.Node(.)

tree <- ape::read.tree(textConnection(data.tree::ToNewick(lineage, heightAttribute = NULL)))

library(ggtree)

ggtree(tree)


dir.create("PrimerTree")
#for (i in 1:nrow(dat.I)) {
  assign(paste("PT", dat.I$Name[i], sep = "."), search_primer_pair(name = dat.I$Name[i], dat.I$F.seq[i], dat.I$R.seq[i], num_permutations = 50, num_aligns = 1000))
  saveRDS(paste("PT", dat.I$Name[i], sep = "."),paste0("PrimerTree/PT.",dat.I$Name[i],".rds"))
}
#, clustal_options = c(exec='clustal-omega-1.2.2-win64/clustalo.exe')

# 3.2. - Inspect the sequence length distribution for each primer pair and remove any sequence records with a length deviating from the
#        majority of the sequences.

#Below code requires clustal files in R install directory

seq_lengths(`PT.AgPestF1-AgPestR1a`) # No obvious outliers
`PT.AgPestF1-AgPestR1a` <- filter_seqs(`PT.AgPestF1-AgPestR1a`, min_length = 200)

seq_lengths(`PT.AgPestF2-AgPestR2`) # No obvious outliers
`PT.AgPestF2-AgPestR2` <- filter_seqs(`PT.AgPestF2-AgPestR2`, min_length = 200)

seq_lengths(`PT.fwhF2-fwhR2n`) # No obvious outliers
`PT.fwhF2-fwhR2n` <- filter_seqs(`PT.fwhF2-fwhR2n`, min_length = 200)

seq_lengths(`PT.SauronS878-BR1`) # No obvious outliers
`PT.SauronS878-BR1` <- filter_seqs(`PT.SauronS878-BR1`, min_length = 200)

#Plot trees
t1 <- plot(`PT.AgPestF1-AgPestR1a`, ranks='class', main='PT.AgPestF1-AgPestR1a', rotate=45, size=1)
t2 <- plot(`PT.AgPestF2-AgPestR2`, ranks='class', main='PT.AgPestF2-AgPestR2', rotate=45, size=1)
t3 <- plot(`PT.fwhF2-fwhR2n`, ranks='class', main='PT.fwhF2-fwhR2n', rotate=45, size=1)
t4 <- plot(`PT.SauronS878-BR1`, ranks='class', main='PT.SauronS878-BR1', rotate=45, size=1)

Fig3 <- t1+t2+t3+t4
#on this plot we can see: 
#Off target amplifications
#Longer branch length = higher resolution


# 3.3. - Evaluate the taxonomic coverage and the specificity of the primers within the Actinopterygii class (i.e. Actinopteri class based
#        on the NCBI nomenclature). Also evaluate the taxonomic resolution of the primers at the genus level and correct for length of the
#        barcode to allow for comparisons between primers. Add additional columns to the input file for all calculated statistics.

dat.I$PT.Specificity <- rep("", nrow(dat.I))
dat.I$PT.PWDistance <- rep("", nrow(dat.I))
dat.I$PT.Length <- rep("", nrow(dat.I))
dat.I$PT.Resolution <- rep("", nrow(dat.I))
dat.I$PT.Order <- rep("", nrow(dat.I))
dat.I$PT.Family <- rep("", nrow(dat.I))
dat.I$PT.Genus <- rep("", nrow(dat.I))

for (i in 1:nrow(dat.I)) {
  tmp1 <- paste("PT", dat.I$Name[i], sep = ".")
  TAXID.All <- length(unique(as.data.frame(get(tmp1)$taxonomy)$taxId))
  TAXID.Act <- length(unique(subset(as.data.frame(get(tmp1)$taxonomy), subset = class == "Insecta")$taxId))
  dat.I$PT.Specificity[i] <- round((TAXID.Act / TAXID.All) * 100, digits = 2)
  dat.I$PT.PWDistance[i] <- as.numeric(calc_rank_dist_ave(get(tmp1), ranks = c("genus")))
  dat.I$PT.Length[i] <- as.integer(mean(get(tmp1)$BLAST_result$product_length))
  dat.I$PT.Resolution[i] <- as.numeric(dat.I$PT.PWDistance[i]) / as.numeric(dat.I$PT.Length[i])
  dat.I$PT.Order[i] <- length(unique(subset(as.data.frame(get(tmp1)$taxonomy), subset = class == "Insecta")$order))
  dat.I$PT.Family[i] <- length(unique(subset(as.data.frame(get(tmp1)$taxonomy), subset = class == "Insecta")$family))
  dat.I$PT.Genus[i] <- length(unique(subset(as.data.frame(get(tmp1)$taxonomy), subset = class == "Insecta")$genus))
}

#   B. Primer specificity (i.e. the percentage of unique Actinopterygii species out of the total number of unique species recovered)

gg.specificity <- ggplot(dat.I, aes(x = factor(Name, levels = Name), y = as.numeric(PT.Specificity))) +
  geom_bar(stat = "identity", fill = "gray50") +
  geom_hline(aes(yintercept = 90), linetype = "dashed", colour = "red3") +
  coord_cartesian(ylim = c(30, 100)) +
  ggtitle("B") +
  ylab("% of unique Actinopterygii species") +
  theme_classic() +
  theme(
    plot.title = element_text(size = 8, colour = "black", face = "bold"),
    axis.title.x = element_blank(),
    axis.title.y = element_text(size = 7, colour = "black"),
    axis.text.x = element_text(size = 7, colour = "black", angle = 90, hjust = 1, vjust = 0.5),
    axis.text.y = element_text(size = 7, colour = "black"),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_line(size = 0.25, colour = "black"),
    axis.ticks.length = unit(0.1, "cm")
  )
gg.specificity

#   C. Taxonomic coverage (i.e. no. of Actinopterygii orders for which sequences were obtained)

gg.coverage <- ggplot(dat.I, aes(x = factor(Name, levels = Name), y = as.numeric(PT.Order))) +
  geom_bar(stat = "identity", fill = "gray50") +
  geom_hline(aes(yintercept = 30), linetype = "dashed", colour = "red3") +
  coord_cartesian(ylim = c(0, 40)) +
  ggtitle("C") +
  ylab("No. of Actinopterygii orders") +
  theme_classic() +
  theme(
    plot.title = element_text(size = 8, colour = "black", face = "bold"),
    axis.title.x = element_blank(),
    axis.title.y = element_text(size = 7, colour = "black"),
    axis.text.x = element_text(size = 7, colour = "black", angle = 90, hjust = 1, vjust = 0.5),
    axis.text.y = element_text(size = 7, colour = "black"),
    axis.ticks.x = element_blank(),
    axis.ticks.y = element_line(size = 0.25, colour = "black"),
    axis.ticks.length = unit(0.1, "cm")
  )
gg.coverage

```


```{r sessioninfo}
sessionInfo(package = NULL)
```
