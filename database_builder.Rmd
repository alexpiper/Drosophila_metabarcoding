---
title: "Database builder"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

## Load packages
```{r setup}
## Load Necessary packages
sapply(c("rentrez", "bold", "taxize","taxizedb", "usethis", "tidyverse", "spider", "insect", "ape", "DECIPHER", "ggpubr", "RColorBrewer", "plotly", "ggforce", "seqinr", "shortread", "patchwork", "viridis","ggridges","UpSetR"), require, character.only = TRUE)


# install.packages("devtools")
#devtools::install_github("alexpiper/taxreturn")
library(taxreturn)

## Get an NCBI api key for taxize queries
# use_entrez()

# After generating your key set it as ENTREZ_KEY in .Renviron.
# ENTREZ_KEY='1c0a0c4afa28448650a1450662a22c68f208'
#usethis::edit_r_environ()
```

## Download data for all insecta

```{r retrieve sequences, eval=FALSE, include=FALSE}
## Fetch sequences from GenBank 
genbank <- fetchSeqs("Insecta", database="genbank", out.dir="reference/insecta/genbank", downstream="Order", quiet=FALSE, marker="COI OR COI OR COX1 OR COXI", output = "gb-binom",compress=FALSE, cores=1)

## Fetch sequences from BOLD
bold <- fetchSeqs("Insecta", database="bold", out.dir="reference/insecta/bold", downstream="Order",quiet=FALSE, marker="COI-5P", output = "gb-binom",compress=FALSE, cores=3)

## Fetch mitochondrial genomes from genbank
fetchSeqs("Insecta", database="genbank", out.dir="reference/insecta/genbank", quiet=FALSE, marker="mitochondria", output = "gb-binom", compress=TRUE, cores=2)

```

## Download data for Arachnida

```{r retrieve arachnid seqs, eval=FALSE, include=FALSE}
## Fetch sequences from GenBank 
fetchSeqs("Arachnida", database="genbank", out.dir="genbank", downstream="Order", quiet=FALSE, output = "gb-binom", compress=TRUE, cores=1)

## Fetch sequences from BOLD
fetchSeqs("Arachnida", database="bold", out.dir="reference/arachnida/bold", downstream=TRUE, quiet=FALSE, downto="Order", marker="COI-5P", output = "gb-binom",compress=FALSE, cores=1)

```

# Get some outgroups using random subsampling of search
```{r outgroups}
outgroup_classes <- dplyr::bind_rows(taxize::downstream("Arthropoda", db="itis", downto="Class")) %>%
  filter(!taxonname=="Insecta") %>%
  pull(taxonname)
outgroup_phyla <- dplyr::bind_rows(taxize::upstream("Insecta", db="itis", upto="Phylum")) %>%
  pull(taxonname)
outgroup_kingdoms <- c("Bacteria", "Fungi")

outgroups <- c(outgroup_classes, outgroup_phyla, outgroup_kingdoms)

fetchSeqs(outgroups, database="genbank", out.dir="reference/outgroups", quiet=FALSE, output = "gb-binom", subsample = 100, compress=TRUE, cores=1)
```

## Merge and summarise origin of sequences

```{R}
#read in all fastas and summarise number of sequences and taxa.
library(Biostrings)

insecta_genbank <- readDNAStringSet(list.files("reference/insecta/genbank", pattern = ".fa", full.names = TRUE))
insecta_bold <- readDNAStringSet(list.files("reference/insecta/bold", pattern = ".fa", full.names = TRUE))
arachnida_genbank <- readDNAStringSet(list.files("reference/arachnida/genbank", pattern = ".fa", full.names = TRUE))
arachnida_bold <- readDNAStringSet(list.files("reference/arachnida/bold", pattern = ".fa", full.names = TRUE))
outgroups_genbank <- readDNAStringSet(list.files("reference/outgroups", pattern = ".fa", full.names = TRUE))
# Unique sequences

seqs <- c(insecta_genbank, insecta_bold, arachnida_genbank, arachnida_bold, outgroups_genbank)
# Get heirarchy and summarise unique species as well?

# Dereplicate
uniqSeqs <- seqs[unique(names(seqs)),] # Remove those sequnce names that are identical across both databases

writeXStringSet(uniqSeqs, "reference/uniqSeqs.fa.gz", width=5000, compress=TRUE)
## summarise number of sequences

tracker <- tribble(
  ~stage, ~species, ~seqs,
  "insecta_genbank", NA, length(insecta_genbank),
  "insecta_bold", NA, length(insecta_bold),
  "arachnida_genbank", NA, length(arachnida_genbank),
  "arachnida_bold", NA, length(arachnida_bold),
  "outgroups", NA, length(outgroups_genbank),
  "merged", NA, length(seqs),
  "unique", NA, length(uniqSeqs)
)
```


## Clean sequences

```{r Clean sequences}
#build PHMM from midori longest - sequences need to be same length
midori <-  Biostrings::readDNAStringSet("MIDORI_LONGEST_20180221_COI.fasta")
insecta_midori <- as.DNAbin(midori[str_detect(names(midori),pattern=";Insecta;"),])
folmer <- insect::virtualPCR(insecta_midori, up = "TITCIACIAAYCAYAARGAYATTGG",down= "TAIACYTCIGGRTGICCRAARAAYCA",cores=2, rcdown = TRUE, trimprimers = TRUE)
filt <- folmer[lengths(folmer)==658]

#Filtered was then aligned in MAFFT - mafft folmer_insecta_fullength.fa > folmer_insecta_fullength_aligned.fa
#alignment was then manually curated in geneious primer
folmer_curated <-  ape::read.dna("reference/folmer_insecta_fullength_aligned_curated.fa",format="fasta")
model <- aphid::derivePHMM(folmer_curated)

filtered <- clean_seqs(uniqSeqs, model, minscore = 500, cores=2, shave=TRUE, maxNs = 0)
insect::writeFASTA(filtered, file="reference/filtered.fa.gz",compress=TRUE)

# Summarise number of sequences and species left

#filter using insect::purge - Could wrap this in a function for ease of use?
db <- insect::taxonomy(db = "NCBI", synonyms = TRUE)
#filter db

db <- db %>%
  filter(!rank %in% c("varietas","subspecies","species subgroup")) %>%
  dplyr::filter(!str_detect(name, fixed("sp."))) %>%
  dplyr::filter(!str_detect(name, fixed("spp."))) %>%
  dplyr::filter(!str_detect(name, fixed("aff."))) %>%
  dplyr::filter(!str_detect(name, fixed("nr."))) %>%
  dplyr::filter(!str_detect(name, fixed("bv."))) %>%
  dplyr::filter(!str_detect(name, fixed("cf."))) %>%
  dplyr::filter(!str_detect(name, fixed("nom."))) %>%
  dplyr::filter(!str_detect(name, fixed("nud."))) %>%
  dplyr::filter(!str_detect(name, fixed("environment"))) %>%
  dplyr::filter(!str_detect(name, fixed("undescribed"))) %>%
  dplyr::filter(!str_detect(name, fixed("unverified"))) %>%
  dplyr::filter(!str_detect(name, fixed("unclassified"))) %>%
  dplyr::filter(!str_detect(name, fixed("uncultured"))) %>%
  dplyr::filter(!str_detect(name, fixed("unidentif"))) %>%
  dplyr::filter(!str_detect(name, fixed("NA"))) %>%
  dplyr::filter(!str_detect(name, fixed("error"))) %>% 
  dplyr::filter(!str_detect(name,"[0-9]"))%>% 
  dplyr::filter(!str_detect(name,"[:punct:]"))

filtered <- ape::read.FASTA(gzfile("Sequences/filtered.fa.gz"))

remove <- names(filtered)  %>% 
  str_split_fixed(";", n = 2) %>% 
  as_tibble() %>%
  filter(V2 %in% db$name) %>%
  unite(names,c("V1","V2"),sep=";")

subset <- filtered[names(filtered) %in% remove$names]
insect::writeFASTA(subset, file="reference/subset.fa.gz",compress=TRUE)
# Summarise number of sequences and species left
rm(filtered)

resolved <- resolve_synonyms(subset, subspecies=FALSE, quiet=FALSE, missing="ignore", higherrank=FALSE, fuzzy=TRUE)

insect::writeFASTA(resolved, file="Sequences/resolved.fa.gz",compress=TRUE)

# Summarise number of sequences and species left

#Check differences in names
length(names(resolved)[which(!names(resolved) %in% names(subset))])
rm(subset)

#Save old names into attributes
attributes(resolved)$oldnames <- names(resolved)
#Get names in format for insect::purge
names(resolved) <- names(resolved) %>%
  str_split_fixed(";",n=2) %>%
  as_tibble() %>%
  pull("V1") 

#filter using insect::purge - Could wrap this in a function for ease of use?
db <- insect::taxonomy(db = "NCBI", synonyms = TRUE)

#get unique names only
resolved <- insect::subset.DNAbin(resolved, subset = !duplicated(names(resolved)))
purged  <- insect::purge(resolved, db = db, level = "Genus", confidence = 0.8, threshold = 0.97, method = "farthest")

#Restore old names
names(purged) <- attributes(purged)$oldnames
insect::writeFASTA(purged,file="Sequences/purged.fa.gz",compress=TRUE)


# Summarise number of sequences and species left

##### PRUNE GROUP SIZES

#purged <- readFASTA("Sequences/purged.fa.gz")

#Prune group sizes down to 5 - Is de-duplication actually a good thing? this may bias towards bad singleton sequences?
pruned <- prune_groups(purged, maxGroupSize = 5, discardby="length",dedup=TRUE, quiet = FALSE)

#Change to complete taxonomic heirarchy
pruned <- reformat_heirarchy(pruned, ranks = c("kingdom","phylum", "class", "order", "family", "genus", "species"), quiet=FALSE)

#Convert to DNAStringset
save <- pruned

pruned <-  pruned %>% as.character %>% lapply(.,paste0,collapse="") %>% unlist %>% DNAStringSet
alphabetFrequency(pruned, collapse=TRUE)

pruned <- replaceAmbiguities(pruned,new="N")
pruned <- ShortRead::clean(pruned)

writeXStringSet(pruned, filepath="Sequences/pruned.fa.gz",compress = TRUE, format = "fasta" )

```

## Trim to primer regions


```{r Create taxonomic classifier database}
#Trim to primer region using virtualPCR from insect package
amplicon <- virtualPCR(filtseqs, up = "ACWGGWTGRACWGTNTAYCC",down= "ARYATDGTRATDGCHCCDGC",cores=3, rcdown = TRUE, trimprimers = TRUE)
writeFASTA(amplicon,"gb_trimmed.fa")

```


## Track sequences lost at each stage
```{r}
## summarise number of sequences

tracker <- tribble(
  ~stage, ~species, ~seqs,
  "insecta_genbank", NA, length(readDNAStringSet(list.files("reference/insecta/genbank", pattern = ".fa", full.names = TRUE))),
  "insecta_bold", NA, length(readDNAStringSet(list.files("reference/insecta/bold", pattern = ".fa", full.names = TRUE))),
  "arachnida_genbank", NA, length(readDNAStringSet(list.files("reference/arachnida/genbank", pattern = ".fa", full.names = TRUE))),
  "arachnida_bold", NA, length(readDNAStringSet(list.files("reference/arachnida/bold", pattern = ".fa", full.names = TRUE))),
  "outgroups", NA, length(readDNAStringSet(list.files("reference/outgroups", pattern = ".fa", full.names = TRUE))),
  "merged", NA, length(seqs),
  "unique", NA, length( readDNAStringSet("reference/uniqSeqs.fa.gz"))
)
```

## Train IDTAXA

```{r IDTAXA}
library(DECIPHER)

merged <- readDNAStringSet("insecta_arachnida_28_10_19/insecta_arachnida_rdp_genus.fa.gz")

#Reformat to complete taxonomic heirarchy 
heirarchy <- reformat_heirarchy(amplicon, db=db, quiet=FALSE)

#Convert to DNAstringset for DECIPHER
seqs <- heirarchy %>% as.character %>% lapply(.,paste0,collapse="") %>% unlist %>% DNAStringSet


# As taxonomies are encoded in the sequence names rather than a separate file, use:
taxid <- NULL
seqs <- RemoveGaps(seqs)
seqs <- OrientNucleotides(seqs)

# obtain the taxonomic assignments
groups <- names(seqs) # sequence names

#Replace metazoa with Root
names(seqs) <- names(seqs) %>% str_replace(pattern="Metazoa", replacement="Root")

# assume the taxonomy begins with 'Root;' 
groups <- gsub("(.*)(Root;)", "\\2", groups) # extract the group label - May need to use a wild card for the root label as its split by 3 genes!
groupCounts <- table(groups)
u_groups <- names(groupCounts) # unique groups
length(u_groups) # number of groups
 
# Pruning training set

maxGroupSize <- 10 # max sequences per label (>= 1)
remove <- logical(length(seqs))
for (i in which(groupCounts > maxGroupSize)) {
  index <- which(groups==u_groups[i])
  keep <- sample(length(index),
  maxGroupSize)
  remove[index[-keep]] <- TRUE
}
sum(remove) # number of sequences eliminated


# Training the classifier
maxIterations <- 3 # must be >= 1
allowGroupRemoval <- TRUE
probSeqsPrev <- integer() # suspected problem sequences from prior iteration
for (i in seq_len(maxIterations)) {
  cat("Training iteration: ", i, "\n", sep="")
  # train the classifier
  trainingSet <- LearnTaxa(seqs[!remove],
  names(seqs)[!remove],
  taxid)
  
  # look for problem sequences
  probSeqs <- trainingSet$problemSequences$Index
  if (length(probSeqs)==0) {
    cat("No problem sequences remaining.\n")
    break
  } else if (length(probSeqs)==length(probSeqsPrev) &&
  all(probSeqsPrev==probSeqs)) {
    cat("Iterations converged.\n")
    break
    }
  if (i==maxIterations)
  break
  probSeqsPrev <- probSeqs
  
  # remove any problem sequences
  index <- which(!remove)[probSeqs]
  remove[index] <- TRUE # remove all problem sequences
  if (!allowGroupRemoval) {
    # replace any removed groups
    missing <- !(u_groups %in% groups[!remove])
    missing <- u_groups[missing]
    if (length(missing) > 0) {
    index <- index[groups[index] %in% missing]
    remove[index] <- FALSE # don't remove
    }
  }
}
sum(remove) # total number of sequences eliminated
length(probSeqs) # number of remaining problem sequences

# View the results of training

trainingSet
plot(trainingSet)

#Write out training set
saveRDS(trainingSet, file="reference/idtaxa.rds")
```
