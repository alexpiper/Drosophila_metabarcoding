---
title: "Database builder"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

## Load packages
```{r setup}
## Load Necessary packages
sapply(c("rentrez", "bold", "taxize","taxizedb", "usethis", "tidyverse", "spider", "insect", "ape", "DECIPHER", "ggpubr", "RColorBrewer", "plotly", "ggforce", "seqinr", "shortread", "patchwork", "viridis","ggridges","UpSetR"), require, character.only = TRUE)


# install.packages("devtools")
#devtools::install_github("alexpiper/taxreturn")
library(taxreturn)

## Get an NCBI api key for taxize queries
# use_entrez()

# After generating your key set it as ENTREZ_KEY in .Renviron.
# ENTREZ_KEY='1c0a0c4afa28448650a1450662a22c68f208'
#usethis::edit_r_environ()
```

## Download data for all insecta

```{r retrieve sequences, eval=FALSE, include=FALSE}
## Fetch sequences from GenBank 
genbank <- fetchSeqs("Insecta", database="genbank", out.dir="reference/insecta/genbank", downstream="Order", quiet=FALSE, marker="COI OR COI OR COX1 OR COXI", output = "gb-binom",compress=FALSE, cores=1)

## Fetch sequences from BOLD
bold <- fetchSeqs("Insecta", database="bold", out.dir="reference/insecta/bold", downstream="Order",quiet=FALSE, marker="COI-5P", output = "gb-binom",compress=FALSE, cores=3)

## Fetch mitochondrial genomes from genbank
fetchSeqs("Insecta", database="genbank", out.dir="reference/insecta/genbank", quiet=FALSE, marker="mitochondria", output = "gb-binom", compress=TRUE, cores=2)

```

## Download data for Arachnida

```{r retrieve arachnid seqs, eval=FALSE, include=FALSE}
## Fetch sequences from GenBank 
fetchSeqs("Arachnida", database="genbank", out.dir="genbank", downstream="Order", quiet=FALSE, output = "gb-binom", compress=TRUE, cores=1)

## Fetch sequences from BOLD
fetchSeqs("Arachnida", database="bold", out.dir="reference/arachnida/bold", downstream=TRUE, quiet=FALSE, downto="Order", marker="COI-5P", output = "gb-binom",compress=FALSE, cores=1)

```

# Get some outgroups using random subsampling of search
```{r outgroups}
outgroup_classes <- dplyr::bind_rows(taxize::downstream("Arthropoda", db="itis", downto="Class")) %>%
  filter(!taxonname=="Insecta") %>%
  pull(taxonname)
outgroup_phyla <- dplyr::bind_rows(taxize::upstream("Insecta", db="itis", upto="Phylum")) %>%
  pull(taxonname)
outgroup_kingdoms <- c("Bacteria", "Fungi")

outgroups <- c(outgroup_classes, outgroup_phyla, outgroup_kingdoms)

fetchSeqs(outgroups, database="genbank", out.dir="reference/outgroups", quiet=FALSE, output = "gb-binom", subsample = 100, compress=TRUE, cores=1)
```

## Merge and clean sequences

```{r merge and clean}
seqs <- c(readDNAStringSet(list.files("reference/insecta/genbank", pattern = ".fa", full.names = TRUE)),
          readDNAStringSet(list.files("reference/insecta/bold", pattern = ".fa", full.names = TRUE)),
          readDNAStringSet(list.files("reference/arachnida/genbank", pattern = ".fa", full.names = TRUE)),
          readDNAStringSet(list.files("reference/arachnida/bold", pattern = ".fa", full.names = TRUE)),
          readDNAStringSet(list.files("reference/outgroups", pattern = ".fa", full.names = TRUE)))

# write out merged seqs
writeXStringSet(seqs, filepath = "reference/mergedseqs.fa.gz", compress=TRUE)

# Dereplicate
uniqSeqs <- seqs[unique(names(seqs)),] # Remove those sequnce names that are identical across both databases
writeXStringSet(uniqSeqs, "reference/uniqSeqs.fa.gz", width=5000, compress=TRUE)

#build PHMM from midori longest - sequences need to be same length
midori <-  Biostrings::readDNAStringSet("MIDORI_LONGEST_20180221_COI.fasta")
insecta_midori <- as.DNAbin(midori[str_detect(names(midori),pattern=";Insecta;"),])
folmer <- insect::virtualPCR(insecta_midori, up = "TITCIACIAAYCAYAARGAYATTGG",down= "TAIACYTCIGGRTGICCRAARAAYCA",cores=2, rcdown = TRUE, trimprimers = TRUE)
filt <- folmer[lengths(folmer)==658]

#Filtered was then aligned in MAFFT - mafft folmer_insecta_fullength.fa > folmer_insecta_fullength_aligned.fa
#alignment was then manually curated in geneious primer
folmer_curated <-  ape::read.dna("reference/folmer_insecta_fullength_aligned_curated.fa",format="fasta")
model <- aphid::derivePHMM(folmer_curated)

filtered <- clean_seqs(uniqSeqs, model, minscore = 400, cores=2, shave=TRUE, maxNs = 0)
insect::writeFASTA(filtered, file="reference/filtered.fa.gz",compress=TRUE)

# Remove non-binomial species names
db <- insect::taxonomy(db = "NCBI", synonyms = TRUE) %>%
  filter(!rank %in% c("varietas","subspecies","species subgroup")) %>%
  dplyr::filter(!str_detect(name, fixed("sp."))) %>%
  dplyr::filter(!str_detect(name, fixed("spp."))) %>%
  dplyr::filter(!str_detect(name, fixed("aff."))) %>%
  dplyr::filter(!str_detect(name, fixed("nr."))) %>%
  dplyr::filter(!str_detect(name, fixed("bv."))) %>%
  dplyr::filter(!str_detect(name, fixed("cf."))) %>%
  dplyr::filter(!str_detect(name, fixed("nom."))) %>%
  dplyr::filter(!str_detect(name, fixed("nud."))) %>%
  dplyr::filter(!str_detect(name, fixed("environment"))) %>%
  dplyr::filter(!str_detect(name, fixed("undescribed"))) %>%
  dplyr::filter(!str_detect(name, fixed("unverified"))) %>%
  dplyr::filter(!str_detect(name, fixed("unclassified"))) %>%
  dplyr::filter(!str_detect(name, fixed("uncultured"))) %>%
  dplyr::filter(!str_detect(name, fixed("unidentif"))) %>%
  dplyr::filter(!str_detect(name, fixed("NA"))) %>%
  dplyr::filter(!str_detect(name, fixed("error"))) %>% 
  dplyr::filter(!str_detect(name,"[0-9]"))%>% 
  dplyr::filter(!str_detect(name,"[:punct:]"))

remove <- names(filtered)  %>% 
  str_split_fixed(";", n = 2) %>% 
  as_tibble() %>%
  filter(V2 %in% db$name) %>%
  unite(names,c("V1","V2"),sep=";")

subset <- filtered[names(filtered) %in% remove$names]
insect::writeFASTA(subset, file="reference/subset.fa.gz",compress=TRUE)

# resolve synonyms
resolved <- resolve_taxonomy(subset, subspecies=FALSE, quiet=FALSE, missing="ignore", higherrank=FALSE, fuzzy=TRUE)

#Check differences in names & Write out
length(names(resolved)[which(!names(resolved) %in% names(subset))])
insect::writeFASTA(resolved, file="reference/resolved.fa.gz", compress=TRUE)

# Filter misannotated taxonomy

#Save old names into attributes
attributes(resolved)$oldnames <- names(resolved)
#Get names in format for insect::purge
names(resolved) <- names(resolved) %>%
  str_split_fixed(";",n=2) %>%
  as_tibble() %>%
  pull("V1") 

#filter using insect::purge - Could wrap this in a function for ease of use?
db <- insect::taxonomy(db = "NCBI", synonyms = TRUE)

#get unique names only
resolved <- insect::subset.DNAbin(resolved, subset = !duplicated(names(resolved)))
purged  <- insect::purge(resolved, db = db, level = "Genus", confidence = 0.8, threshold = 0.97, method = "farthest")

#Restore old names
names(purged) <- attributes(purged)$oldnames
insect::writeFASTA(purged,file="reference/purged.fa.gz",compress=TRUE)

# Filter for stop codons
codon_filt <- taxreturn::codon_filter(purged)

# Prune large group sizes down to 5
pruned <- prune_groups(as.DNAbin(codon_filt), maxGroupSize = 5, discardby="length",dedup=TRUE, quiet = FALSE)

# Reformat to complete taxonomic heirarchy
pruned <- reformat_heirarchy(pruned, ranks = c("kingdom","phylum", "class", "order", "family", "genus", "species"), quiet=FALSE)
insect::writeFASTA(pruned, file="reference/pruned.fa.gz", compress=TRUE)
```


## Summarise sequences lost at each stage
```{r sequence tracker}
# Create read origins table
origin <- bind_rows(
  #Genbank Insecta
  fasta.index(list.files("reference/insecta/genbank", pattern = ".fa", full.names = TRUE)) %>%
    mutate(seqid = desc %>%
    str_replace(pattern="(\\|)(.*?)(?=$)", replacement="")) %>%
  mutate(origin = "genbank_insecta") %>%
  select(origin, seqid),
  #BOLD Insecta
  fasta.index(list.files("reference/insecta/bold", pattern = ".fa", full.names = TRUE)) %>%
    mutate(seqid = desc %>%
    str_replace(pattern="(\\|)(.*?)(?=$)", replacement="")) %>%
  mutate(origin = "bold_insecta") %>%
  select(origin, seqid),
  #Genbank Arachnida
  fasta.index(list.files("reference/arachnida/genbank", pattern = ".fa", full.names = TRUE)) %>%
    mutate(seqid = desc %>%
    str_replace(pattern="(\\|)(.*?)(?=$)", replacement="")) %>%
  mutate(origin = "genbank_arachnida") %>%
  select(origin, seqid),
  #BOLD Arachnida
  fasta.index(list.files("reference/arachnida/bold", pattern = ".fa", full.names = TRUE)) %>%
    mutate(seqid = desc %>%
    str_replace(pattern="(\\|)(.*?)(?=$)", replacement="")) %>%
  mutate(origin = "bold_arachnida") %>%
  select(origin, seqid),
  #Outgroups
  fasta.index(list.files("reference/outgroups", pattern = ".fa", full.names = TRUE)) %>%
    mutate(seqid = desc %>%
    str_replace(pattern="(\\|)(.*?)(?=$)", replacement="")) %>%
  mutate(origin = "outgroups") %>%
  select(origin, seqid),
) %>%
# Remove sequences imported from BOLD to genbank
  mutate(Duplicated = case_when(
    duplicated(seqid) & str_detect(origin, "bold") ~ TRUE,
    TRUE ~ FALSE
    )) %>%
  filter(!Duplicated) %>%   
  select(-Duplicated)


## summarise number of sequences at each stage and their origins
tracker <- bind_rows(
                  taxreturn::summarise_fasta("reference/mergedseqs.fa.gz", label="merged", origin=origin),
                  taxreturn::summarise_fasta("reference/uniqSeqs.fa.gz", label="unique", origin=origin),
                  taxreturn::summarise_fasta("reference/filtered.fa.gz", label="phmm_filtered", origin=origin),
                  taxreturn::summarise_fasta("reference/subset.fa.gz", label="subset", origin=origin),
                  taxreturn::summarise_fasta("reference/resolved.fa.gz", label="resolved", origin=origin),
                  taxreturn::summarise_fasta("reference/purged.fa.gz", label="purged", origin=origin),
                  taxreturn::summarise_fasta("reference/codon_filt.fa.gz", label="codon_filt", origin=origin),
                  taxreturn::summarise_fasta("reference/pruned.fa.gz", label="pruned", origin=origin)
) %>%
  mutate(label = factor(label, levels=c("merged", "unique", "phmm_filtered", "subset", "resolved", "purged", "codon_filt", "pruned" ))) %>%
  pivot_longer(cols=starts_with("n"),
               names_to = "Type",
               values_to = "value"
               )

gg.cleaning <- ggplot(tracker, aes(x=label, y=value, group=origin, fill=origin)) +
  geom_bar(stat="identity") +
  facet_wrap(~Type, nrow=2, ncol=1, scales = "free") +
  scale_fill_brewer(palette="Spectral") +
  xlab("Filter stage") +
  ylab("# Sequences") +
  theme_bw() + 
  scale_y_continuous(labels = scales::comma)
```

# Reformat and Merge in inhouse sequences
```{r}
# read in sequences
seqs <- readDNAStringSet(list.files("reference/inhouse/", pattern = ".fa", full.names = TRUE))

# Get ncbi taxid
db <- get_ranked_lineage(synonyms = TRUE, force=FALSE)

# Get heirarchy
names(seqs) <- names(seqs) %>%
  str_split_fixed(pattern="_", n=2) %>%
  as_tibble() %>%
  mutate(tax_name = str_replace(V2, "_", " ")) %>%
  mutate(tax_name = case_when(
    tax_name %in% (anti_join(., db, by="tax_name") %>% pull(tax_name)) ~ tax_name %>% str_replace(pattern="(\\ )(.*?)(?=$)", replacement=""),
    !tax_name %in% (anti_join(., db, by="tax_name") %>% pull(tax_name)) ~ tax_name
  )) %>%
  left_join(db, by="tax_name") %>% # DUPLICATES HAPPENING HERE!
  filter(!duplicated(V1)) %>%
  mutate(genus = case_when(
    is.na(genus) ~ tax_name,
    !is.na(genus) & !str_detect(tax_name, pattern="\\ ") & !tax_name == genus ~ tax_name,
    TRUE ~ genus
  )) %>%
  unite(col=tax, c("kingdom","phylum", "class", "order", "family", "genus","V2"), sep=";" ) %>%
  unite(col=acc, c("V1", "tax_id"), sep="|") %>%
  unite(col = names, c("acc", "tax"), sep=";") %>%
  mutate(names = str_replace(names, pattern="_", replacement=" ")) %>%
  pull(names)

#filt using phmm
folmer_curated <-  ape::read.dna("reference/folmer_insecta_fullength_aligned_curated.fa", format="fasta")
model <- aphid::derivePHMM(folmer_curated)

filtered <- clean_seqs(seqs, model, minscore = 200, cores=2, shave=TRUE, maxNs = 0)

# Filter for stop codons
codon_filt <- taxreturn::codon_filter(filtered %>% as.character %>% lapply(.,paste0,collapse="") %>% unlist %>% DNAStringSet)

#merge
mergedseqs <- c((insect::readFASTA(file="reference/pruned.fa.gz")), as.DNAbin(codon_filt))

insect::writeFASTA(mergedseqs, file="merged_final.fa.gz")
```

# Create reference set for fwhf2-fwhR2n region of COI

## Trim to primer regions

```{r Create taxonomic classifier database}
#Trim to primer region using virtualPCR from insect package - using BF1 and BR1 primers
amplicon <- virtualPCR(mergedseqs, up = "ACWGGWTGRACWGTNTAYCC",down= "ARYATDGTRATDGCHCCDGC", cores=3, rcdown = TRUE, trimprimers = TRUE)
writeFASTA(amplicon,"gb_trimmed.fa")

```

## Train IDTAXA

```{r IDTAXA}
library(DECIPHER)

merged <- readDNAStringSet("insecta_arachnida_28_10_19/insecta_arachnida_rdp_genus.fa.gz")

#Reformat to complete taxonomic heirarchy 
heirarchy <- reformat_heirarchy(amplicon, db=db, quiet=FALSE)

#Convert to DNAstringset for DECIPHER
seqs <- heirarchy %>% as.character %>% lapply(.,paste0,collapse="") %>% unlist %>% DNAStringSet


# As taxonomies are encoded in the sequence names rather than a separate file, use:
taxid <- NULL
seqs <- RemoveGaps(seqs)
seqs <- OrientNucleotides(seqs)

# obtain the taxonomic assignments
groups <- names(seqs) # sequence names

#Replace metazoa with Root
names(seqs) <- names(seqs) %>% str_replace(pattern="Metazoa", replacement="Root")

# assume the taxonomy begins with 'Root;' 
groups <- gsub("(.*)(Root;)", "\\2", groups) # extract the group label - May need to use a wild card for the root label as its split by 3 genes!
groupCounts <- table(groups)
u_groups <- names(groupCounts) # unique groups
length(u_groups) # number of groups
 
# Pruning training set

maxGroupSize <- 10 # max sequences per label (>= 1)
remove <- logical(length(seqs))
for (i in which(groupCounts > maxGroupSize)) {
  index <- which(groups==u_groups[i])
  keep <- sample(length(index),
  maxGroupSize)
  remove[index[-keep]] <- TRUE
}
sum(remove) # number of sequences eliminated


# Training the classifier
maxIterations <- 3 # must be >= 1
allowGroupRemoval <- TRUE
probSeqsPrev <- integer() # suspected problem sequences from prior iteration
for (i in seq_len(maxIterations)) {
  cat("Training iteration: ", i, "\n", sep="")
  # train the classifier
  trainingSet <- LearnTaxa(seqs[!remove],
  names(seqs)[!remove],
  taxid)
  
  # look for problem sequences
  probSeqs <- trainingSet$problemSequences$Index
  if (length(probSeqs)==0) {
    cat("No problem sequences remaining.\n")
    break
  } else if (length(probSeqs)==length(probSeqsPrev) &&
  all(probSeqsPrev==probSeqs)) {
    cat("Iterations converged.\n")
    break
    }
  if (i==maxIterations)
  break
  probSeqsPrev <- probSeqs
  
  # remove any problem sequences
  index <- which(!remove)[probSeqs]
  remove[index] <- TRUE # remove all problem sequences
  if (!allowGroupRemoval) {
    # replace any removed groups
    missing <- !(u_groups %in% groups[!remove])
    missing <- u_groups[missing]
    if (length(missing) > 0) {
    index <- index[groups[index] %in% missing]
    remove[index] <- FALSE # don't remove
    }
  }
}
sum(remove) # total number of sequences eliminated
length(probSeqs) # number of remaining problem sequences

# View the results of training

trainingSet
plot(trainingSet)

#Write out training set
saveRDS(trainingSet, file="reference/idtaxa.rds")
```
